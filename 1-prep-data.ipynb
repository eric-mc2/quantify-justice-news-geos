{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from zipfile import ZipFile\n",
    "import pyarrow.parquet as pq\n",
    "import gzip\n",
    "import json\n",
    "import pyarrow as pa\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLAB = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"gdrive/MyDrive/Work/qjn/\" if COLAB else \"data/\"\n",
    "FULL_DATASET_PATH = DATA_DIR + \"cjp_tables_old.zip\"\n",
    "\n",
    "# We will put this temporarily into one parquet then will split and delete full.\n",
    "FULL_TEXT_PATH = DATA_DIR + \"newsarticles_article.parquet\"\n",
    "FULL_TEXT_TRAIN_PATH = DATA_DIR + \"newsarticles_article_train.parquet\"\n",
    "FULL_TEXT_DEV_PATH = DATA_DIR + \"newsarticles_article_dev.parquet\"\n",
    "FULL_TEXT_TEST_PATH = DATA_DIR + \"newsarticles_article_test.parquet\"\n",
    "\n",
    "# Can directly split these into new files\n",
    "USER_LABELS_TRAIN_PATH = DATA_DIR + \"newsarticles_usercoding_train.csv\"\n",
    "USER_LABELS_DEV_PATH = DATA_DIR + \"newsarticles_usercoding_dev.csv\"\n",
    "USER_LABELS_TEST_PATH = DATA_DIR + \"newsarticles_usercoding_test.csv\"    \n",
    "\n",
    "# These dont' need to be split\n",
    "DATA_DICT_PATH = DATA_DIR + \"data_dict.txt\"\n",
    "GEOCODED_PATH = DATA_DIR + \"newsarticles_trainedlocation.parquet\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  data/cjp_tables_old.zip\n",
      "  Length      Date    Time    Name\n",
      "---------  ---------- -----   ----\n",
      "        0  02-19-2021 08:33   cjp_tables/\n",
      "  7860721  02-11-2020 00:34   cjp_tables/newsarticles_trainedlocation.csv.gz\n",
      " 20361082  02-11-2020 00:34   cjp_tables/newsarticles_trainedcategoryrelevance.csv.gz\n",
      "   702194  02-11-2020 00:34   cjp_tables/newsarticles_usercoding_categories.csv.gz\n",
      "     6148  03-23-2023 20:22   cjp_tables/.DS_Store\n",
      "  3391051  02-11-2020 00:34   cjp_tables/newsarticles_usercoding.csv.gz\n",
      "      670  02-11-2020 00:30   cjp_tables/newsarticles_newssource.csv.gz\n",
      "    14661  02-11-2020 00:34   cjp_tables/column_names.txt\n",
      "   331916  02-11-2020 00:34   cjp_tables/newsarticles_trainedsentiment.csv.gz\n",
      " 15028273  02-11-2020 00:34   cjp_tables/newsarticles_trainedcoding.csv.gz\n",
      "     1170  02-11-2020 00:34   cjp_tables/newsarticles_category.csv.gz\n",
      "    15152  02-11-2020 00:34   cjp_tables/newsarticles_trainedsentimententities.csv.gz\n",
      "1353923030  02-11-2020 00:34   cjp_tables/newsarticles_article.csv.gz\n",
      "---------                     -------\n",
      "1401637346                     20 files\n"
     ]
    }
   ],
   "source": [
    "!unzip -l {FULL_DATASET_PATH} | grep -v MACOSX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with ZipFile(FULL_DATASET_PATH, 'r') as zf:\n",
    "    with zf.open(\"cjp_tables/column_names.txt\", \"r\") as zzf:\n",
    "        data_dict = zzf.read().decode()\n",
    "        with open(DATA_DICT_PATH, \"w\") as tf:\n",
    "            tf.write(data_dict)\n",
    "\n",
    "    with zf.open(\"cjp_tables/newsarticles_article.csv.gz\", \"r\") as zzf:\n",
    "        with gzip.open(zzf) as zzzf:\n",
    "            article_data_chunks = pd.read_csv(zzzf,\n",
    "                    names=['id','feedname','url','orig_html','title','bodytext',\n",
    "                            'relevant','created','last_modified','news_source_id', 'author'],\n",
    "                        true_values=['t'], false_values=['f'],\n",
    "                        iterator=True, chunksize=1000)\n",
    "            writer = None\n",
    "            for chunk in article_data_chunks:\n",
    "                chunk = chunk.filter(['id','title','bodytext','relevant'])\n",
    "                table = pa.Table.from_pandas(chunk)\n",
    "                if writer is None:\n",
    "                    writer = pq.ParquetWriter(FULL_TEXT_PATH, table.schema)\n",
    "                writer.write_table(table)\n",
    "            writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with ZipFile(FULL_DATASET_PATH, 'r') as zf:\n",
    "    with zf.open(\"cjp_tables/newsarticles_trainedlocation.csv.gz\", \"r\") as zzf:\n",
    "        with gzip.open(zzf) as zzzf:\n",
    "            geocodes = pd.read_csv(zzzf,\n",
    "                    names=['id','text','latitude','longitude','coding_id',\n",
    "                            'confidence','neighborhood','is_best'],\n",
    "                    true_values=['t'],\n",
    "                    false_values=['f'])\n",
    "            geocodes.to_parquet(GEOCODED_PATH)\n",
    "    \n",
    "    with zf.open(\"cjp_tables/newsarticles_usercoding.csv.gz\", \"r\") as zzf:\n",
    "        with gzip.open(zzf) as zzzf:\n",
    "            loc_data = pd.read_csv(zzzf, \n",
    "                        names=['id','date','relevant','article_id','user_id','locations','sentiment'],\n",
    "                        dtype={'locations':'str'},\n",
    "                    true_values=['t'],\n",
    "                    false_values=['f'])\n",
    "            mask = (loc_data['locations'] != '[]') & loc_data['relevant']\n",
    "            loc_data = loc_data[mask]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_data = pd.read_parquet(FULL_TEXT_PATH)\n",
    "article_data = article_data.dropna(subset='bodytext')\n",
    "article_data['bodytext'] = (article_data['bodytext']\n",
    "                                  .str.replace('\\n',' ')\n",
    "                                  .str.replace(u'\\xa0', u' '))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Break out locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_data = loc_data.filter(['article_id','user_id','locations'])\n",
    "loc_data['location'] = loc_data['locations'].apply(json.loads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "exploded = loc_data.explode('location', ignore_index=True)\n",
    "exploded_locs = exploded.location.apply(pd.Series)\n",
    "exploded_locs = exploded_locs.rename(columns={'start':'loc_start','end':'loc_end', 'text':'loc_text'})\n",
    "exploded = pd.concat([exploded, exploded_locs], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix Indexes\n",
    "\n",
    "IDK what is causing this but the article bodytext and location indexes are not aligned. \n",
    "They seem to be consistently off by 9 (at least for the first 20 I checked)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "verify = exploded.merge(article_data, left_on='article_id', right_on='id', how='left')\n",
    "verify['locclean'] = (verify['loc_text']\n",
    "                      .str.replace('\\n',' ')\n",
    "                      .str.replace(u'\\xa0', u' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "verify['extracted'] = verify.apply(lambda r: r.bodytext[r.loc_start:r.loc_end],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = verify['extracted'] == verify.locclean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pct aligned 0.0%\n"
     ]
    }
   ],
   "source": [
    "print(\"Pct aligned {:.1%}\".format(correct.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "OFFSET = 9\n",
    "verify['loc_start'] -= OFFSET\n",
    "verify['loc_end'] -= OFFSET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "verify['extracted'] = verify.apply(lambda r: r.bodytext[r.loc_start:r.loc_end],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = verify['extracted'] == verify.locclean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pct aligned 91.7%\n"
     ]
    }
   ],
   "source": [
    "print(\"Pct aligned {:.1%}\".format(correct.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "OFFSET = 8\n",
    "verify.loc[~correct,'loc_start'] -= OFFSET\n",
    "verify.loc[~correct,'loc_end'] -= OFFSET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "verify['extracted'] = verify.apply(lambda r: r.bodytext[r.loc_start:r.loc_end],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = verify['extracted'] == verify.locclean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pct aligned 99.7%. Misaligned 33 rows.\n"
     ]
    }
   ],
   "source": [
    "print(\"Pct aligned {:.1%}. Misaligned {} rows.\".format(correct.mean(),len(correct)-correct.sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another .3% to fix ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "extracted",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "locclean",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "4f16e562-9051-4426-9339-6dd14c246f7b",
       "rows": [
        [
         "672",
         "",
         " JARRATT, Va."
        ],
        [
         "1068",
         "",
         "         ####  Related Stories"
        ],
        [
         "1259",
         " in the South Side Grand Crossing neighbo",
         "South Side Grand Crossing neighborhood. "
        ],
        [
         "1324",
         "cago&ref=",
         "         "
        ],
        [
         "1552",
         "you're in",
         "         "
        ],
        [
         "1674",
         "e was in ",
         "         "
        ],
        [
         "1675",
         "e was in ",
         "         "
        ],
        [
         "1763",
         "n",
         " "
        ],
        [
         "1786",
         "e was in ",
         "         "
        ],
        [
         "1914",
         "ting on Chicago's South",
         "Chicago's South Side. "
        ],
        [
         "2303",
         "urred:  • At 8:35 p.m. March 17 in the 4900 block of Marshfield Avenue  • At 1:25 a.m. March 19 in the 5400 block of South Ashland Avenue  • At 6:45 a.m. Friday in the 5400 block of South Dame",
         "• At 8:35 p.m. March 17 in the 4900 block of Marshfield Avenue • At 1:25 a.m. March 19 in the 5400 block of South Ashland Avenue • At 6:45 a.m. Friday in the 5400 block of South Damen Avenue"
        ],
        [
         "2308",
         " pre-dawn",
         "         "
        ],
        [
         "2309",
         "ot, t",
         " ___"
        ],
        [
         "2619",
         " from the",
         "         "
        ],
        [
         "2815",
         " in the 2500 block of West 58  t",
         "2500 block of West 58 th Street"
        ],
        [
         "2816",
         " in the 2700 block of East 75  th",
         "2700 block of East 75 th Street"
        ],
        [
         "3061",
         "home on West Grand Avenue after they got out of the car, police",
         "West Grand Avenue after they got out of the car, police said. "
        ],
        [
         "3062",
         "sai",
         " "
        ],
        [
         "3313",
         " in the Englewood  neigh",
         "Englewood neighborhood."
        ],
        [
         "6397",
         " as the CTA Red Line Fullerton stop and about a block away from DePaul",
         "CTA Red Line Fullerton stop and about a block away from DePaul.       "
        ],
        [
         "6797",
         " in the 5100 block of West Wellington A",
         "5100 block of West Wellington Avenue; "
        ],
        [
         "6859",
         "ren, in Avondale on the North",
         "Avondale on the North Side. "
        ],
        [
         "6870",
         "ound on Michigan Avenue from 37th S",
         "Michigan Avenue from 37th Street. "
        ],
        [
         "7101",
         "stigated",
         " CHICAGO"
        ],
        [
         "7128",
         " nature.",
         " CHICAGO"
        ],
        [
         "7202",
         " in the 2000 block of East 71  st",
         "2000 block of East 71 st Street"
        ],
        [
         "7204",
         "red onto 71  s",
         " 71 st Stree"
        ],
        [
         "7206",
         "ners at 71  st  and",
         "71 st and Jeffery"
        ],
        [
         "7536",
         "District",
         " CHICAGO"
        ],
        [
         "7688",
         "",
         " The Chicago Theatre"
        ],
        [
         "8441",
         "747-8380",
         " CHICAGO"
        ],
        [
         "8903",
         "e 300 block of E. Lower Water Stre",
         "300 block of E. Lower Water Street"
        ],
        [
         "9120",
         "he Near Nor",
         "North Side"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 33
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>extracted</th>\n",
       "      <th>locclean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>672</th>\n",
       "      <td></td>\n",
       "      <td>JARRATT, Va.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1068</th>\n",
       "      <td></td>\n",
       "      <td>####  Related Stories</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1259</th>\n",
       "      <td>in the South Side Grand Crossing neighbo</td>\n",
       "      <td>South Side Grand Crossing neighborhood.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1324</th>\n",
       "      <td>cago&amp;ref=</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1552</th>\n",
       "      <td>you're in</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1674</th>\n",
       "      <td>e was in</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1675</th>\n",
       "      <td>e was in</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1763</th>\n",
       "      <td>n</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1786</th>\n",
       "      <td>e was in</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1914</th>\n",
       "      <td>ting on Chicago's South</td>\n",
       "      <td>Chicago's South Side.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2303</th>\n",
       "      <td>urred:  • At 8:35 p.m. March 17 in the 4900 bl...</td>\n",
       "      <td>• At 8:35 p.m. March 17 in the 4900 block of M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2308</th>\n",
       "      <td>pre-dawn</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2309</th>\n",
       "      <td>ot, t</td>\n",
       "      <td>___</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2619</th>\n",
       "      <td>from the</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2815</th>\n",
       "      <td>in the 2500 block of West 58  t</td>\n",
       "      <td>2500 block of West 58 th Street</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2816</th>\n",
       "      <td>in the 2700 block of East 75  th</td>\n",
       "      <td>2700 block of East 75 th Street</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3061</th>\n",
       "      <td>home on West Grand Avenue after they got out o...</td>\n",
       "      <td>West Grand Avenue after they got out of the ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3062</th>\n",
       "      <td>sai</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3313</th>\n",
       "      <td>in the Englewood  neigh</td>\n",
       "      <td>Englewood neighborhood.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6397</th>\n",
       "      <td>as the CTA Red Line Fullerton stop and about ...</td>\n",
       "      <td>CTA Red Line Fullerton stop and about a block ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6797</th>\n",
       "      <td>in the 5100 block of West Wellington A</td>\n",
       "      <td>5100 block of West Wellington Avenue;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6859</th>\n",
       "      <td>ren, in Avondale on the North</td>\n",
       "      <td>Avondale on the North Side.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6870</th>\n",
       "      <td>ound on Michigan Avenue from 37th S</td>\n",
       "      <td>Michigan Avenue from 37th Street.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7101</th>\n",
       "      <td>stigated</td>\n",
       "      <td>CHICAGO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7128</th>\n",
       "      <td>nature.</td>\n",
       "      <td>CHICAGO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7202</th>\n",
       "      <td>in the 2000 block of East 71  st</td>\n",
       "      <td>2000 block of East 71 st Street</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7204</th>\n",
       "      <td>red onto 71  s</td>\n",
       "      <td>71 st Stree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7206</th>\n",
       "      <td>ners at 71  st  and</td>\n",
       "      <td>71 st and Jeffery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7536</th>\n",
       "      <td>District</td>\n",
       "      <td>CHICAGO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7688</th>\n",
       "      <td></td>\n",
       "      <td>The Chicago Theatre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8441</th>\n",
       "      <td>747-8380</td>\n",
       "      <td>CHICAGO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8903</th>\n",
       "      <td>e 300 block of E. Lower Water Stre</td>\n",
       "      <td>300 block of E. Lower Water Street</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9120</th>\n",
       "      <td>he Near Nor</td>\n",
       "      <td>North Side</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              extracted  \\\n",
       "672                                                       \n",
       "1068                                                      \n",
       "1259           in the South Side Grand Crossing neighbo   \n",
       "1324                                          cago&ref=   \n",
       "1552                                          you're in   \n",
       "1674                                          e was in    \n",
       "1675                                          e was in    \n",
       "1763                                                  n   \n",
       "1786                                          e was in    \n",
       "1914                            ting on Chicago's South   \n",
       "2303  urred:  • At 8:35 p.m. March 17 in the 4900 bl...   \n",
       "2308                                           pre-dawn   \n",
       "2309                                              ot, t   \n",
       "2619                                           from the   \n",
       "2815                    in the 2500 block of West 58  t   \n",
       "2816                   in the 2700 block of East 75  th   \n",
       "3061  home on West Grand Avenue after they got out o...   \n",
       "3062                                                sai   \n",
       "3313                            in the Englewood  neigh   \n",
       "6397   as the CTA Red Line Fullerton stop and about ...   \n",
       "6797             in the 5100 block of West Wellington A   \n",
       "6859                      ren, in Avondale on the North   \n",
       "6870                ound on Michigan Avenue from 37th S   \n",
       "7101                                           stigated   \n",
       "7128                                            nature.   \n",
       "7202                   in the 2000 block of East 71  st   \n",
       "7204                                     red onto 71  s   \n",
       "7206                                ners at 71  st  and   \n",
       "7536                                           District   \n",
       "7688                                                      \n",
       "8441                                           747-8380   \n",
       "8903                 e 300 block of E. Lower Water Stre   \n",
       "9120                                        he Near Nor   \n",
       "\n",
       "                                               locclean  \n",
       "672                                        JARRATT, Va.  \n",
       "1068                              ####  Related Stories  \n",
       "1259           South Side Grand Crossing neighborhood.   \n",
       "1324                                                     \n",
       "1552                                                     \n",
       "1674                                                     \n",
       "1675                                                     \n",
       "1763                                                     \n",
       "1786                                                     \n",
       "1914                             Chicago's South Side.   \n",
       "2303  • At 8:35 p.m. March 17 in the 4900 block of M...  \n",
       "2308                                                     \n",
       "2309                                                ___  \n",
       "2619                                                     \n",
       "2815                    2500 block of West 58 th Street  \n",
       "2816                    2700 block of East 75 th Street  \n",
       "3061  West Grand Avenue after they got out of the ca...  \n",
       "3062                                                     \n",
       "3313                            Englewood neighborhood.  \n",
       "6397  CTA Red Line Fullerton stop and about a block ...  \n",
       "6797             5100 block of West Wellington Avenue;   \n",
       "6859                       Avondale on the North Side.   \n",
       "6870                 Michigan Avenue from 37th Street.   \n",
       "7101                                            CHICAGO  \n",
       "7128                                            CHICAGO  \n",
       "7202                    2000 block of East 71 st Street  \n",
       "7204                                        71 st Stree  \n",
       "7206                                  71 st and Jeffery  \n",
       "7536                                            CHICAGO  \n",
       "7688                                The Chicago Theatre  \n",
       "8441                                            CHICAGO  \n",
       "8903                 300 block of E. Lower Water Street  \n",
       "9120                                         North Side  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verify[~correct][['extracted','locclean']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But screw it. It's confusing what is going wrong here. Some are blank.\n",
    "Some seem to have double spaces, but i can't fix that earlier or it messes up\n",
    "the other alignments. Just going to drop these FOR TRAINING."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (verify.index == exploded.index).all()\n",
    "exploded['loc_start'] = verify['loc_start']\n",
    "exploded['loc_end'] = verify['loc_end']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finish locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping 4 duplicated location tags.\n"
     ]
    }
   ],
   "source": [
    "exploded = exploded.filter(['article_id','user_id','loc_start','loc_end','loc_text'])\n",
    "dups = exploded.duplicated()\n",
    "print(f\"Dropping {dups.sum()} duplicated location tags.\")\n",
    "loc_data = exploded.loc[~dups & correct]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strip Whitespace\n",
    "\n",
    "Spacy will drop any NER entity that begins or ends with whitespace.\n",
    "So we'll strip it here and adjust the offsets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_clean = loc_data.loc_text.str.lstrip()\n",
    "end_clean = loc_data.loc_text.str.rstrip()\n",
    "loc_data.loc[:, 'loc_start'] += loc_data.loc_text.str.len() - start_clean.str.len()\n",
    "loc_data.loc[:, 'loc_end'] -= loc_data.loc_text.str.len() - end_clean.str.len()\n",
    "loc_data.loc[:, 'loc_text'] = loc_data.loc_text.str.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extend to token edges\n",
    "\n",
    "Some of the loc text is missing a leading or trailing character in the token.\n",
    "It needs to be token-aligned for spacy. I'll extend the start-end to the next\n",
    "whitespace on either side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_data = loc_data.merge(article_data[['id','bodytext']], left_on='article_id', right_on='id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find previous white space\n",
    "prev_ws = loc_data.apply(lambda row: row.bodytext.rfind(' ', 0, row.loc_start), axis=1).rename('prev_ws')\n",
    "# Find next white space\n",
    "next_ws = loc_data.apply(lambda row: row.bodytext.find(' ', row.loc_end), axis=1).rename('next_ws')\n",
    "# Check if we already started just after a white space.\n",
    "extend_prev = (prev_ws != -1) & (prev_ws != loc_data.loc_start - 1)\n",
    "# Check if we already ended on a white space.\n",
    "extend_next = (next_ws != -1) & (next_ws != loc_data.loc_end)\n",
    "# Conditionally extend indexes first.\n",
    "loc_data['loc_start_ext'] = prev_ws + 1\n",
    "loc_data['loc_end_ext'] = next_ws\n",
    "# Re-slice all strings\n",
    "context = loc_data.apply(lambda row: row.bodytext[row.loc_start_ext:row.loc_end_ext], axis=1)\n",
    "loc_data['loc_text_ext'] = context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selectively overwrite start/end/text\n",
    "loc_data.loc[extend_prev | extend_next, 'loc_text'] = loc_data.loc[extend_prev | extend_next, 'loc_text_ext']\n",
    "loc_data.loc[extend_prev, 'loc_start'] = loc_data.loc[extend_prev, 'loc_start_ext']\n",
    "loc_data.loc[extend_next, 'loc_end'] = loc_data.loc[extend_next, 'loc_end_ext']\n",
    "loc_data = loc_data.drop(columns=['loc_start_ext','loc_end_ext','loc_text_ext'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The expansions has caused some spans to overlap. Spacy can't handle\n",
    "# overlapping NER entities. Need to merge.\n",
    "\n",
    "def merge_spans(row):\n",
    "    spans = sorted(row, key=lambda x: x['start'])\n",
    "    merged = [spans[0]]\n",
    "\n",
    "    for span in spans[1:]:\n",
    "        prev_start, prev_end = merged[-1]['start'], merged[-1]['end']\n",
    "        next_start, next_end = span['start'], span['end']\n",
    "\n",
    "        if prev_end > next_start:  # Overlapping intervals\n",
    "            merged[-1] = {'start': prev_start, 'end': max(prev_end, next_end)}\n",
    "        else:\n",
    "            merged.append({'start': next_start, 'end':next_end})\n",
    "\n",
    "    return merged\n",
    "\n",
    "def group_spans(block):\n",
    "    return [{'start':s, 'end':e} for s,e in zip(block['loc_start'], block['loc_end'])]\n",
    "\n",
    "spans = (loc_data\n",
    "         .groupby('article_id')\n",
    "         .apply(group_spans,include_groups=False)\n",
    "         .apply(merge_spans)\n",
    "         .explode()\n",
    "         .apply(pd.Series)\n",
    "         .reset_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XXX: this process drops user_id and id from labeled loc data.\n",
    "loc_data = spans.merge(article_data[['id','bodytext']], left_on='article_id', right_on='id', how='left')\n",
    "loc_data['loc_text'] = loc_data.apply(lambda r: r.bodytext[r.start:r.end],axis=1)\n",
    "loc_data = loc_data.rename(columns={'start':'loc_start','end':'loc_end'})\n",
    "loc_data = loc_data.drop(columns=['bodytext','id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_dev_test(data, train_path, dev_path, test_path):\n",
    "    train = data.sample(frac=.8, random_state=22225)\n",
    "    dev_test = data.loc[data.index.difference(train.index)]\n",
    "    dev = dev_test.sample(frac=.5, random_state=22225)\n",
    "    test = dev_test.loc[dev_test.index.difference(dev.index)]\n",
    "    train.to_parquet(train_path)\n",
    "    dev.to_parquet(dev_path)\n",
    "    test.to_parquet(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_train_dev_test(article_data, FULL_TEXT_TRAIN_PATH, FULL_TEXT_DEV_PATH, FULL_TEXT_TEST_PATH)\n",
    "os.remove(FULL_TEXT_PATH)\n",
    "del article_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split User Codings\n",
    "\n",
    "Need to observe article splits so we don't leak training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_data_train = pd.read_parquet(FULL_TEXT_TRAIN_PATH, columns=['id'])\n",
    "article_data_dev = pd.read_parquet(FULL_TEXT_DEV_PATH, columns=['id'])\n",
    "article_data_test = pd.read_parquet(FULL_TEXT_TEST_PATH, columns=['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_data_train = loc_data[loc_data.article_id.isin(article_data_train.id)]\n",
    "loc_data_dev = loc_data[loc_data.article_id.isin(article_data_dev.id)]\n",
    "loc_data_test = loc_data[loc_data.article_id.isin(article_data_test.id)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_data_train.to_csv(USER_LABELS_TRAIN_PATH, index=False)\n",
    "loc_data_dev.to_csv(USER_LABELS_DEV_PATH, index=False)\n",
    "loc_data_test.to_csv(USER_LABELS_TEST_PATH, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
