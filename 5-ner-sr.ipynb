{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLAB = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"gdrive/MyDrive/Work/qjn/\" if COLAB else \"data/\"\n",
    "\n",
    "FULL_TEXT_TRAIN_PATH = DATA_DIR + \"newsarticles_article_train.parquet\"\n",
    "FULL_TEXT_DEV_PATH = DATA_DIR + \"newsarticles_article_dev.parquet\"\n",
    "FULL_TEXT_TEST_PATH = DATA_DIR + \"newsarticles_article_test.parquet\"\n",
    "\n",
    "USER_LABELS_TRAIN_PATH = DATA_DIR + \"newsarticles_usercoding_train.csv\"\n",
    "USER_LABELS_DEV_PATH = DATA_DIR + \"newsarticles_usercoding_dev.csv\"\n",
    "USER_LABELS_TEST_PATH = DATA_DIR + \"newsarticles_usercoding_test.csv\"    \n",
    "\n",
    "GEOCODED_PATH = DATA_DIR + \"newsarticles_trainedlocation.parquet\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_data = pd.read_parquet(FULL_TEXT_TRAIN_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_data = pd.read_csv(USER_LABELS_TRAIN_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_texts = loc_data.groupby('article_id',as_index=False).agg({'loc_start':list, 'loc_end':list, 'loc_text':list})\n",
    "ner_data = article_data.merge(loc_texts, left_on='id', right_on='article_id', how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Pretrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class RowScore:\n",
    "    true_pos: int\n",
    "    false_pos: int\n",
    "    false_neg: int\n",
    "\n",
    "    def __init__(self, true_pos, false_pos, false_neg):\n",
    "        if true_pos + false_pos == 0:\n",
    "            self.precision = 0\n",
    "        else:\n",
    "            self.precision = true_pos / (true_pos + false_pos)\n",
    "        \n",
    "        if true_pos + false_neg == 0:\n",
    "            self.recall = 0\n",
    "        else:\n",
    "            self.recall = true_pos / (true_pos + false_neg)\n",
    "        \n",
    "        if self.precision == 0 or self.recall == 0:\n",
    "            self.f1 = 0\n",
    "        else:\n",
    "            self.f1 = 2 / (1 / self.precision + 1 / self.recall)\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f\"RowScore(precision={self.precision:.2e}, recall={self.recall:.2e}, f1={self.f1:.2e})\"\n",
    "\n",
    "    def __add__(self, other):\n",
    "        if not isinstance(other, RowScore):\n",
    "            raise TypeError(\"other must be RowScore\")\n",
    "        return RowScore(self.true_pos + other.true_pos, \n",
    "                        self.false_pos + other.false_pos, \n",
    "                        self.false_neg + other.false_neg)\n",
    "    \n",
    "    def f1_strict(self):\n",
    "        print(self.true_pos, self.false_pos, self.false_neg)\n",
    "        print(\"Strict index and text matches:\")\n",
    "        print(\"Precision: {:.4f}\".format(self.precision))\n",
    "        print(\"Recall: {:.4f}\".format(self.recall))\n",
    "        print(\"F1: {:.4f}\".format(self.f1))\n",
    "        return self.f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Entity:\n",
    "    label: str\n",
    "    start: int\n",
    "    end: int\n",
    "    text: str\n",
    "\n",
    "def predict_batch(batch, model, batch_size):\n",
    "    batch_entities = model(batch.bodytext.to_list(), batch_size=batch_size)\n",
    "    return dict(zip(batch.id, batch_entities))\n",
    "\n",
    "def score_batch(batch, model, batch_size):\n",
    "    total_score = RowScore(0,0,0)\n",
    "    batch_entities = model(batch.bodytext.to_list(), batch_size=batch_size)\n",
    "    for row, entities in zip(batch.itertuples(), batch_entities):\n",
    "        total_score += score_row(row, entities)\n",
    "    return total_score\n",
    "\n",
    "def score_row(row, entities):\n",
    "    y_pred = {e.text.strip() for e in entities if e.label == 'LOC'}\n",
    "    y_true = {t.strip() for t in row.loc_text}\n",
    "    true_pos = len(y_true & y_pred)\n",
    "    false_pos = len(y_pred - y_true)\n",
    "    false_neg = len(y_true - y_pred)\n",
    "    return RowScore(true_pos, false_pos, false_neg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spacy_ner(doc):\n",
    "    loc_labels = ['FAC', # Buildings, airports, highways, bridges, etc.\n",
    "                  'ORG', # Companies, agencies, institutions, etc.\n",
    "                  'GPE', # Countries, cities, states\n",
    "                  'LOC' # Non-GPE locations, mountain ranges, bodies of water\n",
    "                  'EVENT'] # Named events (e.g., \"World Cup\")\n",
    "\n",
    "    matches = []\n",
    "    for token in doc:\n",
    "        if token.ent_type_ in loc_labels:\n",
    "            match = Entity(\"LOC\", token.idx, token.idx + len(token.text), token.text)\n",
    "            matches.append(match)\n",
    "    return matches\n",
    "\n",
    "def spacy_scorer(texts, **kwargs):\n",
    "    docs = nlp.pipe(texts, \n",
    "                    **kwargs,\n",
    "                    disable=[\"tok2vec\", \"tagger\", \"parser\", \"attribute_ruler\", \"lemmatizer\"])\n",
    "    entities = [spacy_ner(d) for d in docs]\n",
    "    return entities\n",
    "\n",
    "def spacy_doccer(texts, **kwargs):\n",
    "    docs = nlp.pipe(texts, \n",
    "                    **kwargs,\n",
    "                    disable=[\"ner\"])\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimize Batch Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 128 is the winner and 64 is 2nd.\n",
    "# for batch_size in batch_sizes:\n",
    "#     start = time.time()\n",
    "#     _ = spacy_scorer(texts, batch_size=batch_size)\n",
    "#     end = time.time()\n",
    "#     print(f\"Batch size {batch_size}: {end - start:.4f} sec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimize nlp.pipe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Optimize nlp.pipe\n",
    "# for batch_size in [16,32,64,128]:\n",
    "#     start = time.time()\n",
    "#     _ = spacy_scorer(texts, batch_size=batch_size, n_process=2)\n",
    "#     end = time.time()\n",
    "#     print(f\"Batch size {batch_size}: {end - start:.4f} sec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Actually Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q3 = ner_data.bodytext.str.len().quantile(.75)\n",
    "q1 = ner_data.bodytext.str.len().quantile(.25)\n",
    "iqr = q3 - q1\n",
    "left_outliers = ner_data.bodytext.str.len() < (q1 - 1.5 * iqr)\n",
    "right_outliers = ner_data.bodytext.str.len() > (q3 + 1.5 * iqr)\n",
    "outliers = left_outliers | right_outliers\n",
    "ner_data['very_long'] = right_outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PIPE_BATCH_SIZE = 64\n",
    "DF_BATCH_SIZE = PIPE_BATCH_SIZE * 4\n",
    "ner_data_sorted = ner_data.sort_values('bodytext', key=lambda x: x.str.len())\n",
    "ner_data_sorted = ner_data_sorted.iloc[:1000] # XXX: SAMPLING FOR TESTING!\n",
    "batches = np.array_split(ner_data_sorted, len(ner_data) // DF_BATCH_SIZE)\n",
    "entities = dict()\n",
    "for batch in tqdm(batches):\n",
    "    batch_size = 1 if batch['very_long'].any() else PIPE_BATCH_SIZE\n",
    "    entities |= predict_batch(batch, spacy_scorer, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_data_sorted['ents'] = ner_data_sorted['id'].map(entities)\n",
    "ner_data_sorted['ent_text'] = ner_data_sorted['ents'].apply(lambda xs: [x.text for x in xs])\n",
    "ner_data_sorted['score'] = ner_data_sorted.apply(lambda x: score_row(x, x.ents), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_data_sorted[['loc_text','ent_text','score']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is missing all the \"[NUM] block of [STREET]\" locations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-Tune Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.training import Example\n",
    "from spacy.util import minibatch\n",
    "import random\n",
    "from spacy.tokens import DocBin, Doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = dict()\n",
    "for batch in tqdm(batches):\n",
    "    batch_size = 1 if batch['very_long'].any() else PIPE_BATCH_SIZE\n",
    "    docs |= predict_batch(batch, spacy_doccer, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OFFSET = 9 # IDK what is causing this.\n",
    "docs = ner_data_sorted['id'].map(docs)\n",
    "entities = ner_data_sorted.apply(lambda r: list(zip(r.loc_start, r.loc_end, r.loc_text)), axis=1)\n",
    "examples = [Example.from_dict(d, {'entities': e}) for d,e in zip(docs, entities)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: I am fixing the indexes which are jank. \n",
    "# Might as well push this to the data processing ipynb actually.\n",
    "# Currently OK-ish but need to handle when keyword appears multiple times.\n",
    "\n",
    "loc_starts = ner_data_wide.apply(lambda row: [row.bodytext.find(t) for t in row.loc_text], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_data_wide.loc_text.apply(lambda x: len(x) - len(set(x))).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'abc'.fin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_data_wide.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in ner_data_long.itertuples():\n",
    "    for txt in row.loc_text:\n",
    "        assert txt in row.bodytext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy.training.offsets_to_biluo_tags(nlp.make_doc(ner_data_sorted.iloc[0].bodytext), entities.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_examples = [Example.from_dict(doc, {\"entities\": [(ent.start_char, ent.end_char, ent.label_) for ent in doc.ents]}) for doc in ner_data_sorted.doc]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NER + SR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO:**\n",
    "* Current spacy model does not resolve coreferences across sentence boundaries.\n",
    "* Keyword similarity is way too many false positives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacyspanbert.spanbert import SpanBERT \n",
    "spanbert = SpanBERT(\"./pretrained_spanbert\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dep_tree(token):\n",
    "    while token.head and token.head != token:\n",
    "        token = token.head\n",
    "    sub = [t.text for t in token.subtree]\n",
    "    return [token.text] + sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spacy_ner_sr(text):\n",
    "    # Process text\n",
    "    doc = nlp(text)\n",
    "\n",
    "    loc_labels = ['FAC', # Buildings, airports, highways, bridges, etc.\n",
    "                  'ORG', # Companies, agencies, institutions, etc.\n",
    "                  'GPE', # Countries, cities, states\n",
    "                  'LOC' # Non-GPE locations, mountain ranges, bodies of water\n",
    "                  'EVENT'] # Named events (e.g., \"World Cup\")\n",
    "    topic_keywords = ['crime','arrest','police']\n",
    "    topics = [nlp(t)[0] for t in topic_keywords]\n",
    "\n",
    "    matches = []\n",
    "    for token in doc:\n",
    "        # Look for location entity first because fewer of these than word embeddings.\n",
    "        if token.ent_type_ in loc_labels: # and token.dep_ in ['prep','pobj']\n",
    "            # Check for crime-related word in sentence.\n",
    "            sent = [t for t in token.sent if t.has_vector]\n",
    "            for tok in sent:\n",
    "                sim = np.mean([t.similarity(tok) for t in topics])\n",
    "                if sim > .5:\n",
    "                    match = {\"keyword\": tok.text,\n",
    "                            \"similarity\": sim,\n",
    "                            \"location\": token.text,\n",
    "                            \"context\": [x.text for x in token.sent if not x.text.isspace()]}\n",
    "                    matches.append(match)\n",
    "    return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = []\n",
    "# This works. Just commented out because it takes 3 minuts.\n",
    "for text in tqdm(article_data.bodytext):\n",
    "    matches.extend(spacy_ner_sr(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = pd.DataFrame.from_records(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches.groupby(['keyword'])['similarity'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches.groupby(['keyword','location'])['similarity'].mean().sort_values(ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches.groupby(['keyword'])['similarity'].mean().sort_values(ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine Tune"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO:**\n",
    "* Split train/dev/test\n",
    "* Fine-tune distilber or someone to just extract the location text somehow\n",
    "* Do EDA on the other trained model to try to check how many locations were geocodable.\n",
    "* DONT CONFUSE THE NEIGHBORHOOD CLASSIFIER WITH THE NER!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
