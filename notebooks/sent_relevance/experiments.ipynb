{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from git import Repo\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import secrets\n",
    "import spacy\n",
    "from spacy.util import load_config\n",
    "from spacy.cli import apply\n",
    "from spacy.scorer import Scorer, Example\n",
    "from spacy.tokens import DocBin, Doc\n",
    "import mlflow\n",
    "from mlflow.entities import ViewType\n",
    "import optuna\n",
    "\n",
    "import scripts.sent_relevance.operations as ops\n",
    "from scripts.utils.config import Config\n",
    "from scripts.utils import flatten_config\n",
    "from scripts.utils.spacy import load_spacy, train, load_metrics\n",
    "from scripts.utils.optuna import ArchiveBestModelCallback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup MLFLow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = \"sent_relevance_models\"\n",
    "task = \"sent_relevance\"\n",
    "\n",
    "# Provide an Experiment description that will appear in the UI\n",
    "experiment_description = (\n",
    "    \"Prototype model architectures for sentence relevance classifier.\"\n",
    ")\n",
    "\n",
    "# Provide searchable tags that define characteristics of the Runs that\n",
    "# will be in this Experiment\n",
    "experiment_tags = {\n",
    "    \"project_name\": \"qjn\",\n",
    "    \"task\": task,\n",
    "    \"mlflow.note.content\": experiment_description,\n",
    "}\n",
    "\n",
    "hyperparams = set([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-20 13:41:12,083 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 127.0.0.1:8080\n",
      "2025-03-20 13:41:12,111 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"GET /api/2.0/mlflow/experiments/get-by-name?experiment_name=sent_relevance_models HTTP/1.1\" 404 115\n",
      "2025-03-20 13:41:12,117 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 13:41:12,143 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"POST /api/2.0/mlflow/experiments/create HTTP/1.1\" 200 43\n",
      "2025/03/20 13:41:12 INFO mlflow.tracking.fluent: Experiment with name 'sent_relevance_models' does not exist. Creating a new experiment.\n",
      "2025-03-20 13:41:12,152 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 13:41:12,159 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"GET /api/2.0/mlflow/experiments/get?experiment_id=485071347047209202 HTTP/1.1\" 200 296\n",
      "2025-03-20 13:41:12,165 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 13:41:12,170 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"POST /api/2.0/mlflow/experiments/set-experiment-tag HTTP/1.1\" 200 2\n",
      "2025-03-20 13:41:12,175 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 13:41:12,183 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"POST /api/2.0/mlflow/experiments/set-experiment-tag HTTP/1.1\" 200 2\n",
      "2025-03-20 13:41:12,189 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 13:41:12,195 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"POST /api/2.0/mlflow/experiments/set-experiment-tag HTTP/1.1\" 200 2\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_tracking_uri(\"http://127.0.0.1:8080\")\n",
    "mlflow.set_experiment(experiment_name)\n",
    "mlflow.set_experiment_tags(experiment_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlflow_log_eval(run_name, params, model_path, nested=False):\n",
    "    \n",
    "    # Evaluate model\n",
    "    metrics = load_metrics(model_path)\n",
    "    best_model_path = os.path.join(model_path, \"model-best\")\n",
    "\n",
    "    # Load model params\n",
    "    repo = Repo(config._LOCAL_PROJECT_DIR, search_parent_directories=True)\n",
    "    params['git_hash'] = repo.heads.main.commit.hexsha\n",
    "\n",
    "    # Reshape params for logging\n",
    "    params = flatten_config(params)\n",
    "    # XXX: This migth have a bug converting children to strings?\n",
    "    params = {k.replace(\"@\",\"_AT_\"): v for k,v in params.items()}\n",
    "\n",
    "    with mlflow.start_run(run_name=run_name, nested=nested) as run:\n",
    "        mlflow.log_params(params)\n",
    "        mlflow.log_metrics(metrics)\n",
    "        mlflow.spacy.log_model(load_spacy(best_model_path), run_name)\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config()\n",
    "train_path = config.get_data_path(f\"{task}.article_text_train\")\n",
    "dev_path = config.get_data_path(f\"{task}.article_text_dev\")\n",
    "base_cfg = config.get_file_path(f\"{task}.base_cfg\")\n",
    "full_cfg = config.get_file_path(f\"{task}.full_cfg\")\n",
    "out_path = config.get_file_path(f\"{task}.trained_model\")\n",
    "out_path_scratch = config.get_file_path(f\"{task}.trained_model\", scratch=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quickstart Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;4mℹ Saving to output directory:\n",
      "/Users/eric/Dev/quantify-news/models/sent_relevance\u001b[0m\n",
      "\u001b[38;5;4mℹ Using CPU\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "[2025-03-20 13:41:15,208] [WARNING] [W112] The model specified to use for initial vectors (en_core_web_sm) has no vectors. This is almost certainly a mistake.\n",
      "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "\u001b[38;5;4mℹ Pipeline: ['textcat_multilabel']\u001b[0m\n",
      "\u001b[38;5;4mℹ Initial learn rate: 0.001\u001b[0m\n",
      "E    #       LOSS TEXTC...  CATS_SCORE  SCORE \n",
      "---  ------  -------------  ----------  ------\n",
      "  0       0           0.25       71.43    0.71\n",
      "  0     200          39.32       60.44    0.60\n",
      "  2     400          24.72       66.08    0.66\n",
      "  3     600          16.28       73.09    0.73\n",
      "  5     800          10.69       77.53    0.78\n",
      "  7    1000           6.50       80.40    0.80\n",
      " 10    1200           4.50       81.27    0.81\n",
      " 13    1400           2.95       82.51    0.83\n",
      " 17    1600           2.05       82.20    0.82\n",
      " 23    1800           1.43       82.91    0.83\n",
      " 29    2000           0.99       83.05    0.83\n",
      " 37    2200           0.70       82.98    0.83\n",
      " 48    2400           0.50       83.31    0.83\n",
      " 60    2600           0.36       83.06    0.83\n",
      " 75    2800           0.26       83.40    0.83\n",
      " 93    3000           0.19       83.40    0.83\n",
      "116    3200           0.14       83.27    0.83\n",
      "143    3400           0.10       83.20    0.83\n",
      "175    3600           0.07       82.92    0.83\n",
      "209    3800           0.06       82.93    0.83\n",
      "242    4000           0.04       83.51    0.84\n",
      "275    4200           0.04       83.37    0.83\n",
      "309    4400           0.03       83.36    0.83\n",
      "342    4600           0.02       83.36    0.83\n",
      "375    4800           0.02       83.06    0.83\n",
      "409    5000           0.02       83.06    0.83\n",
      "442    5200           0.02       82.99    0.83\n",
      "475    5400           0.01       83.06    0.83\n",
      "509    5600           0.01       83.06    0.83\n",
      "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
      "/Users/eric/Dev/quantify-news/models/sent_relevance/model-last\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-20 13:42:26,532 - git.util - DEBUG - Failed checking if running in CYGWIN due to: FileNotFoundError(2, 'No such file or directory')\n",
      "2025-03-20 13:42:26,538 - git.cmd - DEBUG - Popen(['git', 'cat-file', '--batch-check'], cwd=/Users/eric/Dev/quantify-news, stdin=<valid stream>, shell=False, universal_newlines=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 73.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-20 13:42:26,561 - git.cmd - DEBUG - Popen(['git', 'check-ignore', '/Users/eric/Dev/quantify-news/.venv/lib/python3.12/site-packages'], cwd=/Users/eric/Dev/quantify-news, stdin=None, shell=False, universal_newlines=False)\n",
      "2025-03-20 13:42:26,588 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 13:42:26,609 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"POST /api/2.0/mlflow/runs/create HTTP/1.1\" 200 962\n",
      "2025-03-20 13:42:26,619 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 13:42:26,675 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"POST /api/2.0/mlflow/runs/log-batch HTTP/1.1\" 200 2\n",
      "2025-03-20 13:42:26,685 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 13:42:26,712 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"POST /api/2.0/mlflow/runs/log-batch HTTP/1.1\" 200 2\n",
      "\u001b[31m2025/03/20 13:42:35 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "2025-03-20 13:42:35,783 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 13:42:35,812 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"GET /api/2.0/mlflow/runs/get?run_uuid=bba5128d3d054bf09b3267803d05f33e&run_id=bba5128d3d054bf09b3267803d05f33e HTTP/1.1\" 200 12838\n",
      "2025-03-20 13:42:35,839 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 13:42:35,848 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"POST /api/2.0/mlflow/runs/log-model HTTP/1.1\" 200 2\n",
      "2025-03-20 13:42:35,875 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 13:42:35,902 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"GET /api/2.0/mlflow/runs/get?run_uuid=bba5128d3d054bf09b3267803d05f33e&run_id=bba5128d3d054bf09b3267803d05f33e HTTP/1.1\" 200 13422\n",
      "2025-03-20 13:42:35,911 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 13:42:35,918 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"POST /api/2.0/mlflow/runs/update HTTP/1.1\" 200 471\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run quickstart_model at: http://127.0.0.1:8080/#/experiments/485071347047209202/runs/bba5128d3d054bf09b3267803d05f33e\n",
      "🧪 View experiment at: http://127.0.0.1:8080/#/experiments/485071347047209202\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'cats_micro_p': 0.8260869565,\n",
       " 'cats_micro_r': 0.7169811321,\n",
       " 'cats_micro_f': 0.7676767677,\n",
       " 'cats_macro_p': 0.6993103448,\n",
       " 'cats_macro_r': 0.4926436782,\n",
       " 'cats_macro_f': 0.5532451819,\n",
       " 'cats_f_per_type.WHO.p': 1.0,\n",
       " 'cats_f_per_type.WHO.r': 0.4,\n",
       " 'cats_f_per_type.WHO.f': 0.5714285714,\n",
       " 'cats_f_per_type.WHAT.p': 0.6,\n",
       " 'cats_f_per_type.WHAT.r': 0.6666666667,\n",
       " 'cats_f_per_type.WHAT.f': 0.6315789474,\n",
       " 'cats_f_per_type.WHERE.p': 1.0,\n",
       " 'cats_f_per_type.WHERE.r': 0.5,\n",
       " 'cats_f_per_type.WHERE.f': 0.6666666667,\n",
       " 'cats_f_per_type.WHEN.p': 0.0,\n",
       " 'cats_f_per_type.WHEN.r': 0.0,\n",
       " 'cats_f_per_type.WHEN.f': 0.0,\n",
       " 'cats_f_per_type.IRRELEVANT.p': 0.8965517241,\n",
       " 'cats_f_per_type.IRRELEVANT.r': 0.8965517241,\n",
       " 'cats_f_per_type.IRRELEVANT.f': 0.8965517241,\n",
       " 'cats_score': 0.8350646821}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train(train_path, dev_path, full_cfg, out_path)\n",
    "\n",
    "params = dict(load_config(full_cfg).interpolate())\n",
    "mlflow_log_eval(\"quickstart_model\", params, out_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_base(trial, overrides = {}):\n",
    "    print(\"Training with overrides:\\n\", overrides)\n",
    "    ops.train(base_cfg, full_cfg, train_path, dev_path, out_path_scratch, overrides)\n",
    "    \n",
    "    # Train will keep base config and apply overrides at run-time.\n",
    "    # So we load the config with the overrides for logging.\n",
    "    params = dict(load_config(full_cfg, overrides).interpolate())\n",
    "\n",
    "    run_name = f\"optuna_trial_{trial.number}\"\n",
    "    metrics = mlflow_log_eval(run_name, params, out_path_scratch, nested=True)\n",
    "\n",
    "    return metrics['cats_macro_f']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-20 13:42:37,372] Using an existing study with name 'sent_relevance' instead of creating a new one.\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(study_name=experiment_tags['task'],\n",
    "                            direction=\"maximize\",\n",
    "                            storage=config.get_param(f\"{task}.optuna_db\"),\n",
    "                            load_if_exists=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "archiver = ArchiveBestModelCallback(out_path=out_path, out_path_scratch=out_path_scratch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best(): \n",
    "    best = mlflow.search_runs(\n",
    "        experiment_names=[experiment_name],\n",
    "        run_view_type=ViewType.ACTIVE_ONLY,\n",
    "        max_results=1,\n",
    "        order_by=[\"metrics.cats_macro_f DESC\"],\n",
    "    ).iloc[0].T\n",
    "    return best\n",
    "\n",
    "def best_metrics():\n",
    "    best = get_best()\n",
    "    return best[best.index.str.startswith(\"metrics\")].to_dict()\n",
    "\n",
    "def best_params(keys):\n",
    "    best = get_best()\n",
    "    return {key: best.loc[\"params.\" + key] for key in keys}\n",
    "    \n",
    "def best_model():\n",
    "    best = get_best()\n",
    "    return os.path.join(best['artifact_uri'], best['tags.mlflow.runName'], 'model.spacy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp = \"training.batcher.size.start\"\n",
    "hyperparams.add(hp)\n",
    "\n",
    "def objective(trial):\n",
    "    hp_start_size = trial.suggest_int(hp, 1, 100)  # Tune batch start\n",
    "    overrides = {hp: hp_start_size}\n",
    "    return objective_base(trial, overrides)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-20 13:42:37,887 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 13:42:37,916 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"POST /api/2.0/mlflow/runs/create HTTP/1.1\" 200 970\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with overrides:\n",
      " {'training.batcher.size.start': 30}\n",
      "\u001b[38;5;2m✔ Auto-filled config with all values\u001b[0m\n",
      "\u001b[38;5;2m✔ Saved config\u001b[0m\n",
      "/Users/eric/Dev/quantify-news/scripts/sent_relevance/spacy_config.cfg\n",
      "You can now add your data and train your pipeline:\n",
      "python -m spacy train spacy_config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n",
      "\u001b[38;5;4mℹ Saving to output directory:\n",
      "/Users/eric/Dev/quantify-news/models/sent_relevance\u001b[0m\n",
      "\u001b[38;5;4mℹ Using CPU\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "[2025-03-20 13:42:42,405] [WARNING] [W112] The model specified to use for initial vectors (en_core_web_sm) has no vectors. This is almost certainly a mistake.\n",
      "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "\u001b[38;5;4mℹ Pipeline: ['textcat_multilabel']\u001b[0m\n",
      "\u001b[38;5;4mℹ Initial learn rate: 0.001\u001b[0m\n",
      "E    #       LOSS TEXTC...  CATS_SCORE  SCORE \n",
      "---  ------  -------------  ----------  ------\n",
      "  0       0           0.25       71.43    0.71\n",
      "  0     200          39.09       59.34    0.59\n",
      "  1     400          26.06       67.08    0.67\n",
      "  3     600          16.77       74.07    0.74\n",
      "  4     800          10.77       76.57    0.77\n",
      "  6    1000           7.04       80.23    0.80\n",
      "  9    1200           4.79       82.07    0.82\n",
      " 12    1400           3.06       82.51    0.83\n",
      " 16    1600           2.25       82.85    0.83\n",
      " 21    1800           1.57       82.99    0.83\n",
      " 27    2000           1.07       82.99    0.83\n",
      " 35    2200           0.77       82.98    0.83\n",
      " 44    2400           0.53       83.32    0.83\n",
      " 55    2600           0.39       83.13    0.83\n",
      " 69    2800           0.28       83.33    0.83\n",
      " 86    3000           0.20       83.19    0.83\n",
      "107    3200           0.15       83.20    0.83\n",
      "133    3400           0.11       83.27    0.83\n",
      "164    3600           0.08       83.06    0.83\n",
      "197    3800           0.06       82.99    0.83\n",
      "230    4000           0.05       83.50    0.84\n",
      "264    4200           0.04       83.50    0.84\n",
      "297    4400           0.03       83.50    0.83\n",
      "330    4600           0.03       83.57    0.84\n",
      "364    4800           0.02       83.06    0.83\n",
      "397    5000           0.02       83.06    0.83\n",
      "430    5200           0.02       83.12    0.83\n",
      "463    5400           0.01       83.12    0.83\n",
      "497    5600           0.01       83.06    0.83\n",
      "530    5800           0.01       83.26    0.83\n",
      "563    6000           0.01       83.33    0.83\n",
      "597    6200           0.01       83.40    0.83\n",
      "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
      "/Users/eric/Dev/quantify-news/models/sent_relevance/model-last\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-20 13:44:02,312 - git.cmd - DEBUG - Popen(['git', 'cat-file', '--batch-check'], cwd=/Users/eric/Dev/quantify-news, stdin=<valid stream>, shell=False, universal_newlines=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 82.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-20 13:44:02,338 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 13:44:02,361 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"POST /api/2.0/mlflow/runs/create HTTP/1.1\" 200 1074\n",
      "2025-03-20 13:44:02,371 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 13:44:02,442 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"POST /api/2.0/mlflow/runs/log-batch HTTP/1.1\" 200 2\n",
      "2025-03-20 13:44:02,453 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 13:44:02,480 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"POST /api/2.0/mlflow/runs/log-batch HTTP/1.1\" 200 2\n",
      "\u001b[31m2025/03/20 13:44:09 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "2025-03-20 13:44:09,692 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 13:44:09,721 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"GET /api/2.0/mlflow/runs/get?run_uuid=ce5383ad15b243cb9cf666a8d0dc6017&run_id=ce5383ad15b243cb9cf666a8d0dc6017 HTTP/1.1\" 200 12950\n",
      "2025-03-20 13:44:09,744 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 13:44:09,752 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"POST /api/2.0/mlflow/runs/log-model HTTP/1.1\" 200 2\n",
      "2025-03-20 13:44:09,776 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 13:44:09,804 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"GET /api/2.0/mlflow/runs/get?run_uuid=ce5383ad15b243cb9cf666a8d0dc6017&run_id=ce5383ad15b243cb9cf666a8d0dc6017 HTTP/1.1\" 200 13533\n",
      "2025-03-20 13:44:09,814 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 13:44:09,820 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"POST /api/2.0/mlflow/runs/update HTTP/1.1\" 200 470\n",
      "[I 2025-03-20 13:44:09,855] Trial 32 finished with value: 0.5532451819 and parameters: {'training.batcher.size.start': 30}. Best is trial 7 with value: 0.5532451819.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run optuna_trial_32 at: http://127.0.0.1:8080/#/experiments/485071347047209202/runs/ce5383ad15b243cb9cf666a8d0dc6017\n",
      "🧪 View experiment at: http://127.0.0.1:8080/#/experiments/485071347047209202\n",
      "Training with overrides:\n",
      " {'training.batcher.size.start': 30}\n",
      "\u001b[38;5;2m✔ Auto-filled config with all values\u001b[0m\n",
      "\u001b[38;5;2m✔ Saved config\u001b[0m\n",
      "/Users/eric/Dev/quantify-news/scripts/sent_relevance/spacy_config.cfg\n",
      "You can now add your data and train your pipeline:\n",
      "python -m spacy train spacy_config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n",
      "\u001b[38;5;4mℹ Saving to output directory:\n",
      "/Users/eric/Dev/quantify-news/models/sent_relevance\u001b[0m\n",
      "\u001b[38;5;4mℹ Using CPU\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "[2025-03-20 13:44:14,511] [WARNING] [W112] The model specified to use for initial vectors (en_core_web_sm) has no vectors. This is almost certainly a mistake.\n",
      "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "\u001b[38;5;4mℹ Pipeline: ['textcat_multilabel']\u001b[0m\n",
      "\u001b[38;5;4mℹ Initial learn rate: 0.001\u001b[0m\n",
      "E    #       LOSS TEXTC...  CATS_SCORE  SCORE \n",
      "---  ------  -------------  ----------  ------\n",
      "  0       0           0.25       71.43    0.71\n",
      "  0     200          39.09       59.34    0.59\n",
      "  1     400          26.06       67.08    0.67\n",
      "  3     600          16.77       74.07    0.74\n",
      "  4     800          10.77       76.57    0.77\n",
      "  6    1000           7.04       80.23    0.80\n",
      "  9    1200           4.79       82.07    0.82\n",
      " 12    1400           3.06       82.51    0.83\n",
      " 16    1600           2.25       82.85    0.83\n",
      " 21    1800           1.57       82.99    0.83\n",
      " 27    2000           1.07       82.99    0.83\n",
      " 35    2200           0.77       82.98    0.83\n",
      " 44    2400           0.53       83.32    0.83\n",
      " 55    2600           0.39       83.13    0.83\n",
      " 69    2800           0.28       83.33    0.83\n",
      " 86    3000           0.20       83.19    0.83\n",
      "107    3200           0.15       83.20    0.83\n",
      "133    3400           0.11       83.27    0.83\n",
      "164    3600           0.08       83.06    0.83\n",
      "197    3800           0.06       82.99    0.83\n",
      "230    4000           0.05       83.50    0.84\n",
      "264    4200           0.04       83.50    0.84\n",
      "297    4400           0.03       83.50    0.83\n",
      "330    4600           0.03       83.57    0.84\n",
      "364    4800           0.02       83.06    0.83\n",
      "397    5000           0.02       83.06    0.83\n",
      "430    5200           0.02       83.12    0.83\n",
      "463    5400           0.01       83.12    0.83\n",
      "497    5600           0.01       83.06    0.83\n",
      "530    5800           0.01       83.26    0.83\n",
      "563    6000           0.01       83.33    0.83\n",
      "597    6200           0.01       83.40    0.83\n",
      "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
      "/Users/eric/Dev/quantify-news/models/sent_relevance/model-last\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-20 13:45:33,990 - git.cmd - DEBUG - Popen(['git', 'cat-file', '--batch-check'], cwd=/Users/eric/Dev/quantify-news, stdin=<valid stream>, shell=False, universal_newlines=False)\n",
      "2025-03-20 13:45:34,016 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 82.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-20 13:45:34,041 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"POST /api/2.0/mlflow/runs/create HTTP/1.1\" 200 1074\n",
      "2025-03-20 13:45:34,052 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 13:45:34,130 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"POST /api/2.0/mlflow/runs/log-batch HTTP/1.1\" 200 2\n",
      "2025-03-20 13:45:34,142 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 13:45:34,171 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"POST /api/2.0/mlflow/runs/log-batch HTTP/1.1\" 200 2\n",
      "\u001b[31m2025/03/20 13:45:41 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "2025-03-20 13:45:41,952 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 13:45:41,984 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"GET /api/2.0/mlflow/runs/get?run_uuid=f9fef3649e5b43ed8367af618c698a09&run_id=f9fef3649e5b43ed8367af618c698a09 HTTP/1.1\" 200 12950\n",
      "2025-03-20 13:45:42,011 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 13:45:42,022 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"POST /api/2.0/mlflow/runs/log-model HTTP/1.1\" 200 2\n",
      "2025-03-20 13:45:42,051 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 13:45:42,081 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"GET /api/2.0/mlflow/runs/get?run_uuid=f9fef3649e5b43ed8367af618c698a09&run_id=f9fef3649e5b43ed8367af618c698a09 HTTP/1.1\" 200 13533\n",
      "2025-03-20 13:45:42,090 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 13:45:42,097 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"POST /api/2.0/mlflow/runs/update HTTP/1.1\" 200 470\n",
      "[I 2025-03-20 13:45:42,127] Trial 33 finished with value: 0.5532451819 and parameters: {'training.batcher.size.start': 30}. Best is trial 7 with value: 0.5532451819.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run optuna_trial_33 at: http://127.0.0.1:8080/#/experiments/485071347047209202/runs/f9fef3649e5b43ed8367af618c698a09\n",
      "🧪 View experiment at: http://127.0.0.1:8080/#/experiments/485071347047209202\n",
      "Training with overrides:\n",
      " {'training.batcher.size.start': 3}\n",
      "\u001b[38;5;2m✔ Auto-filled config with all values\u001b[0m\n",
      "\u001b[38;5;2m✔ Saved config\u001b[0m\n",
      "/Users/eric/Dev/quantify-news/scripts/sent_relevance/spacy_config.cfg\n",
      "You can now add your data and train your pipeline:\n",
      "python -m spacy train spacy_config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n",
      "\u001b[38;5;4mℹ Saving to output directory:\n",
      "/Users/eric/Dev/quantify-news/models/sent_relevance\u001b[0m\n",
      "\u001b[38;5;4mℹ Using CPU\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "[2025-03-20 13:45:46,746] [WARNING] [W112] The model specified to use for initial vectors (en_core_web_sm) has no vectors. This is almost certainly a mistake.\n",
      "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "\u001b[38;5;4mℹ Pipeline: ['textcat_multilabel']\u001b[0m\n",
      "\u001b[38;5;4mℹ Initial learn rate: 0.001\u001b[0m\n",
      "E    #       LOSS TEXTC...  CATS_SCORE  SCORE \n",
      "---  ------  -------------  ----------  ------\n",
      "  0       0           0.25       71.43    0.71\n",
      "  0     200          40.19       60.95    0.61\n",
      "  1     400          27.50       63.00    0.63\n",
      "  1     600          23.66       68.15    0.68\n",
      "  2     800          16.67       70.13    0.70\n",
      "  3    1000          14.16       74.09    0.74\n",
      "  3    1200          10.50       76.68    0.77\n",
      "  4    1400           8.33       78.23    0.78\n",
      "  5    1600           7.87       79.57    0.80\n",
      "  5    1800           6.18       80.89    0.81\n",
      "  6    2000           4.91       81.49    0.81\n",
      "  6    2200           4.84       81.70    0.82\n",
      "  7    2400           3.07       81.91    0.82\n",
      "  8    2600           3.97       81.78    0.82\n",
      "  8    2800           2.80       82.48    0.82\n",
      "  9    3000           2.62       81.77    0.82\n",
      " 10    3200           2.43       81.77    0.82\n",
      " 10    3400           2.43       82.18    0.82\n",
      " 11    3600           1.45       82.28    0.82\n",
      " 12    3800           2.14       82.10    0.82\n",
      " 12    4000           1.37       82.34    0.82\n",
      " 13    4200           1.44       81.90    0.82\n",
      " 13    4400           1.23       82.03    0.82\n",
      "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
      "/Users/eric/Dev/quantify-news/models/sent_relevance/model-last\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-20 13:46:26,944 - git.cmd - DEBUG - Popen(['git', 'cat-file', '--batch-check'], cwd=/Users/eric/Dev/quantify-news, stdin=<valid stream>, shell=False, universal_newlines=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 42.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-20 13:46:26,974 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 13:46:27,020 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"POST /api/2.0/mlflow/runs/create HTTP/1.1\" 200 1074\n",
      "2025-03-20 13:46:27,044 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 13:46:27,132 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"POST /api/2.0/mlflow/runs/log-batch HTTP/1.1\" 200 2\n",
      "2025-03-20 13:46:27,143 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 13:46:27,173 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"POST /api/2.0/mlflow/runs/log-batch HTTP/1.1\" 200 2\n",
      "\u001b[31m2025/03/20 13:46:34 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "2025-03-20 13:46:34,602 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 13:46:34,633 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"GET /api/2.0/mlflow/runs/get?run_uuid=2a70319755bf4f76a3e5a7fd4435e655&run_id=2a70319755bf4f76a3e5a7fd4435e655 HTTP/1.1\" 200 12949\n",
      "2025-03-20 13:46:34,659 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 13:46:34,670 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"POST /api/2.0/mlflow/runs/log-model HTTP/1.1\" 200 2\n",
      "2025-03-20 13:46:34,699 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 13:46:34,730 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"GET /api/2.0/mlflow/runs/get?run_uuid=2a70319755bf4f76a3e5a7fd4435e655&run_id=2a70319755bf4f76a3e5a7fd4435e655 HTTP/1.1\" 200 13532\n",
      "2025-03-20 13:46:34,738 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 13:46:34,746 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"POST /api/2.0/mlflow/runs/update HTTP/1.1\" 200 470\n",
      "[I 2025-03-20 13:46:34,780] Trial 34 finished with value: 0.4984934087 and parameters: {'training.batcher.size.start': 3}. Best is trial 7 with value: 0.5532451819.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run optuna_trial_34 at: http://127.0.0.1:8080/#/experiments/485071347047209202/runs/2a70319755bf4f76a3e5a7fd4435e655\n",
      "🧪 View experiment at: http://127.0.0.1:8080/#/experiments/485071347047209202\n",
      "Training with overrides:\n",
      " {'training.batcher.size.start': 38}\n",
      "\u001b[38;5;2m✔ Auto-filled config with all values\u001b[0m\n",
      "\u001b[38;5;2m✔ Saved config\u001b[0m\n",
      "/Users/eric/Dev/quantify-news/scripts/sent_relevance/spacy_config.cfg\n",
      "You can now add your data and train your pipeline:\n",
      "python -m spacy train spacy_config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n",
      "\u001b[38;5;4mℹ Saving to output directory:\n",
      "/Users/eric/Dev/quantify-news/models/sent_relevance\u001b[0m\n",
      "\u001b[38;5;4mℹ Using CPU\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "[2025-03-20 13:46:39,430] [WARNING] [W112] The model specified to use for initial vectors (en_core_web_sm) has no vectors. This is almost certainly a mistake.\n",
      "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "\u001b[38;5;4mℹ Pipeline: ['textcat_multilabel']\u001b[0m\n",
      "\u001b[38;5;4mℹ Initial learn rate: 0.001\u001b[0m\n",
      "E    #       LOSS TEXTC...  CATS_SCORE  SCORE \n",
      "---  ------  -------------  ----------  ------\n",
      "  0       0           0.25       69.74    0.70\n",
      "  1     200          38.24       59.79    0.60\n",
      "  2     400          24.38       66.96    0.67\n",
      "  4     600          15.07       72.73    0.73\n",
      "  6     800           9.50       78.61    0.79\n",
      "  8    1000           5.53       82.25    0.82\n",
      " 12    1200           3.63       82.52    0.83\n",
      " 16    1400           2.49       82.27    0.82\n",
      " 21    1600           1.72       82.99    0.83\n",
      " 28    1800           1.16       82.85    0.83\n",
      " 35    2000           0.81       82.77    0.83\n",
      " 45    2200           0.56       83.18    0.83\n",
      " 57    2400           0.41       83.24    0.83\n",
      " 72    2600           0.30       83.77    0.84\n",
      " 89    2800           0.21       83.19    0.83\n",
      "111    3000           0.15       83.00    0.83\n",
      "138    3200           0.11       83.44    0.83\n",
      "170    3400           0.08       83.51    0.84\n",
      "203    3600           0.06       83.38    0.83\n",
      "237    3800           0.05       83.37    0.83\n",
      "270    4000           0.04       83.37    0.83\n",
      "303    4200           0.03       83.30    0.83\n",
      "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
      "/Users/eric/Dev/quantify-news/models/sent_relevance/model-last\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-20 13:47:32,722 - git.cmd - DEBUG - Popen(['git', 'cat-file', '--batch-check'], cwd=/Users/eric/Dev/quantify-news, stdin=<valid stream>, shell=False, universal_newlines=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 55.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-20 13:47:32,756 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 13:47:32,794 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"POST /api/2.0/mlflow/runs/create HTTP/1.1\" 200 1074\n",
      "2025-03-20 13:47:32,804 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 13:47:32,882 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"POST /api/2.0/mlflow/runs/log-batch HTTP/1.1\" 200 2\n",
      "2025-03-20 13:47:32,893 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 13:47:32,924 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"POST /api/2.0/mlflow/runs/log-batch HTTP/1.1\" 200 2\n",
      "\u001b[31m2025/03/20 13:47:40 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "2025-03-20 13:47:40,511 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 13:47:40,550 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"GET /api/2.0/mlflow/runs/get?run_uuid=ea7cd88c85fd47e99ff97e348eb5f61c&run_id=ea7cd88c85fd47e99ff97e348eb5f61c HTTP/1.1\" 200 12958\n",
      "2025-03-20 13:47:40,588 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 13:47:40,599 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"POST /api/2.0/mlflow/runs/log-model HTTP/1.1\" 200 2\n",
      "2025-03-20 13:47:40,631 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 13:47:40,665 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"GET /api/2.0/mlflow/runs/get?run_uuid=ea7cd88c85fd47e99ff97e348eb5f61c&run_id=ea7cd88c85fd47e99ff97e348eb5f61c HTTP/1.1\" 200 13541\n",
      "2025-03-20 13:47:40,673 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 13:47:40,682 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"POST /api/2.0/mlflow/runs/update HTTP/1.1\" 200 470\n",
      "[I 2025-03-20 13:47:40,720] Trial 35 finished with value: 0.5269005848 and parameters: {'training.batcher.size.start': 38}. Best is trial 7 with value: 0.5532451819.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run optuna_trial_35 at: http://127.0.0.1:8080/#/experiments/485071347047209202/runs/ea7cd88c85fd47e99ff97e348eb5f61c\n",
      "🧪 View experiment at: http://127.0.0.1:8080/#/experiments/485071347047209202\n",
      "Training with overrides:\n",
      " {'training.batcher.size.start': 17}\n",
      "\u001b[38;5;2m✔ Auto-filled config with all values\u001b[0m\n",
      "\u001b[38;5;2m✔ Saved config\u001b[0m\n",
      "/Users/eric/Dev/quantify-news/scripts/sent_relevance/spacy_config.cfg\n",
      "You can now add your data and train your pipeline:\n",
      "python -m spacy train spacy_config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n",
      "\u001b[38;5;4mℹ Saving to output directory:\n",
      "/Users/eric/Dev/quantify-news/models/sent_relevance\u001b[0m\n",
      "\u001b[38;5;4mℹ Using CPU\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "[2025-03-20 13:47:45,292] [WARNING] [W112] The model specified to use for initial vectors (en_core_web_sm) has no vectors. This is almost certainly a mistake.\n",
      "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "\u001b[38;5;4mℹ Pipeline: ['textcat_multilabel']\u001b[0m\n",
      "\u001b[38;5;4mℹ Initial learn rate: 0.001\u001b[0m\n",
      "E    #       LOSS TEXTC...  CATS_SCORE  SCORE \n",
      "---  ------  -------------  ----------  ------\n",
      "  0       0           0.25       71.43    0.71\n",
      "  0     200          40.32       59.18    0.59\n",
      "  1     400          25.98       62.87    0.63\n",
      "  2     600          22.77       70.11    0.70\n",
      "  3     800          15.34       73.57    0.74\n",
      "  4    1000          10.67       75.39    0.75\n",
      "  5    1200           7.77       78.65    0.79\n",
      "  6    1400           5.52       81.00    0.81\n",
      "  8    1600           4.01       82.35    0.82\n",
      " 10    1800           3.16       81.84    0.82\n",
      " 13    2000           2.18       82.47    0.82\n",
      " 17    2200           1.64       82.40    0.82\n",
      " 21    2400           1.21       83.12    0.83\n",
      " 26    2600           0.86       83.26    0.83\n",
      " 33    2800           0.64       82.81    0.83\n",
      " 42    3000           0.44       82.99    0.83\n",
      " 52    3200           0.34       83.20    0.83\n",
      " 65    3400           0.25       83.33    0.83\n",
      " 80    3600           0.18       83.06    0.83\n",
      " 99    3800           0.13       83.20    0.83\n",
      "122    4000           0.10       83.20    0.83\n",
      "150    4200           0.07       83.72    0.84\n",
      "183    4400           0.05       83.57    0.84\n",
      "216    4600           0.04       82.92    0.83\n",
      "250    4800           0.03       82.92    0.83\n",
      "283    5000           0.03       82.86    0.83\n",
      "316    5200           0.02       82.86    0.83\n",
      "350    5400           0.02       83.06    0.83\n",
      "383    5600           0.02       83.13    0.83\n",
      "416    5800           0.01       83.13    0.83\n",
      "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
      "/Users/eric/Dev/quantify-news/models/sent_relevance/model-last\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-20 13:48:59,133 - git.cmd - DEBUG - Popen(['git', 'cat-file', '--batch-check'], cwd=/Users/eric/Dev/quantify-news, stdin=<valid stream>, shell=False, universal_newlines=False)\n",
      "2025-03-20 13:48:59,163 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 76.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-20 13:48:59,198 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"POST /api/2.0/mlflow/runs/create HTTP/1.1\" 200 1074\n",
      "2025-03-20 13:48:59,210 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 13:48:59,286 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"POST /api/2.0/mlflow/runs/log-batch HTTP/1.1\" 200 2\n",
      "2025-03-20 13:48:59,297 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 13:48:59,320 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"POST /api/2.0/mlflow/runs/log-batch HTTP/1.1\" 200 2\n",
      "\u001b[31m2025/03/20 13:49:06 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "2025-03-20 13:49:06,974 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 13:49:07,009 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"GET /api/2.0/mlflow/runs/get?run_uuid=aa599633b34045ccb2dfbbcac1256a2b&run_id=aa599633b34045ccb2dfbbcac1256a2b HTTP/1.1\" 200 12950\n",
      "2025-03-20 13:49:07,037 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 13:49:07,049 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"POST /api/2.0/mlflow/runs/log-model HTTP/1.1\" 200 2\n",
      "2025-03-20 13:49:07,088 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 13:49:07,157 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"GET /api/2.0/mlflow/runs/get?run_uuid=aa599633b34045ccb2dfbbcac1256a2b&run_id=aa599633b34045ccb2dfbbcac1256a2b HTTP/1.1\" 200 13533\n",
      "2025-03-20 13:49:07,177 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 13:49:07,194 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"POST /api/2.0/mlflow/runs/update HTTP/1.1\" 200 470\n",
      "[I 2025-03-20 13:49:07,299] Trial 36 finished with value: 0.5532451819 and parameters: {'training.batcher.size.start': 17}. Best is trial 7 with value: 0.5532451819.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run optuna_trial_36 at: http://127.0.0.1:8080/#/experiments/485071347047209202/runs/aa599633b34045ccb2dfbbcac1256a2b\n",
      "🧪 View experiment at: http://127.0.0.1:8080/#/experiments/485071347047209202\n",
      "Training with overrides:\n",
      " {'training.batcher.size.start': 38}\n",
      "\u001b[38;5;2m✔ Auto-filled config with all values\u001b[0m\n",
      "\u001b[38;5;2m✔ Saved config\u001b[0m\n",
      "/Users/eric/Dev/quantify-news/scripts/sent_relevance/spacy_config.cfg\n",
      "You can now add your data and train your pipeline:\n",
      "python -m spacy train spacy_config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n",
      "\u001b[38;5;4mℹ Saving to output directory:\n",
      "/Users/eric/Dev/quantify-news/models/sent_relevance\u001b[0m\n",
      "\u001b[38;5;4mℹ Using CPU\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "[2025-03-20 13:49:15,054] [WARNING] [W112] The model specified to use for initial vectors (en_core_web_sm) has no vectors. This is almost certainly a mistake.\n",
      "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "\u001b[38;5;4mℹ Pipeline: ['textcat_multilabel']\u001b[0m\n",
      "\u001b[38;5;4mℹ Initial learn rate: 0.001\u001b[0m\n",
      "E    #       LOSS TEXTC...  CATS_SCORE  SCORE \n",
      "---  ------  -------------  ----------  ------\n",
      "  0       0           0.25       69.74    0.70\n",
      "  1     200          38.24       59.79    0.60\n",
      "  2     400          24.38       66.96    0.67\n",
      "  4     600          15.07       72.73    0.73\n",
      "  6     800           9.50       78.61    0.79\n",
      "  8    1000           5.53       82.25    0.82\n",
      " 12    1200           3.63       82.52    0.83\n",
      " 16    1400           2.49       82.27    0.82\n",
      " 21    1600           1.72       82.99    0.83\n",
      " 28    1800           1.16       82.85    0.83\n",
      " 35    2000           0.81       82.77    0.83\n",
      " 45    2200           0.56       83.18    0.83\n",
      " 57    2400           0.41       83.24    0.83\n",
      " 72    2600           0.30       83.77    0.84\n",
      " 89    2800           0.21       83.19    0.83\n",
      "111    3000           0.15       83.00    0.83\n",
      "138    3200           0.11       83.44    0.83\n",
      "170    3400           0.08       83.51    0.84\n",
      "203    3600           0.06       83.38    0.83\n",
      "237    3800           0.05       83.37    0.83\n",
      "270    4000           0.04       83.37    0.83\n",
      "303    4200           0.03       83.30    0.83\n",
      "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
      "/Users/eric/Dev/quantify-news/models/sent_relevance/model-last\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-20 13:50:08,332 - git.cmd - DEBUG - Popen(['git', 'cat-file', '--batch-check'], cwd=/Users/eric/Dev/quantify-news, stdin=<valid stream>, shell=False, universal_newlines=False)\n",
      "2025-03-20 13:50:08,361 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 58.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-20 13:50:08,391 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"POST /api/2.0/mlflow/runs/create HTTP/1.1\" 200 1074\n",
      "2025-03-20 13:50:08,401 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 13:50:08,588 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"POST /api/2.0/mlflow/runs/log-batch HTTP/1.1\" 200 2\n",
      "2025-03-20 13:50:08,597 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 13:50:08,622 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"POST /api/2.0/mlflow/runs/log-batch HTTP/1.1\" 200 2\n",
      "\u001b[31m2025/03/20 13:50:16 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "2025-03-20 13:50:16,164 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 13:50:16,196 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"GET /api/2.0/mlflow/runs/get?run_uuid=5e3ab35f619d48a9b9cf303fdbbf1d85&run_id=5e3ab35f619d48a9b9cf303fdbbf1d85 HTTP/1.1\" 200 12958\n",
      "2025-03-20 13:50:16,230 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 13:50:16,240 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"POST /api/2.0/mlflow/runs/log-model HTTP/1.1\" 200 2\n",
      "2025-03-20 13:50:16,270 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 13:50:16,309 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"GET /api/2.0/mlflow/runs/get?run_uuid=5e3ab35f619d48a9b9cf303fdbbf1d85&run_id=5e3ab35f619d48a9b9cf303fdbbf1d85 HTTP/1.1\" 200 13541\n",
      "2025-03-20 13:50:16,319 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 13:50:16,329 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"POST /api/2.0/mlflow/runs/update HTTP/1.1\" 200 470\n",
      "[I 2025-03-20 13:50:16,375] Trial 37 finished with value: 0.5269005848 and parameters: {'training.batcher.size.start': 38}. Best is trial 7 with value: 0.5532451819.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run optuna_trial_37 at: http://127.0.0.1:8080/#/experiments/485071347047209202/runs/5e3ab35f619d48a9b9cf303fdbbf1d85\n",
      "🧪 View experiment at: http://127.0.0.1:8080/#/experiments/485071347047209202\n",
      "Training with overrides:\n",
      " {'training.batcher.size.start': 44}\n",
      "\u001b[38;5;2m✔ Auto-filled config with all values\u001b[0m\n",
      "\u001b[38;5;2m✔ Saved config\u001b[0m\n",
      "/Users/eric/Dev/quantify-news/scripts/sent_relevance/spacy_config.cfg\n",
      "You can now add your data and train your pipeline:\n",
      "python -m spacy train spacy_config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n",
      "\u001b[38;5;4mℹ Saving to output directory:\n",
      "/Users/eric/Dev/quantify-news/models/sent_relevance\u001b[0m\n",
      "\u001b[38;5;4mℹ Using CPU\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "[2025-03-20 13:50:21,283] [WARNING] [W112] The model specified to use for initial vectors (en_core_web_sm) has no vectors. This is almost certainly a mistake.\n",
      "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "\u001b[38;5;4mℹ Pipeline: ['textcat_multilabel']\u001b[0m\n",
      "\u001b[38;5;4mℹ Initial learn rate: 0.001\u001b[0m\n",
      "E    #       LOSS TEXTC...  CATS_SCORE  SCORE \n",
      "---  ------  -------------  ----------  ------\n",
      "  0       0           0.25       69.74    0.70\n",
      "  1     200          36.35       61.57    0.62\n",
      "  2     400          23.07       68.96    0.69\n",
      "  4     600          13.66       74.86    0.75\n",
      "  7     800           7.83       80.80    0.81\n",
      " 10    1000           5.00       81.80    0.82\n",
      " 14    1200           3.06       82.65    0.83\n",
      " 19    1400           2.12       82.92    0.83\n",
      " 25    1600           1.41       82.84    0.83\n",
      " 32    1800           1.01       83.05    0.83\n",
      " 41    2000           0.67       82.91    0.83\n",
      " 53    2200           0.48       83.24    0.83\n",
      " 67    2400           0.35       82.92    0.83\n",
      " 83    2600           0.25       83.12    0.83\n",
      "104    2800           0.18       83.06    0.83\n",
      "129    3000           0.13       82.99    0.83\n",
      "160    3200           0.10       83.00    0.83\n",
      "193    3400           0.07       82.79    0.83\n",
      "227    3600           0.05       82.93    0.83\n",
      "260    3800           0.04       83.44    0.83\n",
      "293    4000           0.04       83.37    0.83\n",
      "327    4200           0.03       82.86    0.83\n",
      "360    4400           0.02       82.86    0.83\n",
      "393    4600           0.02       82.79    0.83\n",
      "426    4800           0.02       82.86    0.83\n",
      "460    5000           0.02       82.86    0.83\n",
      "493    5200           0.01       82.92    0.83\n",
      "526    5400           0.01       83.06    0.83\n",
      "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
      "/Users/eric/Dev/quantify-news/models/sent_relevance/model-last\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-20 13:51:33,556 - git.cmd - DEBUG - Popen(['git', 'cat-file', '--batch-check'], cwd=/Users/eric/Dev/quantify-news, stdin=<valid stream>, shell=False, universal_newlines=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 74.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-20 13:51:33,608 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 13:51:33,647 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"POST /api/2.0/mlflow/runs/create HTTP/1.1\" 200 1074\n",
      "2025-03-20 13:51:33,660 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 13:51:33,740 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"POST /api/2.0/mlflow/runs/log-batch HTTP/1.1\" 200 2\n",
      "2025-03-20 13:51:33,753 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 13:51:33,825 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"POST /api/2.0/mlflow/runs/log-batch HTTP/1.1\" 200 2\n",
      "\u001b[31m2025/03/20 13:51:41 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "2025-03-20 13:51:41,796 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 13:51:41,826 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"GET /api/2.0/mlflow/runs/get?run_uuid=a32ba84ae9d34b98803b4bec793e420e&run_id=a32ba84ae9d34b98803b4bec793e420e HTTP/1.1\" 200 12959\n",
      "2025-03-20 13:51:41,858 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 13:51:41,867 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"POST /api/2.0/mlflow/runs/log-model HTTP/1.1\" 200 2\n",
      "2025-03-20 13:51:41,900 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 13:51:41,932 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"GET /api/2.0/mlflow/runs/get?run_uuid=a32ba84ae9d34b98803b4bec793e420e&run_id=a32ba84ae9d34b98803b4bec793e420e HTTP/1.1\" 200 13542\n",
      "2025-03-20 13:51:41,942 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 13:51:41,949 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"POST /api/2.0/mlflow/runs/update HTTP/1.1\" 200 470\n",
      "[I 2025-03-20 13:51:41,981] Trial 38 finished with value: 0.5380405036 and parameters: {'training.batcher.size.start': 44}. Best is trial 7 with value: 0.5532451819.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run optuna_trial_38 at: http://127.0.0.1:8080/#/experiments/485071347047209202/runs/a32ba84ae9d34b98803b4bec793e420e\n",
      "🧪 View experiment at: http://127.0.0.1:8080/#/experiments/485071347047209202\n",
      "Training with overrides:\n",
      " {'training.batcher.size.start': 17}\n",
      "\u001b[38;5;2m✔ Auto-filled config with all values\u001b[0m\n",
      "\u001b[38;5;2m✔ Saved config\u001b[0m\n",
      "/Users/eric/Dev/quantify-news/scripts/sent_relevance/spacy_config.cfg\n",
      "You can now add your data and train your pipeline:\n",
      "python -m spacy train spacy_config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n",
      "\u001b[38;5;4mℹ Saving to output directory:\n",
      "/Users/eric/Dev/quantify-news/models/sent_relevance\u001b[0m\n",
      "\u001b[38;5;4mℹ Using CPU\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "[2025-03-20 13:51:46,866] [WARNING] [W112] The model specified to use for initial vectors (en_core_web_sm) has no vectors. This is almost certainly a mistake.\n",
      "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "\u001b[38;5;4mℹ Pipeline: ['textcat_multilabel']\u001b[0m\n",
      "\u001b[38;5;4mℹ Initial learn rate: 0.001\u001b[0m\n",
      "E    #       LOSS TEXTC...  CATS_SCORE  SCORE \n",
      "---  ------  -------------  ----------  ------\n",
      "  0       0           0.25       71.43    0.71\n",
      "  0     200          40.32       59.18    0.59\n",
      "  1     400          25.98       62.87    0.63\n",
      "  2     600          22.77       70.11    0.70\n",
      "  3     800          15.34       73.57    0.74\n",
      "  4    1000          10.67       75.39    0.75\n",
      "  5    1200           7.77       78.65    0.79\n",
      "  6    1400           5.52       81.00    0.81\n",
      "  8    1600           4.01       82.35    0.82\n",
      " 10    1800           3.16       81.84    0.82\n",
      " 13    2000           2.18       82.47    0.82\n",
      " 17    2200           1.64       82.40    0.82\n",
      " 21    2400           1.21       83.12    0.83\n",
      " 26    2600           0.86       83.26    0.83\n",
      " 33    2800           0.64       82.81    0.83\n",
      " 42    3000           0.44       82.99    0.83\n",
      " 52    3200           0.34       83.20    0.83\n",
      " 65    3400           0.25       83.33    0.83\n",
      " 80    3600           0.18       83.06    0.83\n",
      " 99    3800           0.13       83.20    0.83\n",
      "122    4000           0.10       83.20    0.83\n",
      "150    4200           0.07       83.72    0.84\n",
      "183    4400           0.05       83.57    0.84\n",
      "216    4600           0.04       82.92    0.83\n",
      "250    4800           0.03       82.92    0.83\n",
      "283    5000           0.03       82.86    0.83\n",
      "316    5200           0.02       82.86    0.83\n",
      "350    5400           0.02       83.06    0.83\n",
      "383    5600           0.02       83.13    0.83\n",
      "416    5800           0.01       83.13    0.83\n",
      "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
      "/Users/eric/Dev/quantify-news/models/sent_relevance/model-last\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-20 13:52:58,491 - git.cmd - DEBUG - Popen(['git', 'cat-file', '--batch-check'], cwd=/Users/eric/Dev/quantify-news, stdin=<valid stream>, shell=False, universal_newlines=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 74.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-20 13:52:58,536 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 13:52:58,589 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"POST /api/2.0/mlflow/runs/create HTTP/1.1\" 200 1074\n",
      "2025-03-20 13:52:58,599 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 13:52:58,688 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"POST /api/2.0/mlflow/runs/log-batch HTTP/1.1\" 200 2\n",
      "2025-03-20 13:52:58,696 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 13:52:58,751 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"POST /api/2.0/mlflow/runs/log-batch HTTP/1.1\" 200 2\n",
      "\u001b[31m2025/03/20 13:53:07 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "2025-03-20 13:53:07,157 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 13:53:07,211 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"GET /api/2.0/mlflow/runs/get?run_uuid=0fca877effa8438daa92807c6a2b1209&run_id=0fca877effa8438daa92807c6a2b1209 HTTP/1.1\" 200 12950\n",
      "2025-03-20 13:53:07,252 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 13:53:07,268 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"POST /api/2.0/mlflow/runs/log-model HTTP/1.1\" 200 2\n",
      "2025-03-20 13:53:07,319 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 13:53:07,372 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"GET /api/2.0/mlflow/runs/get?run_uuid=0fca877effa8438daa92807c6a2b1209&run_id=0fca877effa8438daa92807c6a2b1209 HTTP/1.1\" 200 13533\n",
      "2025-03-20 13:53:07,384 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 13:53:07,407 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"POST /api/2.0/mlflow/runs/update HTTP/1.1\" 200 470\n",
      "[I 2025-03-20 13:53:07,452] Trial 39 finished with value: 0.5532451819 and parameters: {'training.batcher.size.start': 17}. Best is trial 7 with value: 0.5532451819.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run optuna_trial_39 at: http://127.0.0.1:8080/#/experiments/485071347047209202/runs/0fca877effa8438daa92807c6a2b1209\n",
      "🧪 View experiment at: http://127.0.0.1:8080/#/experiments/485071347047209202\n",
      "Training with overrides:\n",
      " {'training.batcher.size.start': 10}\n",
      "\u001b[38;5;2m✔ Auto-filled config with all values\u001b[0m\n",
      "\u001b[38;5;2m✔ Saved config\u001b[0m\n",
      "/Users/eric/Dev/quantify-news/scripts/sent_relevance/spacy_config.cfg\n",
      "You can now add your data and train your pipeline:\n",
      "python -m spacy train spacy_config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n",
      "\u001b[38;5;4mℹ Saving to output directory:\n",
      "/Users/eric/Dev/quantify-news/models/sent_relevance\u001b[0m\n",
      "\u001b[38;5;4mℹ Using CPU\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "[2025-03-20 13:53:12,717] [WARNING] [W112] The model specified to use for initial vectors (en_core_web_sm) has no vectors. This is almost certainly a mistake.\n",
      "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "\u001b[38;5;4mℹ Pipeline: ['textcat_multilabel']\u001b[0m\n",
      "\u001b[38;5;4mℹ Initial learn rate: 0.001\u001b[0m\n",
      "E    #       LOSS TEXTC...  CATS_SCORE  SCORE \n",
      "---  ------  -------------  ----------  ------\n",
      "  0       0           0.25       71.43    0.71\n",
      "  0     200          40.21       60.24    0.60\n",
      "  1     400          26.09       63.20    0.63\n",
      "  2     600          23.93       67.34    0.67\n",
      "  2     800          15.60       70.81    0.71\n",
      "  3    1000          13.59       74.16    0.74\n",
      "  4    1200           9.62       76.03    0.76\n",
      "  4    1400           7.98       76.46    0.76\n",
      "  5    1600           6.64       80.60    0.81\n",
      "  6    1800           5.06       80.92    0.81\n",
      "  7    2000           4.34       81.63    0.82\n",
      "  8    2200           3.33       81.78    0.82\n",
      "  9    2400           2.55       81.76    0.82\n",
      " 10    2600           2.27       81.46    0.81\n",
      " 12    2800           1.65       81.96    0.82\n",
      " 14    3000           1.49       81.89    0.82\n",
      " 17    3200           1.08       82.03    0.82\n",
      " 21    3400           0.86       82.74    0.83\n",
      " 25    3600           0.64       82.68    0.83\n",
      " 31    3800           0.47       83.00    0.83\n",
      " 37    4000           0.36       83.26    0.83\n",
      " 46    4200           0.27       83.40    0.83\n",
      " 56    4400           0.20       83.40    0.83\n",
      " 69    4600           0.15       83.20    0.83\n",
      " 85    4800           0.11       82.89    0.83\n",
      "104    5000           0.08       82.82    0.83\n",
      "127    5200           0.06       82.55    0.83\n",
      "155    5400           0.05       82.54    0.83\n",
      "188    5600           0.03       82.67    0.83\n",
      "221    5800           0.03       83.19    0.83\n",
      "255    6000           0.02       83.19    0.83\n",
      "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
      "/Users/eric/Dev/quantify-news/models/sent_relevance/model-last\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-20 13:54:19,326 - git.cmd - DEBUG - Popen(['git', 'cat-file', '--batch-check'], cwd=/Users/eric/Dev/quantify-news, stdin=<valid stream>, shell=False, universal_newlines=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 69.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-20 13:54:19,370 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 13:54:19,408 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"POST /api/2.0/mlflow/runs/create HTTP/1.1\" 200 1074\n",
      "2025-03-20 13:54:19,422 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 13:54:19,495 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"POST /api/2.0/mlflow/runs/log-batch HTTP/1.1\" 200 2\n",
      "2025-03-20 13:54:19,507 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 13:54:19,530 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"POST /api/2.0/mlflow/runs/log-batch HTTP/1.1\" 200 2\n",
      "\u001b[31m2025/03/20 13:54:27 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "2025-03-20 13:54:27,444 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 13:54:27,489 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"GET /api/2.0/mlflow/runs/get?run_uuid=c1095f3fdda14487988173bad7746741&run_id=c1095f3fdda14487988173bad7746741 HTTP/1.1\" 200 12950\n",
      "2025-03-20 13:54:27,523 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 13:54:27,533 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"POST /api/2.0/mlflow/runs/log-model HTTP/1.1\" 200 2\n",
      "2025-03-20 13:54:27,573 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 13:54:27,620 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"GET /api/2.0/mlflow/runs/get?run_uuid=c1095f3fdda14487988173bad7746741&run_id=c1095f3fdda14487988173bad7746741 HTTP/1.1\" 200 13533\n",
      "2025-03-20 13:54:27,630 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 13:54:27,637 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"POST /api/2.0/mlflow/runs/update HTTP/1.1\" 200 470\n",
      "[I 2025-03-20 13:54:27,673] Trial 40 finished with value: 0.5389594676 and parameters: {'training.batcher.size.start': 10}. Best is trial 7 with value: 0.5532451819.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run optuna_trial_40 at: http://127.0.0.1:8080/#/experiments/485071347047209202/runs/c1095f3fdda14487988173bad7746741\n",
      "🧪 View experiment at: http://127.0.0.1:8080/#/experiments/485071347047209202\n",
      "Training with overrides:\n",
      " {'training.batcher.size.start': 26}\n",
      "\u001b[38;5;2m✔ Auto-filled config with all values\u001b[0m\n",
      "\u001b[38;5;2m✔ Saved config\u001b[0m\n",
      "/Users/eric/Dev/quantify-news/scripts/sent_relevance/spacy_config.cfg\n",
      "You can now add your data and train your pipeline:\n",
      "python -m spacy train spacy_config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n",
      "\u001b[38;5;4mℹ Saving to output directory:\n",
      "/Users/eric/Dev/quantify-news/models/sent_relevance\u001b[0m\n",
      "\u001b[38;5;4mℹ Using CPU\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "[2025-03-20 13:54:32,851] [WARNING] [W112] The model specified to use for initial vectors (en_core_web_sm) has no vectors. This is almost certainly a mistake.\n",
      "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "\u001b[38;5;4mℹ Pipeline: ['textcat_multilabel']\u001b[0m\n",
      "\u001b[38;5;4mℹ Initial learn rate: 0.001\u001b[0m\n",
      "E    #       LOSS TEXTC...  CATS_SCORE  SCORE \n",
      "---  ------  -------------  ----------  ------\n",
      "  0       0           0.25       71.43    0.71\n",
      "  0     200          38.99       60.07    0.60\n",
      "  1     400          25.62       64.12    0.64\n",
      "  2     600          19.68       71.07    0.71\n",
      "  4     800          12.30       75.68    0.76\n",
      "  5    1000           8.26       79.59    0.80\n",
      "  7    1200           5.38       82.12    0.82\n",
      " 10    1400           3.70       81.70    0.82\n",
      " 13    1600           2.54       82.64    0.83\n",
      " 18    1800           1.81       82.99    0.83\n",
      " 23    2000           1.34       82.91    0.83\n",
      " 29    2200           0.92       82.98    0.83\n",
      " 37    2400           0.66       83.18    0.83\n",
      " 47    2600           0.46       83.64    0.84\n",
      " 59    2800           0.34       83.57    0.84\n",
      " 73    3000           0.25       83.70    0.84\n",
      " 91    3200           0.18       83.70    0.84\n",
      "113    3400           0.13       83.20    0.83\n",
      "139    3600           0.10       83.78    0.84\n",
      "171    3800           0.07       83.65    0.84\n",
      "205    4000           0.05       83.44    0.83\n",
      "238    4200           0.04       82.99    0.83\n",
      "271    4400           0.03       82.92    0.83\n",
      "305    4600           0.03       83.05    0.83\n",
      "338    4800           0.02       83.05    0.83\n",
      "371    5000           0.02       83.05    0.83\n",
      "405    5200           0.02       82.99    0.83\n",
      "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
      "/Users/eric/Dev/quantify-news/models/sent_relevance/model-last\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-20 13:55:39,070 - git.cmd - DEBUG - Popen(['git', 'cat-file', '--batch-check'], cwd=/Users/eric/Dev/quantify-news, stdin=<valid stream>, shell=False, universal_newlines=False)\n",
      "2025-03-20 13:55:39,122 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 13:55:39,159 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"POST /api/2.0/mlflow/runs/create HTTP/1.1\" 200 1074\n",
      "2025-03-20 13:55:39,172 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 13:55:39,242 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"POST /api/2.0/mlflow/runs/log-batch HTTP/1.1\" 200 2\n",
      "2025-03-20 13:55:39,253 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 69.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-20 13:55:39,291 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"POST /api/2.0/mlflow/runs/log-batch HTTP/1.1\" 200 2\n",
      "\u001b[31m2025/03/20 13:55:48 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "2025-03-20 13:55:48,856 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 13:55:48,910 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"GET /api/2.0/mlflow/runs/get?run_uuid=38e32c1f943c4c5dbd82ae1d8c63d5c1&run_id=38e32c1f943c4c5dbd82ae1d8c63d5c1 HTTP/1.1\" 200 12950\n",
      "2025-03-20 13:55:48,946 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 13:55:48,956 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"POST /api/2.0/mlflow/runs/log-model HTTP/1.1\" 200 2\n",
      "2025-03-20 13:55:48,984 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 13:55:49,025 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"GET /api/2.0/mlflow/runs/get?run_uuid=38e32c1f943c4c5dbd82ae1d8c63d5c1&run_id=38e32c1f943c4c5dbd82ae1d8c63d5c1 HTTP/1.1\" 200 13533\n",
      "2025-03-20 13:55:49,037 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 13:55:49,045 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"POST /api/2.0/mlflow/runs/update HTTP/1.1\" 200 470\n",
      "[I 2025-03-20 13:55:49,085] Trial 41 finished with value: 0.5389594676 and parameters: {'training.batcher.size.start': 26}. Best is trial 7 with value: 0.5532451819.\n",
      "2025-03-20 13:55:49,097 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 13:55:49,108 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"GET /api/2.0/mlflow/runs/get?run_uuid=06bd48db33a245e2a747dcda59201d30&run_id=06bd48db33a245e2a747dcda59201d30 HTTP/1.1\" 200 970\n",
      "2025-03-20 13:55:49,119 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 13:55:49,129 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"POST /api/2.0/mlflow/runs/update HTTP/1.1\" 200 475\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run optuna_trial_41 at: http://127.0.0.1:8080/#/experiments/485071347047209202/runs/38e32c1f943c4c5dbd82ae1d8c63d5c1\n",
      "🧪 View experiment at: http://127.0.0.1:8080/#/experiments/485071347047209202\n",
      "🏃 View run opt_batch_start_size at: http://127.0.0.1:8080/#/experiments/485071347047209202/runs/06bd48db33a245e2a747dcda59201d30\n",
      "🧪 View experiment at: http://127.0.0.1:8080/#/experiments/485071347047209202\n"
     ]
    }
   ],
   "source": [
    "# Note: as currently configured, the optuna_db goes into the caller notebook folder\n",
    "with mlflow.start_run(run_name=\"opt_batch_start_size\"):\n",
    "    study.optimize(objective, n_trials=10, callbacks=[archiver])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp = \"paths.vectors\"\n",
    "hyperparams.add(hp)\n",
    "\n",
    "def objective(trial):\n",
    "    base_model = trial.suggest_categorical(hp, [\"en_core_web_sm\", \"en_core_web_md\"])\n",
    "    overrides = {hp: base_model} | best_params(hyperparams)\n",
    "    return objective_base(trial, overrides)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-20 13:55:49,571 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 13:55:49,599 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"POST /api/2.0/mlflow/runs/create HTTP/1.1\" 200 958\n",
      "2025-03-20 13:55:49,653 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 13:55:49,674 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"GET /api/2.0/mlflow/experiments/get-by-name?experiment_name=sent_relevance_models HTTP/1.1\" 200 600\n",
      "2025-03-20 13:55:49,683 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 13:55:50,034 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"POST /api/2.0/mlflow/runs/search HTTP/1.1\" 200 14683\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with overrides:\n",
      " {'paths.vectors': 'en_core_web_sm', 'training.batcher.size.start': '17'}\n",
      "\u001b[38;5;2m✔ Auto-filled config with all values\u001b[0m\n",
      "\u001b[38;5;2m✔ Saved config\u001b[0m\n",
      "/Users/eric/Dev/quantify-news/scripts/sent_relevance/spacy_config.cfg\n",
      "You can now add your data and train your pipeline:\n",
      "python -m spacy train spacy_config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n",
      "\u001b[38;5;4mℹ Saving to output directory:\n",
      "/Users/eric/Dev/quantify-news/models/sent_relevance\u001b[0m\n",
      "\u001b[38;5;4mℹ Using CPU\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "[2025-03-20 13:55:55,420] [WARNING] [W112] The model specified to use for initial vectors (en_core_web_sm) has no vectors. This is almost certainly a mistake.\n",
      "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "\u001b[38;5;4mℹ Pipeline: ['textcat_multilabel']\u001b[0m\n",
      "\u001b[38;5;4mℹ Initial learn rate: 0.001\u001b[0m\n",
      "E    #       LOSS TEXTC...  CATS_SCORE  SCORE \n",
      "---  ------  -------------  ----------  ------\n",
      "  0       0           0.25       71.43    0.71\n",
      "  0     200          40.32       59.18    0.59\n",
      "  1     400          25.98       62.87    0.63\n",
      "  2     600          22.77       70.11    0.70\n",
      "  3     800          15.34       73.57    0.74\n",
      "  4    1000          10.67       75.39    0.75\n",
      "  5    1200           7.77       78.65    0.79\n",
      "  6    1400           5.52       81.00    0.81\n",
      "  8    1600           4.01       82.35    0.82\n",
      " 10    1800           3.16       81.84    0.82\n",
      " 13    2000           2.18       82.47    0.82\n",
      " 17    2200           1.64       82.40    0.82\n",
      " 21    2400           1.21       83.12    0.83\n",
      " 26    2600           0.86       83.26    0.83\n",
      " 33    2800           0.64       82.81    0.83\n",
      " 42    3000           0.44       82.99    0.83\n",
      " 52    3200           0.34       83.20    0.83\n",
      " 65    3400           0.25       83.33    0.83\n",
      " 80    3600           0.18       83.06    0.83\n",
      " 99    3800           0.13       83.20    0.83\n",
      "122    4000           0.10       83.20    0.83\n",
      "150    4200           0.07       83.72    0.84\n",
      "183    4400           0.05       83.57    0.84\n",
      "216    4600           0.04       82.92    0.83\n",
      "250    4800           0.03       82.92    0.83\n",
      "283    5000           0.03       82.86    0.83\n",
      "316    5200           0.02       82.86    0.83\n",
      "350    5400           0.02       83.06    0.83\n",
      "383    5600           0.02       83.13    0.83\n",
      "416    5800           0.01       83.13    0.83\n",
      "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
      "/Users/eric/Dev/quantify-news/models/sent_relevance/model-last\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-20 13:57:05,728 - git.cmd - DEBUG - Popen(['git', 'cat-file', '--batch-check'], cwd=/Users/eric/Dev/quantify-news, stdin=<valid stream>, shell=False, universal_newlines=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 73.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-20 13:57:05,761 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 13:57:05,787 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"POST /api/2.0/mlflow/runs/create HTTP/1.1\" 200 1074\n",
      "2025-03-20 13:57:05,798 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 13:57:05,858 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"POST /api/2.0/mlflow/runs/log-batch HTTP/1.1\" 200 2\n",
      "2025-03-20 13:57:05,867 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 13:57:05,885 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"POST /api/2.0/mlflow/runs/log-batch HTTP/1.1\" 200 2\n",
      "\u001b[31m2025/03/20 13:57:13 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "2025-03-20 13:57:13,800 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 13:57:13,850 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"GET /api/2.0/mlflow/runs/get?run_uuid=a914aa71fe264a62a78d40ebec0365be&run_id=a914aa71fe264a62a78d40ebec0365be HTTP/1.1\" 200 12950\n",
      "2025-03-20 13:57:13,881 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 13:57:13,889 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"POST /api/2.0/mlflow/runs/log-model HTTP/1.1\" 200 2\n",
      "2025-03-20 13:57:13,943 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 13:57:13,980 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"GET /api/2.0/mlflow/runs/get?run_uuid=a914aa71fe264a62a78d40ebec0365be&run_id=a914aa71fe264a62a78d40ebec0365be HTTP/1.1\" 200 13533\n",
      "2025-03-20 13:57:13,990 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 13:57:13,999 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"POST /api/2.0/mlflow/runs/update HTTP/1.1\" 200 470\n",
      "[I 2025-03-20 13:57:14,030] Trial 42 finished with value: 0.5532451819 and parameters: {'paths.vectors': 'en_core_web_sm'}. Best is trial 7 with value: 0.5532451819.\n",
      "2025-03-20 13:57:14,069 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 13:57:14,080 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"GET /api/2.0/mlflow/experiments/get-by-name?experiment_name=sent_relevance_models HTTP/1.1\" 200 600\n",
      "2025-03-20 13:57:14,086 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run optuna_trial_42 at: http://127.0.0.1:8080/#/experiments/485071347047209202/runs/a914aa71fe264a62a78d40ebec0365be\n",
      "🧪 View experiment at: http://127.0.0.1:8080/#/experiments/485071347047209202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-20 13:57:14,352 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"POST /api/2.0/mlflow/runs/search HTTP/1.1\" 200 14683\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with overrides:\n",
      " {'paths.vectors': 'en_core_web_sm', 'training.batcher.size.start': '17'}\n",
      "\u001b[38;5;2m✔ Auto-filled config with all values\u001b[0m\n",
      "\u001b[38;5;2m✔ Saved config\u001b[0m\n",
      "/Users/eric/Dev/quantify-news/scripts/sent_relevance/spacy_config.cfg\n",
      "You can now add your data and train your pipeline:\n",
      "python -m spacy train spacy_config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n",
      "\u001b[38;5;4mℹ Saving to output directory:\n",
      "/Users/eric/Dev/quantify-news/models/sent_relevance\u001b[0m\n",
      "\u001b[38;5;4mℹ Using CPU\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "[2025-03-20 13:57:19,347] [WARNING] [W112] The model specified to use for initial vectors (en_core_web_sm) has no vectors. This is almost certainly a mistake.\n",
      "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "\u001b[38;5;4mℹ Pipeline: ['textcat_multilabel']\u001b[0m\n",
      "\u001b[38;5;4mℹ Initial learn rate: 0.001\u001b[0m\n",
      "E    #       LOSS TEXTC...  CATS_SCORE  SCORE \n",
      "---  ------  -------------  ----------  ------\n",
      "  0       0           0.25       71.43    0.71\n",
      "  0     200          40.32       59.18    0.59\n",
      "  1     400          25.98       62.87    0.63\n",
      "  2     600          22.77       70.11    0.70\n",
      "  3     800          15.34       73.57    0.74\n",
      "  4    1000          10.67       75.39    0.75\n",
      "  5    1200           7.77       78.65    0.79\n",
      "  6    1400           5.52       81.00    0.81\n",
      "  8    1600           4.01       82.35    0.82\n",
      " 10    1800           3.16       81.84    0.82\n",
      " 13    2000           2.18       82.47    0.82\n",
      " 17    2200           1.64       82.40    0.82\n",
      " 21    2400           1.21       83.12    0.83\n",
      " 26    2600           0.86       83.26    0.83\n",
      " 33    2800           0.64       82.81    0.83\n",
      " 42    3000           0.44       82.99    0.83\n",
      " 52    3200           0.34       83.20    0.83\n",
      " 65    3400           0.25       83.33    0.83\n",
      " 80    3600           0.18       83.06    0.83\n",
      " 99    3800           0.13       83.20    0.83\n",
      "122    4000           0.10       83.20    0.83\n",
      "150    4200           0.07       83.72    0.84\n",
      "183    4400           0.05       83.57    0.84\n",
      "216    4600           0.04       82.92    0.83\n",
      "250    4800           0.03       82.92    0.83\n",
      "283    5000           0.03       82.86    0.83\n",
      "316    5200           0.02       82.86    0.83\n",
      "350    5400           0.02       83.06    0.83\n",
      "383    5600           0.02       83.13    0.83\n",
      "416    5800           0.01       83.13    0.83\n",
      "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
      "/Users/eric/Dev/quantify-news/models/sent_relevance/model-last\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-20 13:58:27,431 - git.cmd - DEBUG - Popen(['git', 'cat-file', '--batch-check'], cwd=/Users/eric/Dev/quantify-news, stdin=<valid stream>, shell=False, universal_newlines=False)\n",
      "2025-03-20 13:58:27,463 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 70.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-20 13:58:27,494 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"POST /api/2.0/mlflow/runs/create HTTP/1.1\" 200 1074\n",
      "2025-03-20 13:58:27,506 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 13:58:27,573 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"POST /api/2.0/mlflow/runs/log-batch HTTP/1.1\" 200 2\n",
      "2025-03-20 13:58:27,582 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 13:58:27,606 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"POST /api/2.0/mlflow/runs/log-batch HTTP/1.1\" 200 2\n",
      "\u001b[31m2025/03/20 13:58:35 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "2025-03-20 13:58:35,539 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 13:58:35,574 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"GET /api/2.0/mlflow/runs/get?run_uuid=69f84d27710c4cd7a5846b00fd9622ac&run_id=69f84d27710c4cd7a5846b00fd9622ac HTTP/1.1\" 200 12950\n",
      "2025-03-20 13:58:35,600 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 13:58:35,609 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"POST /api/2.0/mlflow/runs/log-model HTTP/1.1\" 200 2\n",
      "2025-03-20 13:58:35,632 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 13:58:35,665 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"GET /api/2.0/mlflow/runs/get?run_uuid=69f84d27710c4cd7a5846b00fd9622ac&run_id=69f84d27710c4cd7a5846b00fd9622ac HTTP/1.1\" 200 13533\n",
      "2025-03-20 13:58:35,676 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 13:58:35,683 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"POST /api/2.0/mlflow/runs/update HTTP/1.1\" 200 470\n",
      "[I 2025-03-20 13:58:35,711] Trial 43 finished with value: 0.5532451819 and parameters: {'paths.vectors': 'en_core_web_sm'}. Best is trial 7 with value: 0.5532451819.\n",
      "2025-03-20 13:58:35,718 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 13:58:35,727 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"GET /api/2.0/mlflow/runs/get?run_uuid=9f95f7377df34fc98e6530ea4349577a&run_id=9f95f7377df34fc98e6530ea4349577a HTTP/1.1\" 200 958\n",
      "2025-03-20 13:58:35,733 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 13:58:35,740 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"POST /api/2.0/mlflow/runs/update HTTP/1.1\" 200 469\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run optuna_trial_43 at: http://127.0.0.1:8080/#/experiments/485071347047209202/runs/69f84d27710c4cd7a5846b00fd9622ac\n",
      "🧪 View experiment at: http://127.0.0.1:8080/#/experiments/485071347047209202\n",
      "🏃 View run opt_base_model at: http://127.0.0.1:8080/#/experiments/485071347047209202/runs/9f95f7377df34fc98e6530ea4349577a\n",
      "🧪 View experiment at: http://127.0.0.1:8080/#/experiments/485071347047209202\n"
     ]
    }
   ],
   "source": [
    "# Note: as currently configured, the optuna_db goes into the caller of create_study ie the notebook\n",
    "with mlflow.start_run(run_name=\"opt_base_model\"):\n",
    "    study.optimize(objective, n_trials=2, callbacks=[archiver])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bow Length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp = \"components.textcat_multilabel.model.length\"\n",
    "hyperparams.add(hp)\n",
    "\n",
    "def objective(trial: optuna.trial.Trial):\n",
    "    length = trial.suggest_int(hp, 1, 18)\n",
    "    overrides = ({hp: 2**length} |\n",
    "                best_params(hyperparams))\n",
    "    return objective_base(trial, overrides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-20 13:58:36,093 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 13:58:36,116 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"POST /api/2.0/mlflow/runs/create HTTP/1.1\" 200 964\n",
      "2025-03-20 13:58:36,163 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 13:58:36,172 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"GET /api/2.0/mlflow/experiments/get-by-name?experiment_name=sent_relevance_models HTTP/1.1\" 200 600\n",
      "2025-03-20 13:58:36,179 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 13:58:36,508 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"POST /api/2.0/mlflow/runs/search HTTP/1.1\" 200 14683\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with overrides:\n",
      " {'components.textcat_multilabel.model.length': '262144', 'training.batcher.size.start': '17', 'paths.vectors': 'en_core_web_sm'}\n",
      "\u001b[38;5;2m✔ Auto-filled config with all values\u001b[0m\n",
      "\u001b[38;5;2m✔ Saved config\u001b[0m\n",
      "/Users/eric/Dev/quantify-news/scripts/sent_relevance/spacy_config.cfg\n",
      "You can now add your data and train your pipeline:\n",
      "python -m spacy train spacy_config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n",
      "\u001b[38;5;4mℹ Saving to output directory:\n",
      "/Users/eric/Dev/quantify-news/models/sent_relevance\u001b[0m\n",
      "\u001b[38;5;4mℹ Using CPU\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "[2025-03-20 13:58:41,915] [WARNING] [W112] The model specified to use for initial vectors (en_core_web_sm) has no vectors. This is almost certainly a mistake.\n",
      "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "\u001b[38;5;4mℹ Pipeline: ['textcat_multilabel']\u001b[0m\n",
      "\u001b[38;5;4mℹ Initial learn rate: 0.001\u001b[0m\n",
      "E    #       LOSS TEXTC...  CATS_SCORE  SCORE \n",
      "---  ------  -------------  ----------  ------\n",
      "  0       0           0.25       71.43    0.71\n",
      "  0     200          40.32       59.18    0.59\n",
      "  1     400          25.98       62.87    0.63\n",
      "  2     600          22.77       70.11    0.70\n",
      "  3     800          15.34       73.57    0.74\n",
      "  4    1000          10.67       75.39    0.75\n",
      "  5    1200           7.77       78.65    0.79\n",
      "  6    1400           5.52       81.00    0.81\n",
      "  8    1600           4.01       82.35    0.82\n",
      " 10    1800           3.16       81.84    0.82\n",
      " 13    2000           2.18       82.47    0.82\n",
      " 17    2200           1.64       82.40    0.82\n",
      " 21    2400           1.21       83.12    0.83\n",
      " 26    2600           0.86       83.26    0.83\n",
      " 33    2800           0.64       82.81    0.83\n",
      " 42    3000           0.44       82.99    0.83\n",
      " 52    3200           0.34       83.20    0.83\n",
      " 65    3400           0.25       83.33    0.83\n",
      " 80    3600           0.18       83.06    0.83\n",
      " 99    3800           0.13       83.20    0.83\n",
      "122    4000           0.10       83.20    0.83\n",
      "150    4200           0.07       83.72    0.84\n",
      "183    4400           0.05       83.57    0.84\n",
      "216    4600           0.04       82.92    0.83\n",
      "250    4800           0.03       82.92    0.83\n",
      "283    5000           0.03       82.86    0.83\n",
      "316    5200           0.02       82.86    0.83\n",
      "350    5400           0.02       83.06    0.83\n",
      "383    5600           0.02       83.13    0.83\n",
      "416    5800           0.01       83.13    0.83\n",
      "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
      "/Users/eric/Dev/quantify-news/models/sent_relevance/model-last\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-20 13:59:51,191 - git.cmd - DEBUG - Popen(['git', 'cat-file', '--batch-check'], cwd=/Users/eric/Dev/quantify-news, stdin=<valid stream>, shell=False, universal_newlines=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 72.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-20 13:59:51,230 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 13:59:51,260 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"POST /api/2.0/mlflow/runs/create HTTP/1.1\" 200 1074\n",
      "2025-03-20 13:59:51,274 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 13:59:51,350 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"POST /api/2.0/mlflow/runs/log-batch HTTP/1.1\" 200 2\n",
      "2025-03-20 13:59:51,360 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 13:59:51,378 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"POST /api/2.0/mlflow/runs/log-batch HTTP/1.1\" 200 2\n",
      "\u001b[31m2025/03/20 13:59:59 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "2025-03-20 13:59:59,397 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 13:59:59,434 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"GET /api/2.0/mlflow/runs/get?run_uuid=f79dae01650849d4997098fb9853af19&run_id=f79dae01650849d4997098fb9853af19 HTTP/1.1\" 200 12950\n",
      "2025-03-20 13:59:59,460 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 13:59:59,467 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"POST /api/2.0/mlflow/runs/log-model HTTP/1.1\" 200 2\n",
      "2025-03-20 13:59:59,497 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 13:59:59,531 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"GET /api/2.0/mlflow/runs/get?run_uuid=f79dae01650849d4997098fb9853af19&run_id=f79dae01650849d4997098fb9853af19 HTTP/1.1\" 200 13533\n",
      "2025-03-20 13:59:59,541 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 13:59:59,549 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"POST /api/2.0/mlflow/runs/update HTTP/1.1\" 200 470\n",
      "[I 2025-03-20 13:59:59,579] Trial 44 finished with value: 0.5532451819 and parameters: {'components.textcat_multilabel.model.length': 12}. Best is trial 7 with value: 0.5532451819.\n",
      "2025-03-20 13:59:59,622 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 13:59:59,632 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"GET /api/2.0/mlflow/experiments/get-by-name?experiment_name=sent_relevance_models HTTP/1.1\" 200 600\n",
      "2025-03-20 13:59:59,638 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run optuna_trial_44 at: http://127.0.0.1:8080/#/experiments/485071347047209202/runs/f79dae01650849d4997098fb9853af19\n",
      "🧪 View experiment at: http://127.0.0.1:8080/#/experiments/485071347047209202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-20 13:59:59,964 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"POST /api/2.0/mlflow/runs/search HTTP/1.1\" 200 14683\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with overrides:\n",
      " {'components.textcat_multilabel.model.length': '262144', 'training.batcher.size.start': '17', 'paths.vectors': 'en_core_web_sm'}\n",
      "\u001b[38;5;2m✔ Auto-filled config with all values\u001b[0m\n",
      "\u001b[38;5;2m✔ Saved config\u001b[0m\n",
      "/Users/eric/Dev/quantify-news/scripts/sent_relevance/spacy_config.cfg\n",
      "You can now add your data and train your pipeline:\n",
      "python -m spacy train spacy_config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n",
      "\u001b[38;5;4mℹ Saving to output directory:\n",
      "/Users/eric/Dev/quantify-news/models/sent_relevance\u001b[0m\n",
      "\u001b[38;5;4mℹ Using CPU\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "[2025-03-20 14:00:04,977] [WARNING] [W112] The model specified to use for initial vectors (en_core_web_sm) has no vectors. This is almost certainly a mistake.\n",
      "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "\u001b[38;5;4mℹ Pipeline: ['textcat_multilabel']\u001b[0m\n",
      "\u001b[38;5;4mℹ Initial learn rate: 0.001\u001b[0m\n",
      "E    #       LOSS TEXTC...  CATS_SCORE  SCORE \n",
      "---  ------  -------------  ----------  ------\n",
      "  0       0           0.25       71.43    0.71\n",
      "  0     200          40.32       59.18    0.59\n",
      "  1     400          25.98       62.87    0.63\n",
      "  2     600          22.77       70.11    0.70\n",
      "  3     800          15.34       73.57    0.74\n",
      "  4    1000          10.67       75.39    0.75\n",
      "  5    1200           7.77       78.65    0.79\n",
      "  6    1400           5.52       81.00    0.81\n",
      "  8    1600           4.01       82.35    0.82\n",
      " 10    1800           3.16       81.84    0.82\n",
      " 13    2000           2.18       82.47    0.82\n",
      " 17    2200           1.64       82.40    0.82\n",
      " 21    2400           1.21       83.12    0.83\n",
      " 26    2600           0.86       83.26    0.83\n",
      " 33    2800           0.64       82.81    0.83\n",
      " 42    3000           0.44       82.99    0.83\n",
      " 52    3200           0.34       83.20    0.83\n",
      " 65    3400           0.25       83.33    0.83\n",
      " 80    3600           0.18       83.06    0.83\n",
      " 99    3800           0.13       83.20    0.83\n",
      "122    4000           0.10       83.20    0.83\n",
      "150    4200           0.07       83.72    0.84\n",
      "183    4400           0.05       83.57    0.84\n",
      "216    4600           0.04       82.92    0.83\n",
      "250    4800           0.03       82.92    0.83\n",
      "283    5000           0.03       82.86    0.83\n",
      "316    5200           0.02       82.86    0.83\n",
      "350    5400           0.02       83.06    0.83\n",
      "383    5600           0.02       83.13    0.83\n",
      "416    5800           0.01       83.13    0.83\n",
      "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
      "/Users/eric/Dev/quantify-news/models/sent_relevance/model-last\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-20 14:01:14,691 - git.cmd - DEBUG - Popen(['git', 'cat-file', '--batch-check'], cwd=/Users/eric/Dev/quantify-news, stdin=<valid stream>, shell=False, universal_newlines=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 72.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-20 14:01:14,728 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 14:01:14,769 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"POST /api/2.0/mlflow/runs/create HTTP/1.1\" 200 1074\n",
      "2025-03-20 14:01:14,780 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 14:01:14,852 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"POST /api/2.0/mlflow/runs/log-batch HTTP/1.1\" 200 2\n",
      "2025-03-20 14:01:14,863 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 14:01:14,885 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"POST /api/2.0/mlflow/runs/log-batch HTTP/1.1\" 200 2\n",
      "\u001b[31m2025/03/20 14:01:23 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "2025-03-20 14:01:23,945 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 14:01:23,984 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"GET /api/2.0/mlflow/runs/get?run_uuid=242d54f7cfa24e578878ac90cd7d5a79&run_id=242d54f7cfa24e578878ac90cd7d5a79 HTTP/1.1\" 200 12950\n",
      "2025-03-20 14:01:24,014 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 14:01:24,022 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"POST /api/2.0/mlflow/runs/log-model HTTP/1.1\" 200 2\n",
      "2025-03-20 14:01:24,086 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 14:01:24,124 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"GET /api/2.0/mlflow/runs/get?run_uuid=242d54f7cfa24e578878ac90cd7d5a79&run_id=242d54f7cfa24e578878ac90cd7d5a79 HTTP/1.1\" 200 13533\n",
      "2025-03-20 14:01:24,134 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 14:01:24,140 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"POST /api/2.0/mlflow/runs/update HTTP/1.1\" 200 470\n",
      "[I 2025-03-20 14:01:24,173] Trial 45 finished with value: 0.5532451819 and parameters: {'components.textcat_multilabel.model.length': 4}. Best is trial 7 with value: 0.5532451819.\n",
      "2025-03-20 14:01:24,221 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 14:01:24,233 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"GET /api/2.0/mlflow/experiments/get-by-name?experiment_name=sent_relevance_models HTTP/1.1\" 200 600\n",
      "2025-03-20 14:01:24,241 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run optuna_trial_45 at: http://127.0.0.1:8080/#/experiments/485071347047209202/runs/242d54f7cfa24e578878ac90cd7d5a79\n",
      "🧪 View experiment at: http://127.0.0.1:8080/#/experiments/485071347047209202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-20 14:01:24,961 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"POST /api/2.0/mlflow/runs/search HTTP/1.1\" 200 14683\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with overrides:\n",
      " {'components.textcat_multilabel.model.length': '262144', 'training.batcher.size.start': '17', 'paths.vectors': 'en_core_web_sm'}\n",
      "\u001b[38;5;2m✔ Auto-filled config with all values\u001b[0m\n",
      "\u001b[38;5;2m✔ Saved config\u001b[0m\n",
      "/Users/eric/Dev/quantify-news/scripts/sent_relevance/spacy_config.cfg\n",
      "You can now add your data and train your pipeline:\n",
      "python -m spacy train spacy_config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n",
      "\u001b[38;5;4mℹ Saving to output directory:\n",
      "/Users/eric/Dev/quantify-news/models/sent_relevance\u001b[0m\n",
      "\u001b[38;5;4mℹ Using CPU\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "[2025-03-20 14:01:30,201] [WARNING] [W112] The model specified to use for initial vectors (en_core_web_sm) has no vectors. This is almost certainly a mistake.\n",
      "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "\u001b[38;5;4mℹ Pipeline: ['textcat_multilabel']\u001b[0m\n",
      "\u001b[38;5;4mℹ Initial learn rate: 0.001\u001b[0m\n",
      "E    #       LOSS TEXTC...  CATS_SCORE  SCORE \n",
      "---  ------  -------------  ----------  ------\n",
      "  0       0           0.25       71.43    0.71\n",
      "  0     200          40.32       59.18    0.59\n",
      "  1     400          25.98       62.87    0.63\n",
      "  2     600          22.77       70.11    0.70\n",
      "  3     800          15.34       73.57    0.74\n",
      "  4    1000          10.67       75.39    0.75\n",
      "  5    1200           7.77       78.65    0.79\n",
      "  6    1400           5.52       81.00    0.81\n",
      "  8    1600           4.01       82.35    0.82\n",
      " 10    1800           3.16       81.84    0.82\n",
      " 13    2000           2.18       82.47    0.82\n",
      " 17    2200           1.64       82.40    0.82\n",
      " 21    2400           1.21       83.12    0.83\n",
      " 26    2600           0.86       83.26    0.83\n",
      " 33    2800           0.64       82.81    0.83\n",
      " 42    3000           0.44       82.99    0.83\n",
      " 52    3200           0.34       83.20    0.83\n",
      " 65    3400           0.25       83.33    0.83\n",
      " 80    3600           0.18       83.06    0.83\n",
      " 99    3800           0.13       83.20    0.83\n",
      "122    4000           0.10       83.20    0.83\n",
      "150    4200           0.07       83.72    0.84\n",
      "183    4400           0.05       83.57    0.84\n",
      "216    4600           0.04       82.92    0.83\n",
      "250    4800           0.03       82.92    0.83\n",
      "283    5000           0.03       82.86    0.83\n",
      "316    5200           0.02       82.86    0.83\n",
      "350    5400           0.02       83.06    0.83\n",
      "383    5600           0.02       83.13    0.83\n",
      "416    5800           0.01       83.13    0.83\n",
      "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
      "/Users/eric/Dev/quantify-news/models/sent_relevance/model-last\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-20 14:02:37,775 - git.cmd - DEBUG - Popen(['git', 'cat-file', '--batch-check'], cwd=/Users/eric/Dev/quantify-news, stdin=<valid stream>, shell=False, universal_newlines=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 70.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-20 14:02:37,841 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 14:02:38,006 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"POST /api/2.0/mlflow/runs/create HTTP/1.1\" 200 1074\n",
      "2025-03-20 14:02:38,023 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 14:02:38,099 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"POST /api/2.0/mlflow/runs/log-batch HTTP/1.1\" 200 2\n",
      "2025-03-20 14:02:38,111 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 14:02:38,134 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"POST /api/2.0/mlflow/runs/log-batch HTTP/1.1\" 200 2\n",
      "\u001b[31m2025/03/20 14:02:47 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "2025-03-20 14:02:47,062 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 14:02:47,139 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"GET /api/2.0/mlflow/runs/get?run_uuid=bb495a2fc38241ecbed70aa8bc6e2bda&run_id=bb495a2fc38241ecbed70aa8bc6e2bda HTTP/1.1\" 200 12950\n",
      "2025-03-20 14:02:47,165 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 14:02:47,174 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"POST /api/2.0/mlflow/runs/log-model HTTP/1.1\" 200 2\n",
      "2025-03-20 14:02:47,204 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 14:02:47,241 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"GET /api/2.0/mlflow/runs/get?run_uuid=bb495a2fc38241ecbed70aa8bc6e2bda&run_id=bb495a2fc38241ecbed70aa8bc6e2bda HTTP/1.1\" 200 13533\n",
      "2025-03-20 14:02:47,251 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 14:02:47,259 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"POST /api/2.0/mlflow/runs/update HTTP/1.1\" 200 470\n",
      "[I 2025-03-20 14:02:47,293] Trial 46 finished with value: 0.5532451819 and parameters: {'components.textcat_multilabel.model.length': 5}. Best is trial 7 with value: 0.5532451819.\n",
      "2025-03-20 14:02:47,339 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 14:02:47,350 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"GET /api/2.0/mlflow/experiments/get-by-name?experiment_name=sent_relevance_models HTTP/1.1\" 200 600\n",
      "2025-03-20 14:02:47,359 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run optuna_trial_46 at: http://127.0.0.1:8080/#/experiments/485071347047209202/runs/bb495a2fc38241ecbed70aa8bc6e2bda\n",
      "🧪 View experiment at: http://127.0.0.1:8080/#/experiments/485071347047209202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-20 14:02:48,197 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"POST /api/2.0/mlflow/runs/search HTTP/1.1\" 200 14683\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with overrides:\n",
      " {'components.textcat_multilabel.model.length': '262144', 'training.batcher.size.start': '17', 'paths.vectors': 'en_core_web_sm'}\n",
      "\u001b[38;5;2m✔ Auto-filled config with all values\u001b[0m\n",
      "\u001b[38;5;2m✔ Saved config\u001b[0m\n",
      "/Users/eric/Dev/quantify-news/scripts/sent_relevance/spacy_config.cfg\n",
      "You can now add your data and train your pipeline:\n",
      "python -m spacy train spacy_config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n",
      "\u001b[38;5;4mℹ Saving to output directory:\n",
      "/Users/eric/Dev/quantify-news/models/sent_relevance\u001b[0m\n",
      "\u001b[38;5;4mℹ Using CPU\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "[2025-03-20 14:02:53,631] [WARNING] [W112] The model specified to use for initial vectors (en_core_web_sm) has no vectors. This is almost certainly a mistake.\n",
      "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "\u001b[38;5;4mℹ Pipeline: ['textcat_multilabel']\u001b[0m\n",
      "\u001b[38;5;4mℹ Initial learn rate: 0.001\u001b[0m\n",
      "E    #       LOSS TEXTC...  CATS_SCORE  SCORE \n",
      "---  ------  -------------  ----------  ------\n",
      "  0       0           0.25       71.43    0.71\n",
      "  0     200          40.32       59.18    0.59\n",
      "  1     400          25.98       62.87    0.63\n",
      "  2     600          22.77       70.11    0.70\n",
      "  3     800          15.34       73.57    0.74\n",
      "  4    1000          10.67       75.39    0.75\n",
      "  5    1200           7.77       78.65    0.79\n",
      "  6    1400           5.52       81.00    0.81\n",
      "  8    1600           4.01       82.35    0.82\n",
      " 10    1800           3.16       81.84    0.82\n",
      " 13    2000           2.18       82.47    0.82\n",
      " 17    2200           1.64       82.40    0.82\n",
      " 21    2400           1.21       83.12    0.83\n",
      " 26    2600           0.86       83.26    0.83\n",
      " 33    2800           0.64       82.81    0.83\n",
      " 42    3000           0.44       82.99    0.83\n",
      " 52    3200           0.34       83.20    0.83\n",
      " 65    3400           0.25       83.33    0.83\n",
      " 80    3600           0.18       83.06    0.83\n",
      " 99    3800           0.13       83.20    0.83\n",
      "122    4000           0.10       83.20    0.83\n",
      "150    4200           0.07       83.72    0.84\n",
      "183    4400           0.05       83.57    0.84\n",
      "216    4600           0.04       82.92    0.83\n",
      "250    4800           0.03       82.92    0.83\n",
      "283    5000           0.03       82.86    0.83\n",
      "316    5200           0.02       82.86    0.83\n",
      "350    5400           0.02       83.06    0.83\n",
      "383    5600           0.02       83.13    0.83\n",
      "416    5800           0.01       83.13    0.83\n",
      "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
      "/Users/eric/Dev/quantify-news/models/sent_relevance/model-last\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-20 14:04:00,948 - git.cmd - DEBUG - Popen(['git', 'cat-file', '--batch-check'], cwd=/Users/eric/Dev/quantify-news, stdin=<valid stream>, shell=False, universal_newlines=False)\n",
      "2025-03-20 14:04:00,985 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 70.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-20 14:04:01,020 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"POST /api/2.0/mlflow/runs/create HTTP/1.1\" 200 1074\n",
      "2025-03-20 14:04:01,031 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 14:04:01,160 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"POST /api/2.0/mlflow/runs/log-batch HTTP/1.1\" 200 2\n",
      "2025-03-20 14:04:01,170 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 14:04:01,195 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"POST /api/2.0/mlflow/runs/log-batch HTTP/1.1\" 200 2\n",
      "\u001b[31m2025/03/20 14:04:09 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "2025-03-20 14:04:09,344 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 14:04:09,377 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"GET /api/2.0/mlflow/runs/get?run_uuid=55f8c6a2e976464293a80822469a6d42&run_id=55f8c6a2e976464293a80822469a6d42 HTTP/1.1\" 200 12950\n",
      "2025-03-20 14:04:09,409 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 14:04:09,416 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"POST /api/2.0/mlflow/runs/log-model HTTP/1.1\" 200 2\n",
      "2025-03-20 14:04:09,446 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 14:04:09,482 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"GET /api/2.0/mlflow/runs/get?run_uuid=55f8c6a2e976464293a80822469a6d42&run_id=55f8c6a2e976464293a80822469a6d42 HTTP/1.1\" 200 13533\n",
      "2025-03-20 14:04:09,493 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 14:04:09,501 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"POST /api/2.0/mlflow/runs/update HTTP/1.1\" 200 470\n",
      "[I 2025-03-20 14:04:09,530] Trial 47 finished with value: 0.5532451819 and parameters: {'components.textcat_multilabel.model.length': 7}. Best is trial 7 with value: 0.5532451819.\n",
      "2025-03-20 14:04:09,578 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 14:04:09,590 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"GET /api/2.0/mlflow/experiments/get-by-name?experiment_name=sent_relevance_models HTTP/1.1\" 200 600\n",
      "2025-03-20 14:04:09,597 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run optuna_trial_47 at: http://127.0.0.1:8080/#/experiments/485071347047209202/runs/55f8c6a2e976464293a80822469a6d42\n",
      "🧪 View experiment at: http://127.0.0.1:8080/#/experiments/485071347047209202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-20 14:04:10,362 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"POST /api/2.0/mlflow/runs/search HTTP/1.1\" 200 14683\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with overrides:\n",
      " {'components.textcat_multilabel.model.length': '262144', 'training.batcher.size.start': '17', 'paths.vectors': 'en_core_web_sm'}\n",
      "\u001b[38;5;2m✔ Auto-filled config with all values\u001b[0m\n",
      "\u001b[38;5;2m✔ Saved config\u001b[0m\n",
      "/Users/eric/Dev/quantify-news/scripts/sent_relevance/spacy_config.cfg\n",
      "You can now add your data and train your pipeline:\n",
      "python -m spacy train spacy_config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n",
      "\u001b[38;5;4mℹ Saving to output directory:\n",
      "/Users/eric/Dev/quantify-news/models/sent_relevance\u001b[0m\n",
      "\u001b[38;5;4mℹ Using CPU\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "[2025-03-20 14:04:15,517] [WARNING] [W112] The model specified to use for initial vectors (en_core_web_sm) has no vectors. This is almost certainly a mistake.\n",
      "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "\u001b[38;5;4mℹ Pipeline: ['textcat_multilabel']\u001b[0m\n",
      "\u001b[38;5;4mℹ Initial learn rate: 0.001\u001b[0m\n",
      "E    #       LOSS TEXTC...  CATS_SCORE  SCORE \n",
      "---  ------  -------------  ----------  ------\n",
      "  0       0           0.25       71.43    0.71\n",
      "  0     200          40.32       59.18    0.59\n",
      "  1     400          25.98       62.87    0.63\n",
      "  2     600          22.77       70.11    0.70\n",
      "  3     800          15.34       73.57    0.74\n",
      "  4    1000          10.67       75.39    0.75\n",
      "  5    1200           7.77       78.65    0.79\n",
      "  6    1400           5.52       81.00    0.81\n",
      "  8    1600           4.01       82.35    0.82\n",
      " 10    1800           3.16       81.84    0.82\n",
      " 13    2000           2.18       82.47    0.82\n",
      " 17    2200           1.64       82.40    0.82\n",
      " 21    2400           1.21       83.12    0.83\n",
      " 26    2600           0.86       83.26    0.83\n",
      " 33    2800           0.64       82.81    0.83\n",
      " 42    3000           0.44       82.99    0.83\n",
      " 52    3200           0.34       83.20    0.83\n",
      " 65    3400           0.25       83.33    0.83\n",
      " 80    3600           0.18       83.06    0.83\n",
      " 99    3800           0.13       83.20    0.83\n",
      "122    4000           0.10       83.20    0.83\n",
      "150    4200           0.07       83.72    0.84\n",
      "183    4400           0.05       83.57    0.84\n",
      "216    4600           0.04       82.92    0.83\n",
      "250    4800           0.03       82.92    0.83\n",
      "283    5000           0.03       82.86    0.83\n",
      "316    5200           0.02       82.86    0.83\n",
      "350    5400           0.02       83.06    0.83\n",
      "383    5600           0.02       83.13    0.83\n",
      "416    5800           0.01       83.13    0.83\n",
      "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
      "/Users/eric/Dev/quantify-news/models/sent_relevance/model-last\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-20 14:05:27,875 - git.cmd - DEBUG - Popen(['git', 'cat-file', '--batch-check'], cwd=/Users/eric/Dev/quantify-news, stdin=<valid stream>, shell=False, universal_newlines=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 75.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-20 14:05:27,944 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 14:05:27,983 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"POST /api/2.0/mlflow/runs/create HTTP/1.1\" 200 1074\n",
      "2025-03-20 14:05:27,997 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 14:05:28,082 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"POST /api/2.0/mlflow/runs/log-batch HTTP/1.1\" 200 2\n",
      "2025-03-20 14:05:28,094 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 14:05:28,123 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"POST /api/2.0/mlflow/runs/log-batch HTTP/1.1\" 200 2\n",
      "\u001b[31m2025/03/20 14:05:37 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "2025-03-20 14:05:37,717 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 14:05:37,757 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"GET /api/2.0/mlflow/runs/get?run_uuid=273f29122a3844cea00daa0a7948d249&run_id=273f29122a3844cea00daa0a7948d249 HTTP/1.1\" 200 12950\n",
      "2025-03-20 14:05:37,811 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 14:05:37,827 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"POST /api/2.0/mlflow/runs/log-model HTTP/1.1\" 200 2\n",
      "2025-03-20 14:05:37,877 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 14:05:37,980 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"GET /api/2.0/mlflow/runs/get?run_uuid=273f29122a3844cea00daa0a7948d249&run_id=273f29122a3844cea00daa0a7948d249 HTTP/1.1\" 200 13533\n",
      "2025-03-20 14:05:38,008 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 14:05:38,020 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"POST /api/2.0/mlflow/runs/update HTTP/1.1\" 200 470\n",
      "[I 2025-03-20 14:05:38,088] Trial 48 finished with value: 0.5532451819 and parameters: {'components.textcat_multilabel.model.length': 13}. Best is trial 7 with value: 0.5532451819.\n",
      "2025-03-20 14:05:38,171 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 14:05:38,194 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"GET /api/2.0/mlflow/experiments/get-by-name?experiment_name=sent_relevance_models HTTP/1.1\" 200 600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run optuna_trial_48 at: http://127.0.0.1:8080/#/experiments/485071347047209202/runs/273f29122a3844cea00daa0a7948d249\n",
      "🧪 View experiment at: http://127.0.0.1:8080/#/experiments/485071347047209202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-20 14:05:38,210 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 14:05:39,487 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"POST /api/2.0/mlflow/runs/search HTTP/1.1\" 200 14683\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with overrides:\n",
      " {'components.textcat_multilabel.model.length': '262144', 'training.batcher.size.start': '17', 'paths.vectors': 'en_core_web_sm'}\n",
      "\u001b[38;5;2m✔ Auto-filled config with all values\u001b[0m\n",
      "\u001b[38;5;2m✔ Saved config\u001b[0m\n",
      "/Users/eric/Dev/quantify-news/scripts/sent_relevance/spacy_config.cfg\n",
      "You can now add your data and train your pipeline:\n",
      "python -m spacy train spacy_config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n",
      "\u001b[38;5;4mℹ Saving to output directory:\n",
      "/Users/eric/Dev/quantify-news/models/sent_relevance\u001b[0m\n",
      "\u001b[38;5;4mℹ Using CPU\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "[2025-03-20 14:05:45,844] [WARNING] [W112] The model specified to use for initial vectors (en_core_web_sm) has no vectors. This is almost certainly a mistake.\n",
      "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "\u001b[38;5;4mℹ Pipeline: ['textcat_multilabel']\u001b[0m\n",
      "\u001b[38;5;4mℹ Initial learn rate: 0.001\u001b[0m\n",
      "E    #       LOSS TEXTC...  CATS_SCORE  SCORE \n",
      "---  ------  -------------  ----------  ------\n",
      "  0       0           0.25       71.43    0.71\n",
      "  0     200          40.32       59.18    0.59\n",
      "  1     400          25.98       62.87    0.63\n",
      "  2     600          22.77       70.11    0.70\n",
      "  3     800          15.34       73.57    0.74\n",
      "  4    1000          10.67       75.39    0.75\n",
      "  5    1200           7.77       78.65    0.79\n",
      "  6    1400           5.52       81.00    0.81\n",
      "  8    1600           4.01       82.35    0.82\n",
      " 10    1800           3.16       81.84    0.82\n",
      " 13    2000           2.18       82.47    0.82\n",
      " 17    2200           1.64       82.40    0.82\n",
      " 21    2400           1.21       83.12    0.83\n",
      " 26    2600           0.86       83.26    0.83\n",
      " 33    2800           0.64       82.81    0.83\n",
      " 42    3000           0.44       82.99    0.83\n",
      " 52    3200           0.34       83.20    0.83\n",
      " 65    3400           0.25       83.33    0.83\n",
      " 80    3600           0.18       83.06    0.83\n",
      " 99    3800           0.13       83.20    0.83\n",
      "122    4000           0.10       83.20    0.83\n",
      "150    4200           0.07       83.72    0.84\n",
      "183    4400           0.05       83.57    0.84\n",
      "216    4600           0.04       82.92    0.83\n",
      "250    4800           0.03       82.92    0.83\n",
      "283    5000           0.03       82.86    0.83\n",
      "316    5200           0.02       82.86    0.83\n",
      "350    5400           0.02       83.06    0.83\n",
      "383    5600           0.02       83.13    0.83\n",
      "416    5800           0.01       83.13    0.83\n",
      "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
      "/Users/eric/Dev/quantify-news/models/sent_relevance/model-last\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-20 14:06:56,853 - git.cmd - DEBUG - Popen(['git', 'cat-file', '--batch-check'], cwd=/Users/eric/Dev/quantify-news, stdin=<valid stream>, shell=False, universal_newlines=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 74.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-20 14:06:56,889 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 14:06:56,928 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"POST /api/2.0/mlflow/runs/create HTTP/1.1\" 200 1074\n",
      "2025-03-20 14:06:56,938 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 14:06:57,149 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"POST /api/2.0/mlflow/runs/log-batch HTTP/1.1\" 200 2\n",
      "2025-03-20 14:06:57,158 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 14:06:57,180 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"POST /api/2.0/mlflow/runs/log-batch HTTP/1.1\" 200 2\n",
      "\u001b[31m2025/03/20 14:07:04 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "2025-03-20 14:07:04,929 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 14:07:04,964 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"GET /api/2.0/mlflow/runs/get?run_uuid=8e5129b471f94bf783ef6ab770110a74&run_id=8e5129b471f94bf783ef6ab770110a74 HTTP/1.1\" 200 12950\n",
      "2025-03-20 14:07:04,992 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 14:07:05,003 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"POST /api/2.0/mlflow/runs/log-model HTTP/1.1\" 200 2\n",
      "2025-03-20 14:07:05,033 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 14:07:05,071 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"GET /api/2.0/mlflow/runs/get?run_uuid=8e5129b471f94bf783ef6ab770110a74&run_id=8e5129b471f94bf783ef6ab770110a74 HTTP/1.1\" 200 13533\n",
      "2025-03-20 14:07:05,082 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 14:07:05,089 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"POST /api/2.0/mlflow/runs/update HTTP/1.1\" 200 470\n",
      "[I 2025-03-20 14:07:05,125] Trial 49 finished with value: 0.5532451819 and parameters: {'components.textcat_multilabel.model.length': 18}. Best is trial 7 with value: 0.5532451819.\n",
      "2025-03-20 14:07:05,171 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 14:07:05,181 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"GET /api/2.0/mlflow/experiments/get-by-name?experiment_name=sent_relevance_models HTTP/1.1\" 200 600\n",
      "2025-03-20 14:07:05,189 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run optuna_trial_49 at: http://127.0.0.1:8080/#/experiments/485071347047209202/runs/8e5129b471f94bf783ef6ab770110a74\n",
      "🧪 View experiment at: http://127.0.0.1:8080/#/experiments/485071347047209202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-20 14:07:05,623 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"POST /api/2.0/mlflow/runs/search HTTP/1.1\" 200 14683\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with overrides:\n",
      " {'components.textcat_multilabel.model.length': '262144', 'training.batcher.size.start': '17', 'paths.vectors': 'en_core_web_sm'}\n",
      "\u001b[38;5;2m✔ Auto-filled config with all values\u001b[0m\n",
      "\u001b[38;5;2m✔ Saved config\u001b[0m\n",
      "/Users/eric/Dev/quantify-news/scripts/sent_relevance/spacy_config.cfg\n",
      "You can now add your data and train your pipeline:\n",
      "python -m spacy train spacy_config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n",
      "\u001b[38;5;4mℹ Saving to output directory:\n",
      "/Users/eric/Dev/quantify-news/models/sent_relevance\u001b[0m\n",
      "\u001b[38;5;4mℹ Using CPU\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "[2025-03-20 14:07:11,022] [WARNING] [W112] The model specified to use for initial vectors (en_core_web_sm) has no vectors. This is almost certainly a mistake.\n",
      "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "\u001b[38;5;4mℹ Pipeline: ['textcat_multilabel']\u001b[0m\n",
      "\u001b[38;5;4mℹ Initial learn rate: 0.001\u001b[0m\n",
      "E    #       LOSS TEXTC...  CATS_SCORE  SCORE \n",
      "---  ------  -------------  ----------  ------\n",
      "  0       0           0.25       71.43    0.71\n",
      "  0     200          40.32       59.18    0.59\n",
      "  1     400          25.98       62.87    0.63\n",
      "  2     600          22.77       70.11    0.70\n",
      "  3     800          15.34       73.57    0.74\n",
      "  4    1000          10.67       75.39    0.75\n",
      "  5    1200           7.77       78.65    0.79\n",
      "  6    1400           5.52       81.00    0.81\n",
      "  8    1600           4.01       82.35    0.82\n",
      " 10    1800           3.16       81.84    0.82\n",
      " 13    2000           2.18       82.47    0.82\n",
      " 17    2200           1.64       82.40    0.82\n",
      " 21    2400           1.21       83.12    0.83\n",
      " 26    2600           0.86       83.26    0.83\n",
      " 33    2800           0.64       82.81    0.83\n",
      " 42    3000           0.44       82.99    0.83\n",
      " 52    3200           0.34       83.20    0.83\n",
      " 65    3400           0.25       83.33    0.83\n",
      " 80    3600           0.18       83.06    0.83\n",
      " 99    3800           0.13       83.20    0.83\n",
      "122    4000           0.10       83.20    0.83\n",
      "150    4200           0.07       83.72    0.84\n",
      "183    4400           0.05       83.57    0.84\n",
      "216    4600           0.04       82.92    0.83\n",
      "250    4800           0.03       82.92    0.83\n",
      "283    5000           0.03       82.86    0.83\n",
      "316    5200           0.02       82.86    0.83\n",
      "350    5400           0.02       83.06    0.83\n",
      "383    5600           0.02       83.13    0.83\n",
      "416    5800           0.01       83.13    0.83\n",
      "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
      "/Users/eric/Dev/quantify-news/models/sent_relevance/model-last\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-20 14:08:05,464 - git.cmd - DEBUG - Popen(['git', 'cat-file', '--batch-check'], cwd=/Users/eric/Dev/quantify-news, stdin=<valid stream>, shell=False, universal_newlines=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 57.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-20 14:08:05,489 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 14:08:05,514 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"POST /api/2.0/mlflow/runs/create HTTP/1.1\" 200 1074\n",
      "2025-03-20 14:08:05,522 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 14:08:05,565 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"POST /api/2.0/mlflow/runs/log-batch HTTP/1.1\" 200 2\n",
      "2025-03-20 14:08:05,570 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 14:08:05,584 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"POST /api/2.0/mlflow/runs/log-batch HTTP/1.1\" 200 2\n",
      "\u001b[31m2025/03/20 14:08:10 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "2025-03-20 14:08:10,863 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 14:08:10,884 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"GET /api/2.0/mlflow/runs/get?run_uuid=9c2eb558cef249119e774836e6c06932&run_id=9c2eb558cef249119e774836e6c06932 HTTP/1.1\" 200 12950\n",
      "2025-03-20 14:08:10,904 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 14:08:10,912 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"POST /api/2.0/mlflow/runs/log-model HTTP/1.1\" 200 2\n",
      "2025-03-20 14:08:10,930 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 14:08:10,952 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"GET /api/2.0/mlflow/runs/get?run_uuid=9c2eb558cef249119e774836e6c06932&run_id=9c2eb558cef249119e774836e6c06932 HTTP/1.1\" 200 13533\n",
      "2025-03-20 14:08:10,960 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 14:08:10,965 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"POST /api/2.0/mlflow/runs/update HTTP/1.1\" 200 470\n",
      "[I 2025-03-20 14:08:10,987] Trial 50 finished with value: 0.5532451819 and parameters: {'components.textcat_multilabel.model.length': 15}. Best is trial 7 with value: 0.5532451819.\n",
      "2025-03-20 14:08:11,020 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 14:08:11,028 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"GET /api/2.0/mlflow/experiments/get-by-name?experiment_name=sent_relevance_models HTTP/1.1\" 200 600\n",
      "2025-03-20 14:08:11,033 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run optuna_trial_50 at: http://127.0.0.1:8080/#/experiments/485071347047209202/runs/9c2eb558cef249119e774836e6c06932\n",
      "🧪 View experiment at: http://127.0.0.1:8080/#/experiments/485071347047209202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-20 14:08:11,339 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"POST /api/2.0/mlflow/runs/search HTTP/1.1\" 200 14683\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with overrides:\n",
      " {'components.textcat_multilabel.model.length': '262144', 'training.batcher.size.start': '17', 'paths.vectors': 'en_core_web_sm'}\n",
      "\u001b[38;5;2m✔ Auto-filled config with all values\u001b[0m\n",
      "\u001b[38;5;2m✔ Saved config\u001b[0m\n",
      "/Users/eric/Dev/quantify-news/scripts/sent_relevance/spacy_config.cfg\n",
      "You can now add your data and train your pipeline:\n",
      "python -m spacy train spacy_config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n",
      "\u001b[38;5;4mℹ Saving to output directory:\n",
      "/Users/eric/Dev/quantify-news/models/sent_relevance\u001b[0m\n",
      "\u001b[38;5;4mℹ Using CPU\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "[2025-03-20 14:08:14,525] [WARNING] [W112] The model specified to use for initial vectors (en_core_web_sm) has no vectors. This is almost certainly a mistake.\n",
      "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "\u001b[38;5;4mℹ Pipeline: ['textcat_multilabel']\u001b[0m\n",
      "\u001b[38;5;4mℹ Initial learn rate: 0.001\u001b[0m\n",
      "E    #       LOSS TEXTC...  CATS_SCORE  SCORE \n",
      "---  ------  -------------  ----------  ------\n",
      "  0       0           0.25       71.43    0.71\n",
      "  0     200          40.32       59.18    0.59\n",
      "  1     400          25.98       62.87    0.63\n",
      "  2     600          22.77       70.11    0.70\n",
      "  3     800          15.34       73.57    0.74\n",
      "  4    1000          10.67       75.39    0.75\n",
      "  5    1200           7.77       78.65    0.79\n",
      "  6    1400           5.52       81.00    0.81\n",
      "  8    1600           4.01       82.35    0.82\n",
      " 10    1800           3.16       81.84    0.82\n",
      " 13    2000           2.18       82.47    0.82\n",
      " 17    2200           1.64       82.40    0.82\n",
      " 21    2400           1.21       83.12    0.83\n",
      " 26    2600           0.86       83.26    0.83\n",
      " 33    2800           0.64       82.81    0.83\n",
      " 42    3000           0.44       82.99    0.83\n",
      " 52    3200           0.34       83.20    0.83\n",
      " 65    3400           0.25       83.33    0.83\n",
      " 80    3600           0.18       83.06    0.83\n",
      " 99    3800           0.13       83.20    0.83\n",
      "122    4000           0.10       83.20    0.83\n",
      "150    4200           0.07       83.72    0.84\n",
      "183    4400           0.05       83.57    0.84\n",
      "216    4600           0.04       82.92    0.83\n",
      "250    4800           0.03       82.92    0.83\n",
      "283    5000           0.03       82.86    0.83\n",
      "316    5200           0.02       82.86    0.83\n",
      "350    5400           0.02       83.06    0.83\n",
      "383    5600           0.02       83.13    0.83\n",
      "416    5800           0.01       83.13    0.83\n",
      "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
      "/Users/eric/Dev/quantify-news/models/sent_relevance/model-last\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-20 14:09:02,487 - git.cmd - DEBUG - Popen(['git', 'cat-file', '--batch-check'], cwd=/Users/eric/Dev/quantify-news, stdin=<valid stream>, shell=False, universal_newlines=False)\n",
      "2025-03-20 14:09:02,512 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 49.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-20 14:09:02,533 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"POST /api/2.0/mlflow/runs/create HTTP/1.1\" 200 1074\n",
      "2025-03-20 14:09:02,542 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 14:09:02,590 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"POST /api/2.0/mlflow/runs/log-batch HTTP/1.1\" 200 2\n",
      "2025-03-20 14:09:02,597 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 14:09:02,612 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"POST /api/2.0/mlflow/runs/log-batch HTTP/1.1\" 200 2\n",
      "\u001b[31m2025/03/20 14:09:07 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "2025-03-20 14:09:07,719 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 14:09:07,743 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"GET /api/2.0/mlflow/runs/get?run_uuid=0be6a60bb952444f93b0ac8b41911bff&run_id=0be6a60bb952444f93b0ac8b41911bff HTTP/1.1\" 200 12950\n",
      "2025-03-20 14:09:07,763 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 14:09:07,768 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"POST /api/2.0/mlflow/runs/log-model HTTP/1.1\" 200 2\n",
      "2025-03-20 14:09:07,788 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 14:09:07,835 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"GET /api/2.0/mlflow/runs/get?run_uuid=0be6a60bb952444f93b0ac8b41911bff&run_id=0be6a60bb952444f93b0ac8b41911bff HTTP/1.1\" 200 13533\n",
      "2025-03-20 14:09:07,842 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 14:09:07,847 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"POST /api/2.0/mlflow/runs/update HTTP/1.1\" 200 470\n",
      "[I 2025-03-20 14:09:07,868] Trial 51 finished with value: 0.5532451819 and parameters: {'components.textcat_multilabel.model.length': 11}. Best is trial 7 with value: 0.5532451819.\n",
      "2025-03-20 14:09:07,899 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 14:09:07,906 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"GET /api/2.0/mlflow/experiments/get-by-name?experiment_name=sent_relevance_models HTTP/1.1\" 200 600\n",
      "2025-03-20 14:09:07,911 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run optuna_trial_51 at: http://127.0.0.1:8080/#/experiments/485071347047209202/runs/0be6a60bb952444f93b0ac8b41911bff\n",
      "🧪 View experiment at: http://127.0.0.1:8080/#/experiments/485071347047209202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-20 14:09:08,212 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"POST /api/2.0/mlflow/runs/search HTTP/1.1\" 200 14683\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with overrides:\n",
      " {'components.textcat_multilabel.model.length': '262144', 'training.batcher.size.start': '17', 'paths.vectors': 'en_core_web_sm'}\n",
      "\u001b[38;5;2m✔ Auto-filled config with all values\u001b[0m\n",
      "\u001b[38;5;2m✔ Saved config\u001b[0m\n",
      "/Users/eric/Dev/quantify-news/scripts/sent_relevance/spacy_config.cfg\n",
      "You can now add your data and train your pipeline:\n",
      "python -m spacy train spacy_config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n",
      "\u001b[38;5;4mℹ Saving to output directory:\n",
      "/Users/eric/Dev/quantify-news/models/sent_relevance\u001b[0m\n",
      "\u001b[38;5;4mℹ Using CPU\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "[2025-03-20 14:09:11,324] [WARNING] [W112] The model specified to use for initial vectors (en_core_web_sm) has no vectors. This is almost certainly a mistake.\n",
      "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "\u001b[38;5;4mℹ Pipeline: ['textcat_multilabel']\u001b[0m\n",
      "\u001b[38;5;4mℹ Initial learn rate: 0.001\u001b[0m\n",
      "E    #       LOSS TEXTC...  CATS_SCORE  SCORE \n",
      "---  ------  -------------  ----------  ------\n",
      "  0       0           0.25       71.43    0.71\n",
      "  0     200          40.32       59.18    0.59\n",
      "  1     400          25.98       62.87    0.63\n",
      "  2     600          22.77       70.11    0.70\n",
      "  3     800          15.34       73.57    0.74\n",
      "  4    1000          10.67       75.39    0.75\n",
      "  5    1200           7.77       78.65    0.79\n",
      "  6    1400           5.52       81.00    0.81\n",
      "  8    1600           4.01       82.35    0.82\n",
      " 10    1800           3.16       81.84    0.82\n",
      " 13    2000           2.18       82.47    0.82\n",
      " 17    2200           1.64       82.40    0.82\n",
      " 21    2400           1.21       83.12    0.83\n",
      " 26    2600           0.86       83.26    0.83\n",
      " 33    2800           0.64       82.81    0.83\n",
      " 42    3000           0.44       82.99    0.83\n",
      " 52    3200           0.34       83.20    0.83\n",
      " 65    3400           0.25       83.33    0.83\n",
      " 80    3600           0.18       83.06    0.83\n",
      " 99    3800           0.13       83.20    0.83\n",
      "122    4000           0.10       83.20    0.83\n",
      "150    4200           0.07       83.72    0.84\n",
      "183    4400           0.05       83.57    0.84\n",
      "216    4600           0.04       82.92    0.83\n",
      "250    4800           0.03       82.92    0.83\n",
      "283    5000           0.03       82.86    0.83\n",
      "316    5200           0.02       82.86    0.83\n",
      "350    5400           0.02       83.06    0.83\n",
      "383    5600           0.02       83.13    0.83\n",
      "416    5800           0.01       83.13    0.83\n",
      "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
      "/Users/eric/Dev/quantify-news/models/sent_relevance/model-last\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-20 14:10:05,079 - git.cmd - DEBUG - Popen(['git', 'cat-file', '--batch-check'], cwd=/Users/eric/Dev/quantify-news, stdin=<valid stream>, shell=False, universal_newlines=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 55.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-20 14:10:05,115 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 14:10:05,152 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"POST /api/2.0/mlflow/runs/create HTTP/1.1\" 200 1074\n",
      "2025-03-20 14:10:05,163 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 14:10:05,221 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"POST /api/2.0/mlflow/runs/log-batch HTTP/1.1\" 200 2\n",
      "2025-03-20 14:10:05,228 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 14:10:05,250 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"POST /api/2.0/mlflow/runs/log-batch HTTP/1.1\" 200 2\n",
      "\u001b[31m2025/03/20 14:10:11 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "2025-03-20 14:10:11,711 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 14:10:11,740 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"GET /api/2.0/mlflow/runs/get?run_uuid=3d57811e15fe4bca82c23081b0a1bfb1&run_id=3d57811e15fe4bca82c23081b0a1bfb1 HTTP/1.1\" 200 12950\n",
      "2025-03-20 14:10:11,768 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 14:10:11,778 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"POST /api/2.0/mlflow/runs/log-model HTTP/1.1\" 200 2\n",
      "2025-03-20 14:10:11,804 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 14:10:11,835 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"GET /api/2.0/mlflow/runs/get?run_uuid=3d57811e15fe4bca82c23081b0a1bfb1&run_id=3d57811e15fe4bca82c23081b0a1bfb1 HTTP/1.1\" 200 13533\n",
      "2025-03-20 14:10:11,847 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 14:10:11,857 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"POST /api/2.0/mlflow/runs/update HTTP/1.1\" 200 470\n",
      "[I 2025-03-20 14:10:11,892] Trial 52 finished with value: 0.5532451819 and parameters: {'components.textcat_multilabel.model.length': 7}. Best is trial 7 with value: 0.5532451819.\n",
      "2025-03-20 14:10:11,903 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 14:10:11,915 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"GET /api/2.0/mlflow/runs/get?run_uuid=e7f61d93fa0a4b56ad90f118eb6633f3&run_id=e7f61d93fa0a4b56ad90f118eb6633f3 HTTP/1.1\" 200 964\n",
      "2025-03-20 14:10:11,924 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 14:10:11,934 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"POST /api/2.0/mlflow/runs/update HTTP/1.1\" 200 472\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run optuna_trial_52 at: http://127.0.0.1:8080/#/experiments/485071347047209202/runs/3d57811e15fe4bca82c23081b0a1bfb1\n",
      "🧪 View experiment at: http://127.0.0.1:8080/#/experiments/485071347047209202\n",
      "🏃 View run opt_linear_length at: http://127.0.0.1:8080/#/experiments/485071347047209202/runs/e7f61d93fa0a4b56ad90f118eb6633f3\n",
      "🧪 View experiment at: http://127.0.0.1:8080/#/experiments/485071347047209202\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run(run_name=\"opt_linear_length\"):\n",
    "    study.optimize(objective, n_trials=9, callbacks=[archiver])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NGram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp = \"components.textcat_multilabel.model.ngram_size\"\n",
    "hyperparams.add(hp)\n",
    "\n",
    "def objective(trial: optuna.trial.Trial):\n",
    "    length = trial.suggest_int(hp, 1, 2)\n",
    "    overrides = ({hp: length} | best_params(hyperparams))\n",
    "    return objective_base(trial, overrides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-20 14:10:12,220 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 14:10:12,237 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"POST /api/2.0/mlflow/runs/create HTTP/1.1\" 200 948\n",
      "2025-03-20 14:10:12,269 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 14:10:12,277 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"GET /api/2.0/mlflow/experiments/get-by-name?experiment_name=sent_relevance_models HTTP/1.1\" 200 600\n",
      "2025-03-20 14:10:12,283 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 14:10:12,643 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"POST /api/2.0/mlflow/runs/search HTTP/1.1\" 200 14683\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with overrides:\n",
      " {'components.textcat_multilabel.model.ngram_size': '1', 'training.batcher.size.start': '17', 'paths.vectors': 'en_core_web_sm', 'components.textcat_multilabel.model.length': '262144'}\n",
      "\u001b[38;5;2m✔ Auto-filled config with all values\u001b[0m\n",
      "\u001b[38;5;2m✔ Saved config\u001b[0m\n",
      "/Users/eric/Dev/quantify-news/scripts/sent_relevance/spacy_config.cfg\n",
      "You can now add your data and train your pipeline:\n",
      "python -m spacy train spacy_config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n",
      "\u001b[38;5;4mℹ Saving to output directory:\n",
      "/Users/eric/Dev/quantify-news/models/sent_relevance\u001b[0m\n",
      "\u001b[38;5;4mℹ Using CPU\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "[2025-03-20 14:10:16,424] [WARNING] [W112] The model specified to use for initial vectors (en_core_web_sm) has no vectors. This is almost certainly a mistake.\n",
      "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "\u001b[38;5;4mℹ Pipeline: ['textcat_multilabel']\u001b[0m\n",
      "\u001b[38;5;4mℹ Initial learn rate: 0.001\u001b[0m\n",
      "E    #       LOSS TEXTC...  CATS_SCORE  SCORE \n",
      "---  ------  -------------  ----------  ------\n",
      "  0       0           0.25       71.43    0.71\n",
      "  0     200          40.32       59.18    0.59\n",
      "  1     400          25.98       62.87    0.63\n",
      "  2     600          22.77       70.11    0.70\n",
      "  3     800          15.34       73.57    0.74\n",
      "  4    1000          10.67       75.39    0.75\n",
      "  5    1200           7.77       78.65    0.79\n",
      "  6    1400           5.52       81.00    0.81\n",
      "  8    1600           4.01       82.35    0.82\n",
      " 10    1800           3.16       81.84    0.82\n",
      " 13    2000           2.18       82.47    0.82\n",
      " 17    2200           1.64       82.40    0.82\n",
      " 21    2400           1.21       83.12    0.83\n",
      " 26    2600           0.86       83.26    0.83\n",
      " 33    2800           0.64       82.81    0.83\n",
      " 42    3000           0.44       82.99    0.83\n",
      " 52    3200           0.34       83.20    0.83\n",
      " 65    3400           0.25       83.33    0.83\n",
      " 80    3600           0.18       83.06    0.83\n",
      " 99    3800           0.13       83.20    0.83\n",
      "122    4000           0.10       83.20    0.83\n",
      "150    4200           0.07       83.72    0.84\n",
      "183    4400           0.05       83.57    0.84\n",
      "216    4600           0.04       82.92    0.83\n",
      "250    4800           0.03       82.92    0.83\n",
      "283    5000           0.03       82.86    0.83\n",
      "316    5200           0.02       82.86    0.83\n",
      "350    5400           0.02       83.06    0.83\n",
      "383    5600           0.02       83.13    0.83\n",
      "416    5800           0.01       83.13    0.83\n",
      "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
      "/Users/eric/Dev/quantify-news/models/sent_relevance/model-last\n",
      "Training time: 56.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-20 14:11:10,466 - git.cmd - DEBUG - Popen(['git', 'cat-file', '--batch-check'], cwd=/Users/eric/Dev/quantify-news, stdin=<valid stream>, shell=False, universal_newlines=False)\n",
      "2025-03-20 14:11:10,498 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 14:11:10,522 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"POST /api/2.0/mlflow/runs/create HTTP/1.1\" 200 1074\n",
      "2025-03-20 14:11:10,530 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 14:11:10,576 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"POST /api/2.0/mlflow/runs/log-batch HTTP/1.1\" 200 2\n",
      "2025-03-20 14:11:10,584 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 14:11:10,602 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"POST /api/2.0/mlflow/runs/log-batch HTTP/1.1\" 200 2\n",
      "\u001b[31m2025/03/20 14:11:16 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "2025-03-20 14:11:16,600 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 14:11:16,627 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"GET /api/2.0/mlflow/runs/get?run_uuid=9e284812e4974a19b50fc60175284c80&run_id=9e284812e4974a19b50fc60175284c80 HTTP/1.1\" 200 12950\n",
      "2025-03-20 14:11:16,651 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 14:11:16,657 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"POST /api/2.0/mlflow/runs/log-model HTTP/1.1\" 200 2\n",
      "2025-03-20 14:11:16,676 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 14:11:16,700 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"GET /api/2.0/mlflow/runs/get?run_uuid=9e284812e4974a19b50fc60175284c80&run_id=9e284812e4974a19b50fc60175284c80 HTTP/1.1\" 200 13533\n",
      "2025-03-20 14:11:16,706 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 14:11:16,711 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"POST /api/2.0/mlflow/runs/update HTTP/1.1\" 200 470\n",
      "[I 2025-03-20 14:11:16,734] Trial 53 finished with value: 0.5532451819 and parameters: {'components.textcat_multilabel.model.ngram_size': 1}. Best is trial 7 with value: 0.5532451819.\n",
      "2025-03-20 14:11:16,767 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 14:11:16,775 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"GET /api/2.0/mlflow/experiments/get-by-name?experiment_name=sent_relevance_models HTTP/1.1\" 200 600\n",
      "2025-03-20 14:11:16,782 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run optuna_trial_53 at: http://127.0.0.1:8080/#/experiments/485071347047209202/runs/9e284812e4974a19b50fc60175284c80\n",
      "🧪 View experiment at: http://127.0.0.1:8080/#/experiments/485071347047209202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-20 14:11:17,172 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"POST /api/2.0/mlflow/runs/search HTTP/1.1\" 200 14683\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with overrides:\n",
      " {'components.textcat_multilabel.model.ngram_size': '1', 'training.batcher.size.start': '17', 'paths.vectors': 'en_core_web_sm', 'components.textcat_multilabel.model.length': '262144'}\n",
      "\u001b[38;5;2m✔ Auto-filled config with all values\u001b[0m\n",
      "\u001b[38;5;2m✔ Saved config\u001b[0m\n",
      "/Users/eric/Dev/quantify-news/scripts/sent_relevance/spacy_config.cfg\n",
      "You can now add your data and train your pipeline:\n",
      "python -m spacy train spacy_config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n",
      "\u001b[38;5;4mℹ Saving to output directory:\n",
      "/Users/eric/Dev/quantify-news/models/sent_relevance\u001b[0m\n",
      "\u001b[38;5;4mℹ Using CPU\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "[2025-03-20 14:11:20,939] [WARNING] [W112] The model specified to use for initial vectors (en_core_web_sm) has no vectors. This is almost certainly a mistake.\n",
      "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "\u001b[38;5;4mℹ Pipeline: ['textcat_multilabel']\u001b[0m\n",
      "\u001b[38;5;4mℹ Initial learn rate: 0.001\u001b[0m\n",
      "E    #       LOSS TEXTC...  CATS_SCORE  SCORE \n",
      "---  ------  -------------  ----------  ------\n",
      "  0       0           0.25       71.43    0.71\n",
      "  0     200          40.32       59.18    0.59\n",
      "  1     400          25.98       62.87    0.63\n",
      "  2     600          22.77       70.11    0.70\n",
      "  3     800          15.34       73.57    0.74\n",
      "  4    1000          10.67       75.39    0.75\n",
      "  5    1200           7.77       78.65    0.79\n",
      "  6    1400           5.52       81.00    0.81\n",
      "  8    1600           4.01       82.35    0.82\n",
      " 10    1800           3.16       81.84    0.82\n",
      " 13    2000           2.18       82.47    0.82\n",
      " 17    2200           1.64       82.40    0.82\n",
      " 21    2400           1.21       83.12    0.83\n",
      " 26    2600           0.86       83.26    0.83\n",
      " 33    2800           0.64       82.81    0.83\n",
      " 42    3000           0.44       82.99    0.83\n",
      " 52    3200           0.34       83.20    0.83\n",
      " 65    3400           0.25       83.33    0.83\n",
      " 80    3600           0.18       83.06    0.83\n",
      " 99    3800           0.13       83.20    0.83\n",
      "122    4000           0.10       83.20    0.83\n",
      "150    4200           0.07       83.72    0.84\n",
      "183    4400           0.05       83.57    0.84\n",
      "216    4600           0.04       82.92    0.83\n",
      "250    4800           0.03       82.92    0.83\n",
      "283    5000           0.03       82.86    0.83\n",
      "316    5200           0.02       82.86    0.83\n",
      "350    5400           0.02       83.06    0.83\n",
      "383    5600           0.02       83.13    0.83\n",
      "416    5800           0.01       83.13    0.83\n",
      "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
      "/Users/eric/Dev/quantify-news/models/sent_relevance/model-last\n",
      "Training time: 54.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-20 14:12:13,398 - git.cmd - DEBUG - Popen(['git', 'cat-file', '--batch-check'], cwd=/Users/eric/Dev/quantify-news, stdin=<valid stream>, shell=False, universal_newlines=False)\n",
      "2025-03-20 14:12:13,429 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 14:12:13,452 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"POST /api/2.0/mlflow/runs/create HTTP/1.1\" 200 1074\n",
      "2025-03-20 14:12:13,461 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 14:12:13,570 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"POST /api/2.0/mlflow/runs/log-batch HTTP/1.1\" 200 2\n",
      "2025-03-20 14:12:13,577 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 14:12:13,592 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"POST /api/2.0/mlflow/runs/log-batch HTTP/1.1\" 200 2\n",
      "\u001b[31m2025/03/20 14:12:19 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "2025-03-20 14:12:19,474 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 14:12:19,511 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"GET /api/2.0/mlflow/runs/get?run_uuid=88042ea6a2904452b7501fe9d25c3cb8&run_id=88042ea6a2904452b7501fe9d25c3cb8 HTTP/1.1\" 200 12950\n",
      "2025-03-20 14:12:19,535 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 14:12:19,543 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"POST /api/2.0/mlflow/runs/log-model HTTP/1.1\" 200 2\n",
      "2025-03-20 14:12:19,564 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 14:12:19,588 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"GET /api/2.0/mlflow/runs/get?run_uuid=88042ea6a2904452b7501fe9d25c3cb8&run_id=88042ea6a2904452b7501fe9d25c3cb8 HTTP/1.1\" 200 13533\n",
      "2025-03-20 14:12:19,596 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 14:12:19,604 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"POST /api/2.0/mlflow/runs/update HTTP/1.1\" 200 470\n",
      "[I 2025-03-20 14:12:19,629] Trial 54 finished with value: 0.5532451819 and parameters: {'components.textcat_multilabel.model.ngram_size': 2}. Best is trial 7 with value: 0.5532451819.\n",
      "2025-03-20 14:12:19,636 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 14:12:19,643 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"GET /api/2.0/mlflow/runs/get?run_uuid=173b494a571a4b98a57c73b4a6234408&run_id=173b494a571a4b98a57c73b4a6234408 HTTP/1.1\" 200 948\n",
      "2025-03-20 14:12:19,648 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 14:12:19,653 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"POST /api/2.0/mlflow/runs/update HTTP/1.1\" 200 464\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run optuna_trial_54 at: http://127.0.0.1:8080/#/experiments/485071347047209202/runs/88042ea6a2904452b7501fe9d25c3cb8\n",
      "🧪 View experiment at: http://127.0.0.1:8080/#/experiments/485071347047209202\n",
      "🏃 View run opt_ngram at: http://127.0.0.1:8080/#/experiments/485071347047209202/runs/173b494a571a4b98a57c73b4a6234408\n",
      "🧪 View experiment at: http://127.0.0.1:8080/#/experiments/485071347047209202\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run(run_name=\"opt_ngram\"):\n",
    "    study.optimize(objective, n_trials=2, callbacks=[archiver])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Null Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NullModel:\n",
    "\n",
    "    def train(self, data_path: str):\n",
    "        blank = spacy.blank(\"en\")\n",
    "        docs = DocBin().from_disk(data_path).get_docs(blank.vocab)\n",
    "        probs = {}\n",
    "        n_docs = 0\n",
    "        for d in docs:\n",
    "             n_docs += 1\n",
    "             for c in d.cats:\n",
    "                  probs[c] = probs.setdefault(c, 0) + d.cats[c]\n",
    "        self.probs = {c: p / n_docs for c,p in probs.items()}\n",
    "        self.n_docs = n_docs\n",
    "\n",
    "    def eval(self, data_path):\n",
    "        blank = spacy.blank(\"en\")\n",
    "        golds = list(DocBin().from_disk(data_path).get_docs(blank.vocab))\n",
    "        rng = np.random.default_rng(seed=secrets.randbits(128))\n",
    "        scores = pd.DataFrame.from_records([self.eval_trial(rng, golds) for _ in range(100)])\n",
    "        scores = scores.select_dtypes('number')\n",
    "        return scores.mean().to_dict()\n",
    "\n",
    "    def eval_trial(self, rng, golds):\n",
    "        preds = pd.concat([\n",
    "            pd.Series(rng.choice(2, size=self.n_docs, p=[pc, 1-pc]), name=c)\n",
    "            for c, pc in self.probs.items()\n",
    "        ], axis=1)\n",
    "\n",
    "        examples = []\n",
    "        for row,gold in zip(preds.iterrows(), golds):\n",
    "            d = Doc(gold.vocab).from_bytes(gold.to_bytes())\n",
    "            for c in d.cats:\n",
    "                d.cats[c] = row[1][c]\n",
    "            examples.append(Example(d, gold))\n",
    "\n",
    "        scorer = Scorer(default_pipeline=['textcat_multilabel'])\n",
    "        return flatten_config(scorer.score_cats(examples, \"cats\", labels=preds.columns.to_list()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-20 14:12:33,128 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 14:12:33,144 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"POST /api/2.0/mlflow/runs/create HTTP/1.1\" 200 974\n",
      "2025-03-20 14:12:33,150 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 14:12:33,168 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"POST /api/2.0/mlflow/runs/log-batch HTTP/1.1\" 200 2\n",
      "2025-03-20 14:12:33,174 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 14:12:33,182 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"POST /api/2.0/mlflow/runs/log-batch HTTP/1.1\" 200 2\n",
      "2025-03-20 14:12:33,188 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 14:12:33,201 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"GET /api/2.0/mlflow/runs/get?run_uuid=38d3b3773f86499fbae95e2936c35a6d&run_id=38d3b3773f86499fbae95e2936c35a6d HTTP/1.1\" 200 5874\n",
      "2025-03-20 14:12:33,208 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 14:12:33,213 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"POST /api/2.0/mlflow/runs/update HTTP/1.1\" 200 477\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run null_model_expectation at: http://127.0.0.1:8080/#/experiments/485071347047209202/runs/38d3b3773f86499fbae95e2936c35a6d\n",
      "🧪 View experiment at: http://127.0.0.1:8080/#/experiments/485071347047209202\n"
     ]
    }
   ],
   "source": [
    "null_model = NullModel()\n",
    "null_model.train(train_path)\n",
    "metrics = null_model.eval(dev_path)\n",
    "with mlflow.start_run(run_name=\"null_model_expectation\", nested=False) as run:\n",
    "        mlflow.log_metrics(metrics)\n",
    "        mlflow.log_params(null_model.probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-20 14:12:33,290 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 14:12:33,296 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"GET /api/2.0/mlflow/experiments/get-by-name?experiment_name=sent_relevance_models HTTP/1.1\" 200 600\n",
      "2025-03-20 14:12:33,301 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 14:12:33,710 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"POST /api/2.0/mlflow/runs/search HTTP/1.1\" 200 14683\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'training.batcher.size.start': '17',\n",
       " 'paths.vectors': 'en_core_web_sm',\n",
       " 'components.textcat_multilabel.model.ngram_size': '1',\n",
       " 'components.textcat_multilabel.model.length': '262144'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params(hyperparams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-20 14:12:33,792 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 14:12:33,799 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"GET /api/2.0/mlflow/experiments/get-by-name?experiment_name=sent_relevance_models HTTP/1.1\" 200 600\n",
      "2025-03-20 14:12:33,805 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 14:12:34,178 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"POST /api/2.0/mlflow/runs/search HTTP/1.1\" 200 14683\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'metrics.cats_macro_p': 0.6993103448,\n",
       " 'metrics.cats_micro_r': 0.7169811321,\n",
       " 'metrics.cats_macro_r': 0.4926436782,\n",
       " 'metrics.cats_f_per_type.WHAT.f': 0.6315789474,\n",
       " 'metrics.cats_f_per_type.WHEN.f': 0.0,\n",
       " 'metrics.cats_macro_f': 0.5532451819,\n",
       " 'metrics.cats_f_per_type.WHEN.p': 0.0,\n",
       " 'metrics.cats_f_per_type.WHO.r': 0.4,\n",
       " 'metrics.cats_f_per_type.WHERE.f': 0.6666666667,\n",
       " 'metrics.cats_f_per_type.WHEN.r': 0.0,\n",
       " 'metrics.cats_f_per_type.WHO.p': 1.0,\n",
       " 'metrics.cats_f_per_type.WHERE.p': 1.0,\n",
       " 'metrics.cats_f_per_type.WHERE.r': 0.5,\n",
       " 'metrics.cats_score': 0.8371653214,\n",
       " 'metrics.cats_f_per_type.IRRELEVANT.f': 0.8965517241,\n",
       " 'metrics.cats_f_per_type.WHAT.r': 0.6666666667,\n",
       " 'metrics.cats_f_per_type.IRRELEVANT.r': 0.8965517241,\n",
       " 'metrics.cats_micro_p': 0.8260869565,\n",
       " 'metrics.cats_f_per_type.IRRELEVANT.p': 0.8965517241,\n",
       " 'metrics.cats_micro_f': 0.7676767677,\n",
       " 'metrics.cats_f_per_type.WHO.f': 0.5714285714,\n",
       " 'metrics.cats_f_per_type.WHAT.p': 0.6}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-20 14:12:34,348 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 14:12:34,359 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"GET /api/2.0/mlflow/experiments/get-by-name?experiment_name=sent_relevance_models HTTP/1.1\" 200 600\n",
      "2025-03-20 14:12:34,366 - urllib3.connectionpool - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2025-03-20 14:12:34,739 - urllib3.connectionpool - DEBUG - http://127.0.0.1:8080 \"POST /api/2.0/mlflow/runs/search HTTP/1.1\" 200 14683\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m✔ Loaded model\n",
      "/Users/eric/Dev/quantify-news/mlruns/485071347047209202/88042ea6a2904452b7501fe9d25c3cb8/artifacts/optuna_trial_54/model.spacy\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "apply(data_path=Path(dev_path), \n",
    "      output_file=Path(\"./preds.spacy\"), \n",
    "      model=best_model(), \n",
    "      json_field=\"text\", \n",
    "      batch_size=1,\n",
    "      n_process=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_pred = DocBin().from_disk(\"./preds.spacy\")\n",
    "docs_gold = DocBin().from_disk(dev_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "text",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "WHO.y",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "WHO.x",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "WHERE.y",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "WHERE.x",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "WHEN.y",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "WHEN.x",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "WHAT.y",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "WHAT.x",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "IRRELEVANT.y",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "IRRELEVANT.x",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "ced06d99-520d-41a5-98f3-2bf3c5e68c82",
       "rows": [
        [
         "0",
         "The other driver, a 23-year-old man, was cited for failing to reduce speed to avoid an accident.",
         "0",
         "1",
         "0",
         "0",
         "0",
         "0",
         "0",
         "1",
         "1",
         "0"
        ],
        [
         "1",
         "It states the boat \"shall not be operated waterborne\" when winds exceed 35 mph and/or wave heights exceed 2 feet.",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "1",
         "1"
        ],
        [
         "2",
         "champion James Holzhauer on working for the Cubs, cashing in on his celebrity and changing how the game is played » ]",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "1",
         "1"
        ],
        [
         "3",
         "#####",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "1",
         "1"
        ],
        [
         "4",
         "“It seems that CDOT is focused on tipping the scales for bikes using ‘lock-to,’ instead of letting residents on the South Side determine for themselves what kind of bike-share system they prefer to use,” Jesse Lucci, general manager of Lime Chicago, was quoted as saying in an email.",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "1",
         "1"
        ],
        [
         "5",
         "The visitors apparently fell from Taft Point, a popular outlook west of Glacier Point, park officials said in a news release.",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "1",
         "1"
        ],
        [
         "6",
         "There are songs that I wish were made and I want to make them.",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "1",
         "1"
        ],
        [
         "7",
         "Around that time, two people were shot a few blocks over in the 1300 block of South Troy.",
         "1",
         "1",
         "1",
         "1",
         "1",
         "0",
         "1",
         "1",
         "0",
         "0"
        ],
        [
         "8",
         "The shooter suffered a self-inflicted gunshot wound to the left leg and was taken in police custody to Stroger Hospital, police said.",
         "1",
         "1",
         "0",
         "0",
         "0",
         "0",
         "1",
         "1",
         "0",
         "0"
        ],
        [
         "9",
         "[1] **",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "1",
         "1"
        ],
        [
         "10",
         "[ TMZ: Rapper Chief Keef arrested ]",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "1",
         "1"
        ],
        [
         "11",
         "This is not a Portage problem, but a regional issue that we all have been fighting for some time,” Portage police said in a Facebook post.",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "1",
         "1"
        ],
        [
         "12",
         "According to officials, the children were not properly restrained in the vehicle; the toddler needed to be resuscitated at the scene.",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "1",
         "1"
        ],
        [
         "13",
         "[70] ** McKee failed to tell passengers to put on their flotation devices or prepare to abandon ship as waves crashed into the boat, which was originally designed for military use in World War II but had been refurbished as a tourist attraction, according to the indictment .",
         "0",
         "1",
         "0",
         "0",
         "0",
         "0",
         "1",
         "1",
         "1",
         "0"
        ],
        [
         "14",
         "The man took himself to West Suburban Medical Center, where his condition stabilized.",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "1",
         "0",
         "0",
         "1"
        ],
        [
         "15",
         "[7]: _URL_",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "1",
         "1"
        ],
        [
         "16",
         "A man and woman [ were found dead ]",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "1",
         "0",
         "0",
         "1"
        ],
        [
         "17",
         "assault-20190803-q5nnjvgyxbdwfogqgrqdsikvzy-story.html#nt=related-content [8]: /news/breaking/ct-man-shot-southwest-side-construction- yard-20190802-75q3ynomi5df5kkebk7ynxx2by-story.html#nt=related-content",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "1",
         "1"
        ],
        [
         "18",
         "** Three overdoses left two people dead in less than 24 hours in Portage, Indiana.",
         "0",
         "0",
         "0",
         "1",
         "0",
         "0",
         "1",
         "1",
         "0",
         "0"
        ],
        [
         "19",
         "Kenner said she is working with police and district personnel to review video surveillance footage from the hallways, but said there are no cameras located in or near the bathrooms.",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "1",
         "1"
        ],
        [
         "20",
         "He was walking in the 3300 block of West Fulton when he heard shots and felt pain, police said.",
         "1",
         "1",
         "1",
         "1",
         "0",
         "0",
         "1",
         "1",
         "0",
         "0"
        ],
        [
         "21",
         "The principal said in an interview that she wasn’t surprised that another threat was found and has suspicions that the second threat was made as a joke.",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "1",
         "0",
         "0",
         "1"
        ],
        [
         "22",
         "Rangers said the deaths are under investigation and did not immediately release more information about the victims.",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "1",
         "1"
        ],
        [
         "23",
         "[4]: _URL_",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "1",
         "1"
        ],
        [
         "24",
         "The woman was grazed in the right foot and refused medical treatment at the scene.",
         "1",
         "1",
         "0",
         "0",
         "0",
         "0",
         "1",
         "1",
         "0",
         "0"
        ],
        [
         "25",
         "[ [Most read] Q&amp;A with ‘Jeopardy!’",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "1",
         "1"
        ],
        [
         "26",
         "Weather was calm when the vessel known as a Stretch Duck 7 began its trip on July 19, but investigators have contended that operators had ample warning that a strong storm was approaching.",
         "0",
         "1",
         "0",
         "0",
         "0",
         "1",
         "1",
         "0",
         "0",
         "0"
        ],
        [
         "27",
         "Mayor Rahm Emanuel’s administration has lifted the locking requirement for Chicago’s dockless bike-sharing companies, but in a way that competitors warn could once again favor Uber, the ride-sharing giant whose investors include the mayor’s brother.",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "1",
         "1"
        ],
        [
         "28",
         "The city’s original plan gave dockless bike-sharing companies now conducting a test run on the Far South Side a July 1 deadline to have locking equipment that allowed the bikes to be tethered to a sign post, bike rack or other fixed object.",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "1",
         "1"
        ],
        [
         "29",
         "The photo was taken on Oct. 6, though it only gained national attention weeks later when Dippel posted it to Twitter with a plea to help him identify the couple.",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "1",
         "1"
        ],
        [
         "30",
         "If you or anyone you know is struggling with addiction, you can call the Illinois Helpline at 833-2FINDHELP, or the Indiana Addiction hotline at 800-662-HELP",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "1",
         "1"
        ],
        [
         "31",
         "Anthony Beale (9th), chairman of the City Council’s Transportation Committee, added, “If Uber is just rolling out their dockless stations and rules and regs have suddenly been changed, then once again [the question is], are we changing the rules for Uber?”",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "1",
         "1"
        ],
        [
         "32",
         "The 32-year-old said he ran to where the bullets flew and startled people were running away to make sure his friends and family there weren’t hit.",
         "0",
         "1",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "33",
         "The driver will be cited for improper lane usage and driving off the roadway, police said.",
         "0",
         "1",
         "0",
         "0",
         "0",
         "0",
         "0",
         "1",
         "1",
         "0"
        ],
        [
         "34",
         "Luna was born in 2016.",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "1",
         "1"
        ],
        [
         "35",
         "[3]: _URL_",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "1",
         "1"
        ],
        [
         "36",
         "He also is accused of not properly assessing the weather before or after the boat went into Table Rock Lake near the tourist town of Branson, U.S. Attorney Tim Garrison said during a news conference in Springfield.",
         "0",
         "1",
         "0",
         "1",
         "0",
         "0",
         "0",
         "1",
         "0",
         "0"
        ],
        [
         "37",
         "[2] [1]: _URL_",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "1",
         "1"
        ],
        [
         "38",
         "* It started with me.",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "1",
         "1"
        ],
        [
         "39",
         "[3] * [ Family: Man pulled from Lake Michigan identified as missing ‘boat hopper’ ]",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "1",
         "1"
        ]
       ],
       "shape": {
        "columns": 11,
        "rows": 40
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>WHO.y</th>\n",
       "      <th>WHO.x</th>\n",
       "      <th>WHERE.y</th>\n",
       "      <th>WHERE.x</th>\n",
       "      <th>WHEN.y</th>\n",
       "      <th>WHEN.x</th>\n",
       "      <th>WHAT.y</th>\n",
       "      <th>WHAT.x</th>\n",
       "      <th>IRRELEVANT.y</th>\n",
       "      <th>IRRELEVANT.x</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The other driver, a 23-year-old man, was cited...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It states the boat \"shall not be operated wate...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>champion James Holzhauer on working for the Cu...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#####</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>“It seems that CDOT is focused on tipping the ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The visitors apparently fell from Taft Point, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>There are songs that I wish were made and I wa...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Around that time, two people were shot a few b...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>The shooter suffered a self-inflicted gunshot ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[1] **</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[ TMZ: Rapper Chief Keef arrested ]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>This is not a Portage problem, but a regional ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>According to officials, the children were not ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[70] ** McKee failed to tell passengers to put...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>The man took himself to West Suburban Medical ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[7]: _URL_</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>A man and woman [ were found dead ]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>assault-20190803-q5nnjvgyxbdwfogqgrqdsikvzy-st...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>** Three overdoses left two people dead in les...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Kenner said she is working with police and dis...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>He was walking in the 3300 block of West Fulto...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>The principal said in an interview that she wa...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Rangers said the deaths are under investigatio...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>[4]: _URL_</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>The woman was grazed in the right foot and ref...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>[ [Most read] Q&amp;amp;A with ‘Jeopardy!’</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Weather was calm when the vessel known as a St...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Mayor Rahm Emanuel’s administration has lifted...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>The city’s original plan gave dockless bike-sh...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>The photo was taken on Oct. 6, though it only ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>If you or anyone you know is struggling with a...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Anthony Beale (9th), chairman of the City Coun...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>The 32-year-old said he ran to where the bulle...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>The driver will be cited for improper lane usa...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Luna was born in 2016.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>[3]: _URL_</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>He also is accused of not properly assessing t...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>[2] [1]: _URL_</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>* It started with me.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>[3] * [ Family: Man pulled from Lake Michigan ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  WHO.y  WHO.x  WHERE.y  \\\n",
       "0   The other driver, a 23-year-old man, was cited...      0      1        0   \n",
       "1   It states the boat \"shall not be operated wate...      0      0        0   \n",
       "2   champion James Holzhauer on working for the Cu...      0      0        0   \n",
       "3                                               #####      0      0        0   \n",
       "4   “It seems that CDOT is focused on tipping the ...      0      0        0   \n",
       "5   The visitors apparently fell from Taft Point, ...      0      0        0   \n",
       "6   There are songs that I wish were made and I wa...      0      0        0   \n",
       "7   Around that time, two people were shot a few b...      1      1        1   \n",
       "8   The shooter suffered a self-inflicted gunshot ...      1      1        0   \n",
       "9                                              [1] **      0      0        0   \n",
       "10                [ TMZ: Rapper Chief Keef arrested ]      0      0        0   \n",
       "11  This is not a Portage problem, but a regional ...      0      0        0   \n",
       "12  According to officials, the children were not ...      0      0        0   \n",
       "13  [70] ** McKee failed to tell passengers to put...      0      1        0   \n",
       "14  The man took himself to West Suburban Medical ...      0      0        0   \n",
       "15                                         [7]: _URL_      0      0        0   \n",
       "16                A man and woman [ were found dead ]      0      0        0   \n",
       "17  assault-20190803-q5nnjvgyxbdwfogqgrqdsikvzy-st...      0      0        0   \n",
       "18  ** Three overdoses left two people dead in les...      0      0        0   \n",
       "19  Kenner said she is working with police and dis...      0      0        0   \n",
       "20  He was walking in the 3300 block of West Fulto...      1      1        1   \n",
       "21  The principal said in an interview that she wa...      0      0        0   \n",
       "22  Rangers said the deaths are under investigatio...      0      0        0   \n",
       "23                                         [4]: _URL_      0      0        0   \n",
       "24  The woman was grazed in the right foot and ref...      1      1        0   \n",
       "25             [ [Most read] Q&amp;A with ‘Jeopardy!’      0      0        0   \n",
       "26  Weather was calm when the vessel known as a St...      0      1        0   \n",
       "27  Mayor Rahm Emanuel’s administration has lifted...      0      0        0   \n",
       "28  The city’s original plan gave dockless bike-sh...      0      0        0   \n",
       "29  The photo was taken on Oct. 6, though it only ...      0      0        0   \n",
       "30  If you or anyone you know is struggling with a...      0      0        0   \n",
       "31  Anthony Beale (9th), chairman of the City Coun...      0      0        0   \n",
       "32  The 32-year-old said he ran to where the bulle...      0      1        0   \n",
       "33  The driver will be cited for improper lane usa...      0      1        0   \n",
       "34                             Luna was born in 2016.      0      0        0   \n",
       "35                                         [3]: _URL_      0      0        0   \n",
       "36  He also is accused of not properly assessing t...      0      1        0   \n",
       "37                                     [2] [1]: _URL_      0      0        0   \n",
       "38                              * It started with me.      0      0        0   \n",
       "39  [3] * [ Family: Man pulled from Lake Michigan ...      0      0        0   \n",
       "\n",
       "    WHERE.x  WHEN.y  WHEN.x  WHAT.y  WHAT.x  IRRELEVANT.y  IRRELEVANT.x  \n",
       "0         0       0       0       0       1             1             0  \n",
       "1         0       0       0       0       0             1             1  \n",
       "2         0       0       0       0       0             1             1  \n",
       "3         0       0       0       0       0             1             1  \n",
       "4         0       0       0       0       0             1             1  \n",
       "5         0       0       0       0       0             1             1  \n",
       "6         0       0       0       0       0             1             1  \n",
       "7         1       1       0       1       1             0             0  \n",
       "8         0       0       0       1       1             0             0  \n",
       "9         0       0       0       0       0             1             1  \n",
       "10        0       0       0       0       0             1             1  \n",
       "11        0       0       0       0       0             1             1  \n",
       "12        0       0       0       0       0             1             1  \n",
       "13        0       0       0       1       1             1             0  \n",
       "14        0       0       0       1       0             0             1  \n",
       "15        0       0       0       0       0             1             1  \n",
       "16        0       0       0       1       0             0             1  \n",
       "17        0       0       0       0       0             1             1  \n",
       "18        1       0       0       1       1             0             0  \n",
       "19        0       0       0       0       0             1             1  \n",
       "20        1       0       0       1       1             0             0  \n",
       "21        0       0       0       1       0             0             1  \n",
       "22        0       0       0       0       0             1             1  \n",
       "23        0       0       0       0       0             1             1  \n",
       "24        0       0       0       1       1             0             0  \n",
       "25        0       0       0       0       0             1             1  \n",
       "26        0       0       1       1       0             0             0  \n",
       "27        0       0       0       0       0             1             1  \n",
       "28        0       0       0       0       0             1             1  \n",
       "29        0       0       0       0       0             1             1  \n",
       "30        0       0       0       0       0             1             1  \n",
       "31        0       0       0       0       0             1             1  \n",
       "32        0       0       0       0       0             0             0  \n",
       "33        0       0       0       0       1             1             0  \n",
       "34        0       0       0       0       0             1             1  \n",
       "35        0       0       0       0       0             1             1  \n",
       "36        1       0       0       0       1             0             0  \n",
       "37        0       0       0       0       0             1             1  \n",
       "38        0       0       0       0       0             1             1  \n",
       "39        0       0       0       0       0             1             1  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare = pd.DataFrame.from_records([({'text': gold.text} \n",
    "                           | {k+\".x\": v for k,v in gold.cats.items()} \n",
    "                           | {k+\".y\": 1 if v > .5 else 0 for k,v in pred.cats.items()} )\n",
    "    for pred,gold in zip(docs_pred.get_docs(spacy.blank(\"en\").vocab),\n",
    "                        docs_gold.get_docs(spacy.blank(\"en\").vocab))])\n",
    "compare.sort_index(axis=1, ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions\n",
    "\n",
    "At this point i'm guessing hp tuning won't help the model.\n",
    "Though I haven't tried any of the more advanced model architectures yet. \n",
    "I'm not sure if this task is a) trainable or b) useful in the contest of the pipeline.\n",
    "It would be better to either label more data and try again,\n",
    "or move onto the next part. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (qjn)",
   "language": "python",
   "name": "qjn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
