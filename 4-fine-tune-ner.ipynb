{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YNy3T0twt7Ox"
      },
      "outputs": [],
      "source": [
        "%pip install optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LwNrHZyUDLKa"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "import subprocess\n",
        "import os\n",
        "import time\n",
        "import json\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "import spacy\n",
        "import optuna\n",
        "from thinc.api import Config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8w3CU2hiDLKc"
      },
      "outputs": [],
      "source": [
        "COLAB = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I0Z92KYODLKd"
      },
      "outputs": [],
      "source": [
        "DATA_DIR = \"gdrive/MyDrive/Work/quantify-news/data/\" if COLAB else \"data/\"\n",
        "PROJECT_DIR = \"gdrive/MyDrive/Work/quantify-news/\" if COLAB else \"./\"\n",
        "TMP_DIR = \"/content/\" if COLAB else \"./\"\n",
        "\n",
        "GPU_ID = \"0\" if COLAB else \"-1\"\n",
        "\n",
        "DATA_TRAIN_BIN_PATH = DATA_DIR + \"ner_train.spacy\"\n",
        "DATA_DEV_BIN_PATH = DATA_DIR + \"ner_dev.spacy\"\n",
        "DATA_TEST_BIN_PATH = DATA_DIR + \"ner_test.spacy\"\n",
        "PRED_BIN_PATH = DATA_DIR + \"ner_pred.spacy\"\n",
        "\n",
        "SPACY_CONFIG_PATH = PROJECT_DIR + (\"spacy_base_config_colab.cfg\" if COLAB else \"spacy_base_config.cfg\")\n",
        "SPACY_FULL_CONFIG_PATH = PROJECT_DIR + \"spacy_config.cfg\"\n",
        "\n",
        "# For spacy training inner loop\n",
        "TRAINED_MODEL_PATH = TMP_DIR + \"models/\"\n",
        "BEST_MODEL_TRAIN_PATH = TRAINED_MODEL_PATH + \"model-best/\"\n",
        "BEST_MODEL_RESULTS_PATH = BEST_MODEL_TRAIN_PATH + \"meta.json\"\n",
        "\n",
        "# For optuna outer loop\n",
        "BEST_MODEL_OPT_PATH = PROJECT_DIR + \"models/model-best/\"\n",
        "METRICS_DIR = PROJECT_DIR + \"metrics/\"\n",
        "METRICS_OUTPUT_PATH = METRICS_DIR + \"metrics.json\"\n",
        "SAMPLE_OUTPUT_PATH = METRICS_DIR + \"metrics_sample/\"\n",
        "\n",
        "HP_STUDY_NAME = \"ner_hp\"\n",
        "HP_HISTORY_PATH = \"sqlite:///{}/{}.db\".format(PROJECT_DIR, HP_STUDY_NAME)\n",
        "PARAMS_OUTPUT_PATH = PROJECT_DIR + \"best_params.json\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1HBSqb_6OE_3",
        "outputId": "7e94877d-3906-4312-aaba-3b00fa030947"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n",
            "UTF-8\n"
          ]
        }
      ],
      "source": [
        "if COLAB:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/gdrive')\n",
        "    assert spacy.require_gpu()\n",
        "\n",
        "    import locale\n",
        "    print(locale.getpreferredencoding())\n",
        "    def getpreferredencoding(do_setlocale=True):\n",
        "        return 'UTF-8'\n",
        "    locale.getpreferredencoding = getpreferredencoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uyLTP84GDLKe"
      },
      "outputs": [],
      "source": [
        "spacy_config = Config().from_disk(SPACY_CONFIG_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kMeoPSLtDLKf"
      },
      "outputs": [],
      "source": [
        "SPACY_BASE_MODEL = spacy_config['components']['ner']['source']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6NSq3JLTDLKg",
        "outputId": "c329d50b-78f4-44c3-9afb-e12bf826d157"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_md')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    nlp_base = spacy.load(SPACY_BASE_MODEL)\n",
        "except:\n",
        "    spacy.cli.download(SPACY_BASE_MODEL)\n",
        "    nlp_base = spacy.load(SPACY_BASE_MODEL)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n86fesV_DLKh"
      },
      "source": [
        "# Fine-Tune Spacy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m4MPiIFTYeoV",
        "outputId": "947555e6-61cc-47ca-9168-ddb389daf562"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[38;5;2m✔ Auto-filled config with all values\u001b[0m\n",
            "\u001b[38;5;2m✔ Saved config\u001b[0m\n",
            "gdrive/MyDrive/Work/quantify-news/spacy_config.cfg\n",
            "You can now add your data and train your pipeline:\n",
            "python -m spacy train spacy_config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"
          ]
        }
      ],
      "source": [
        "!python -m spacy init fill-config {SPACY_CONFIG_PATH} {SPACY_FULL_CONFIG_PATH}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sll0hS12RqBD",
        "outputId": "21874398-7063-4bb4-b40b-9377dc9a05fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[38;5;2m✔ Created output directory: /content/models\u001b[0m\n",
            "\u001b[38;5;4mℹ Saving to output directory: /content/models\u001b[0m\n",
            "\u001b[38;5;4mℹ Using GPU: 0\u001b[0m\n",
            "\u001b[1m\n",
            "=========================== Initializing pipeline ===========================\u001b[0m\n",
            "[2025-03-11 21:34:09,251] [INFO] Set up nlp object from config\n",
            "[2025-03-11 21:34:09,265] [DEBUG] Loading corpus from path: gdrive/MyDrive/Work/quantify-news/data/ner_dev.spacy\n",
            "[2025-03-11 21:34:09,267] [DEBUG] Loading corpus from path: gdrive/MyDrive/Work/quantify-news/data/ner_train.spacy\n",
            "[2025-03-11 21:34:09,268] [INFO] Pipeline: ['ner']\n",
            "[2025-03-11 21:34:09,268] [INFO] Resuming training for: ['ner']\n",
            "[2025-03-11 21:34:09,276] [INFO] Created vocabulary\n",
            "[2025-03-11 21:34:11,200] [INFO] Added vectors: en_core_web_md\n",
            "[2025-03-11 21:34:11,307] [INFO] Finished initializing nlp object\n",
            "[2025-03-11 21:34:11,307] [INFO] Initialized pipeline components: []\n",
            "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
            "\u001b[1m\n",
            "============================= Training pipeline =============================\u001b[0m\n",
            "[2025-03-11 21:34:11,322] [DEBUG] Loading corpus from path: gdrive/MyDrive/Work/quantify-news/data/ner_dev.spacy\n",
            "[2025-03-11 21:34:11,324] [DEBUG] Loading corpus from path: gdrive/MyDrive/Work/quantify-news/data/ner_train.spacy\n",
            "\u001b[38;5;4mℹ Pipeline: ['ner']\u001b[0m\n",
            "\u001b[38;5;4mℹ Initial learn rate: 0.001\u001b[0m\n",
            "E    #       LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
            "---  ------  --------  ------  ------  ------  ------\n",
            "  0       0    236.13    0.00    0.00    0.00    0.00\n",
            "  0    1600   5771.07   61.14   70.45   54.00    0.61\n",
            "  1    3200   5488.27   57.58   50.07   67.76    0.58\n",
            "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
            "/content/models/model-last\n"
          ]
        }
      ],
      "source": [
        "!python -m spacy train \\\n",
        "    {SPACY_FULL_CONFIG_PATH} \\\n",
        "    --gpu-id {GPU_ID} \\\n",
        "    --output {TRAINED_MODEL_PATH} \\\n",
        "    --verbose\n",
        "# --code ./entity_remapper.py \\"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VdgAnLV7DLKk"
      },
      "source": [
        "## Hyperparameter tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G1iBHhoxpm1y"
      },
      "outputs": [],
      "source": [
        "def shell(command, time_fmt=None):\n",
        "    start = time.time()\n",
        "    process = subprocess.Popen(command, shell=False,\n",
        "                               stdout=subprocess.PIPE,\n",
        "                               stderr=subprocess.STDOUT,\n",
        "                               text=True,\n",
        "                               encoding='utf-8',\n",
        "                               bufsize=1)\n",
        "    for line in process.stdout:\n",
        "        print(line, end='', flush=True)\n",
        "    process.wait()\n",
        "    end = time.time()\n",
        "\n",
        "    print(time_fmt.format(end - start))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JbM8VAr0DLKl"
      },
      "outputs": [],
      "source": [
        "def objective(trial):\n",
        "    start_size = trial.suggest_int(\"start_size\", 100, 500)  # Tune batch start\n",
        "    stop_size = trial.suggest_int(\"stop_size\", 1000, 5000)  # Tune batch stop\n",
        "    learning_rate = trial.suggest_float(\"lr\", 1e-5, 1e-3, log=True)\n",
        "\n",
        "    command = [\n",
        "        \"python\", \"-m\", \"spacy\",\n",
        "        \"train\", SPACY_FULL_CONFIG_PATH,\n",
        "        \"--gpu-id\", GPU_ID,\n",
        "        \"--training.batcher.size.start\", str(start_size),\n",
        "        \"--training.batcher.size.stop\", str(stop_size),\n",
        "        \"--training.optimizer.learn_rate\", str(learning_rate),\n",
        "        \"--output\", TRAINED_MODEL_PATH,\n",
        "    ]\n",
        "    # TODO: I can use spacy.cli.train.train here instead of shell proc!\n",
        "    shell(command, \"Training time: {:.4f} sec\")\n",
        "\n",
        "    with open(BEST_MODEL_RESULTS_PATH) as fp:\n",
        "        result = json.load(fp)\n",
        "\n",
        "    return result['performance']['ents_f']\n",
        "\n",
        "\n",
        "\n",
        "# class SaveBestModelCallback:\n",
        "#     def __call__(self, study: optuna.study.Study, trial: optuna.trial.FrozenTrial) -> None:\n",
        "#         if study.best_value <= trial.value:\n",
        "#             shutil.copytree(BEST_MODEL_TRAIN_PATH, BEST_MODEL_OPT_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YXzT0nJKigRS"
      },
      "outputs": [],
      "source": [
        "# study = optuna.create_study(study_name=HP_STUDY_NAME, direction=\"maximize\",\n",
        "#                             storage=HP_HISTORY_PATH, load_if_exists=True,\n",
        "#                             callbacks=[SaveBestModelCallback()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7kBmOU1TDLKm"
      },
      "outputs": [],
      "source": [
        "# study.optimize(objective, n_trials=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fEY-tNuuiahE"
      },
      "outputs": [],
      "source": [
        "# print(\"Best F1 (on val):\")\n",
        "# print(study.best_value)\n",
        "# print(\"Best params:\")\n",
        "# print(study.best_params)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bjfnOI6RDLKm"
      },
      "source": [
        "# Evaluate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eo97wELd9CDh"
      },
      "source": [
        "## Visualize sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZHxnYIjYDLKn"
      },
      "outputs": [],
      "source": [
        "# if not os.path.exists(SAMPLE_OUTPUT_PATH):\n",
        "#     os.makedirs(SAMPLE_OUTPUT_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "blviPAMKZAjF"
      },
      "outputs": [],
      "source": [
        "# !python -m spacy \\\n",
        "#   benchmark accuracy \\\n",
        "#   {BEST_MODEL_TRAIN_PATH} {DATA_DEV_BIN_PATH} \\\n",
        "#   --gpu-id {GPU_ID} \\\n",
        "#   --output {METRICS_OUTPUT_PATH} \\\n",
        "#   --displacy-path {SAMPLE_OUTPUT_PATH}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1k3qebHC9EXX"
      },
      "source": [
        "## Run and test confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D0sw0EIz6EI-"
      },
      "outputs": [],
      "source": [
        "from spacy.tokens import DocBin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_LKs-IPa0ykU",
        "outputId": "dc68a6a4-9173-4761-b3c0-ea29b7fd99e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[38;5;4mℹ Using GPU: 0\u001b[0m\n",
            "\u001b[38;5;2m✔ Loaded model gdrive/MyDrive/Work/quantify-news/models/model-best/\u001b[0m\n",
            "448it [00:10, 42.83it/s]\n"
          ]
        }
      ],
      "source": [
        "!python -m spacy apply \\\n",
        "    {BEST_MODEL_OPT_PATH} \\\n",
        "    {DATA_DEV_BIN_PATH} \\\n",
        "    {PRED_BIN_PATH} \\\n",
        "    --gpu-id {GPU_ID} \\\n",
        "    --force"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wTm1GTqG5_JJ"
      },
      "outputs": [],
      "source": [
        "nlp = spacy.load(BEST_MODEL_OPT_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D0Am0NyS3nRY"
      },
      "outputs": [],
      "source": [
        "pred_docs = list(DocBin().from_disk(PRED_BIN_PATH).get_docs(nlp.vocab))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A6gmVRQTGM_h"
      },
      "outputs": [],
      "source": [
        "gold_docs = list(DocBin().from_disk(DATA_DEV_BIN_PATH).get_docs(nlp_base.vocab))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "37XeOLVzHPG4"
      },
      "outputs": [],
      "source": [
        "assert len(pred_docs) == len(gold_docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YujqpEbI6RAK",
        "outputId": "80a7cf89-9631-482d-a54b-3ad527b3c2ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1:  0.9418653283145128\n",
            "Precision:  0.8901185770750988\n",
            "Recall:  1.0\n"
          ]
        }
      ],
      "source": [
        "from spacy.scorer import Scorer\n",
        "from spacy.training import Example\n",
        "\n",
        "scorer = Scorer()\n",
        "examples = [Example(infer, gold) for infer, gold in zip(pred_docs, gold_docs)]\n",
        "scores = scorer.score(examples)\n",
        "print(\"F1: \", scores['ents_f'])\n",
        "print(\"Precision: \", scores['ents_p'])\n",
        "print(\"Recall: \", scores['ents_r'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uSZGIKkA9ZJw"
      },
      "source": [
        "XXX: this actually looks like it's doing well! it has great recall.\n",
        "actually it doen't have any false negatives. and the false positives are all\n",
        "IMO locations. so maybe don't need to do anything else?\n",
        "\n",
        "Ok but i'm confused because i replicated this on the dev data and also didn't\n",
        "get a false negative. but the trial didn't have 100% recall. so what is\n",
        "going on here?"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
